<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Mengchu Li" />
  <meta name="author" content="Lukas Trottner" />
  <title>Lecture notes Foundations of Statistical Inference</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title"><span class="nodecor">Lecture notes</span><br />
<strong>Foundations of<br />
Statistical Inference</strong></h1>
<p class="author">Mengchu Li</p>
<p class="author">Lukas Trottner</p>
<p class="date">Autumn Term 2024<br />
2024-11-08<br />
- <em>Preliminary version</em> -<br />
<img src="UoB_Logo.png" alt="image" /></p>
</header>
<h1 id="chap:prob">Probability basics</h1>
<h2 id="probability-spaces-and-a-bit-of-measure-theory">Probability
spaces and a bit of measure theory</h2>
<p>Underlying any probabilistic model is a probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>,
where</p>
<ul>
<li><p><span class="math inline">\(\Omega\)</span> is the <em>sample
space</em> that contains all possible outcomes <span
class="math inline">\(\omega\)</span>, called <em>elementary
events</em>;</p></li>
<li><p>the event space <span class="math inline">\(\mathcal{F}\subset
2^{\Omega}\)</span> is a collection of subsets of the sample space that
we wish to assign a probability to. A set <span class="math inline">\(A
\in \mathcal{F}\)</span> is called event;</p></li>
<li><p><span class="math inline">\(\mathbb{P}\)</span> is a probability
measure that assigns to each event <span class="math inline">\(A \in
\mathcal{F}\)</span> a probability <span
class="math inline">\(\mathbb{P}(A) \in [0,1]\)</span>.</p></li>
</ul>
<div id="ex:prob_model" class="example">
<p><em>Example 1.1</em>. Consider the experiment of throwing a fair coin
twice. We model <span class="math inline">\(\Omega = \{HH, HT, TH, TT\}
= \{\omega_i: i= 1,\ldots,4\}\)</span> and <span
class="math display">\[\begin{aligned}
\mathcal{F}= 2^\Omega = \big\{&amp;\varnothing, \Omega, \{HH\}, \{HT\},
\{TH\}, \{TT\}, \{HH,HT\}, \{HH, TH\}, \{HH, TT\}, \{HT,TH\}, \{HT,
TT\},\\
&amp;\{TH,TT\}, \{HH,HT,TH\}, \{HH,HT,TT\}, \{HH,TH,TT\}, \{HT,TH,TT\}
\big\}
\end{aligned}\]</span> Since the coin is fair, each of the 4 elementary
events <span class="math inline">\(\{HH\}, \{HT\}, \{TH\},
\{TT\}\)</span> has the same probability, which is given by <span
class="math inline">\(1/4\)</span>, i.e., <span
class="math inline">\(\mathbb{P}(\{\omega \}) = 1/4\)</span> for all
<span class="math inline">\(\omega \in \Omega\)</span>. The probability
that one of the distinct outcomes <span
class="math inline">\(HT\)</span> and <span
class="math inline">\(TH\)</span> happens is intuitively obtained by
summing up the probabilities, i.e., <span
class="math inline">\(\mathbb{P}(\{HT, TH\}) = \mathbb{P}(\{HT\}) +
\mathbb{P}(\{TH\}) = 1/4 +1/4 = 1/2\)</span>. More generally, for <span
class="math inline">\(C \subset \{1,\ldots,n\}\)</span>, we may set
<span class="math display">\[\mathbb{P}(\{\omega_i : i \in C\}) =
\mathbb{P}(\bigcup_{i \in C} \{\omega_i\}) = \sum_{i \in
C}\mathbb{P}(\{\omega_i\}) = \lvert C \rvert/4.\]</span> Note however
that with this definition, probabilities of unions of events (translates
to “at least one of the events happens”) are <em>not</em> always
obtained by summing up: <span class="math display">\[\mathbb{P}(\{HT\}
\cup \{HT,TH\}) = \mathbb{P}(\{HT,TH\}) = 1/2 \neq 3/4 =
\mathbb{P}(\{HT\}) + \mathbb{P}(\{HT,TH\}).\]</span> The reason here:
the events are not disjoint! With the above model we can for example
identify “heads appears in first throw” with the event <span
class="math inline">\(\{HH,HT\}\)</span>, which has probability <span
class="math inline">\(1/2\)</span>, or “heads appears at least once”
with the event <span class="math inline">\(\{HT,TH,HH\}\)</span>, which
has probability <span class="math inline">\(3/4\)</span>. A
reformulation of this would be “tails does not appear twice” and the
probability can be expressed as <span class="math display">\[3/4 = 1 -
1/4 = 1 - \mathbb{P}(\text{``tails appears twice&#39;&#39;}) = 1 -
\mathbb{P}(\{TT\}) = 1 - \mathbb{P}(\Omega\setminus
\{HT,TH,HH\}).\]</span></p>
</div>
<p>To make these notions mathematically rigorous, we introduce some
fundamental concepts from measure theory, where one builds a consistent
theory of assigning volumes to sets on general spaces. First we deal
with the types of event spaces that we allow for a probability
space.</p>
<div class="definition">
<p><strong>Definition 1.2</strong>. <span
class="math inline">\(\mathcal{F} \subset 2^{\Omega}\)</span> is called
a <span class="math inline">\(\sigma\)</span>-algebra if all of the
following are satisfied:</p>
<ol>
<li><p><span class="math inline">\(\Omega \in
\mathcal{F}\)</span></p></li>
<li><p><span class="math inline">\(A \in \mathcal{F}\implies
A^{\mathrm{c}} \coloneq\Omega \setminus A \in
\mathcal{F}\)</span></p></li>
<li><p><span class="math inline">\((A_n)_{n \in \mathbb{N}} \subset
\mathcal{F}\implies \bigcup_{n \in \mathbb{N}} A_n \in
\mathcal{F}\)</span></p></li>
</ol>
</div>
<p>If <span class="math inline">\(\mathcal{F}\)</span> is a <span
class="math inline">\(\sigma\)</span>-algebra over <span
class="math inline">\(\Omega\)</span>, we call <span
class="math inline">\((\Omega,\mathcal{F})\)</span> a <em>measurable
space</em>.</p>
<div id="lem:sigma_prop" class="lemma">
<p><strong>Lemma 1.3</strong>. <em>Any <span
class="math inline">\(\sigma\)</span>-algebra <span
class="math inline">\(\mathcal{F}\)</span> has the following
properties:</em></p>
<ol>
<li><p><em><span class="math inline">\(\varnothing \in
\mathcal{F}\)</span></em></p></li>
<li><p><em><span class="math inline">\(A,B \in \mathcal{F}\implies A
\cup B \in \mathcal{F}\)</span></em></p></li>
<li><p><em><span class="math inline">\(A,B \in \mathcal{F} \implies A
\cap B \in \mathcal{F}\)</span></em></p></li>
<li><p><em><span class="math inline">\((A_n)_{n\in \mathbb{N}} \subset
\mathcal{F} \implies \bigcap_{n \in \mathbb{N}} A_n \in
\mathcal{F}\)</span></em></p></li>
<li><p><em><span class="math inline">\(A,B \in \mathcal{F}\implies A
\setminus B \in \mathcal{F}\)</span></em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em> Exercise. ◻</p>
</div>
<div class="example">
<p><em>Example 1.4</em>. The simplest examples of <span
class="math inline">\(\sigma\)</span>-algebras are the trivial <span
class="math inline">\(\sigma\)</span>-algebra <span
class="math inline">\(\mathcal{F} = \{\varnothing,\Omega\}\)</span> and
the power set <span class="math inline">\(\mathcal{F} =
2^{\Omega}\)</span> (sometimes called discrete <span
class="math inline">\(\sigma\)</span>-algebra).</p>
</div>
<p>For uncountable spaces <span class="math inline">\(\Omega\)</span>,
the power set <span class="math inline">\(2^{\Omega}\)</span> is usually
a poor choice because it is simply too big in the sense that we cannot
design meaningful measures that consistently assign volumes to all
subsets of <span class="math inline">\(\Omega\)</span> (look up the
Banach–Tarski paradox if you are interested why). Instead, we usually
start with a nice family of subsets <span
class="math inline">\(\mathcal{E}\)</span> of <span
class="math inline">\(\Omega\)</span> and works with the smallest <span
class="math inline">\(\sigma\)</span>-algebra that contains <span
class="math inline">\(\mathcal{E}\)</span>.</p>
<div class="definition">
<p><strong>Definition 1.5</strong>. Let <span
class="math inline">\(\mathcal{E}\)</span> be a family of subsets of
<span class="math inline">\(\Omega\)</span>. Then <span
class="math inline">\(\sigma(\mathcal{E})\)</span> is defined as the
smallest <span class="math inline">\(\sigma\)</span>-algebra over <span
class="math inline">\(\Omega\)</span> that contains <span
class="math inline">\(\mathcal{E}\)</span>, or equivalently, <span
class="math display">\[\sigma(\mathcal{E})
\coloneq\bigcap_{\mathcal{F}\in \mathcal{A}} \mathcal{F},\]</span> where
<span class="math inline">\(\mathcal{A} = \{\mathcal{F} \subset
2^{\Omega}: \mathcal{F}\text{ is a } \sigma\text{-algebra and }
\mathcal{E} \subset \mathcal{F}\}\)</span>. The family <span
class="math inline">\(\mathcal{E}\)</span> is called a
<em>generator</em> of <span
class="math inline">\(\sigma(\mathcal{E})\)</span>.</p>
</div>
<div class="exercise">
<p><em>Exercise 1.6</em>. Let <span
class="math inline">\(\Omega\)</span> be a countable set and <span
class="math inline">\(\mathcal{E} = \{\{\omega\}: \omega \in
\Omega\}\)</span>. Show that <span
class="math inline">\(\sigma(\mathcal{E}) =
2^{\mathcal{E}}\)</span>.</p>
</div>
<p>For our statistical purposes the by far most important <span
class="math inline">\(\sigma\)</span>-algebra is the Borel <span
class="math inline">\(\sigma\)</span>-algebra <span
class="math inline">\(\mathcal{B}(\mathbb{R})\)</span> over the real
numbers <span class="math inline">\(\mathbb{R}\)</span>, which is
defined as <span class="math display">\[\mathcal{B}(\mathbb{R})
\coloneq\sigma\big(\big\{O \subset \mathbb{R}: O \text{ open}\big\}
\big),\]</span> and we will always implicitly equip <span
class="math inline">\(\mathbb{R}\)</span> with this <span
class="math inline">\(\sigma\)</span>-algebra when considering it as a
measurable space. The Borel <span
class="math inline">\(\sigma\)</span>-algebra has the following simpler
characterisation.</p>
<div id="lem:borel_gen" class="lemma">
<p><strong>Lemma 1.7</strong>. <em>All of the following families of sets
are generators of <span
class="math inline">\(\mathcal{B}(\mathbb{R})\)</span>:</em></p>
<ol>
<li><p><em><span class="math inline">\(\mathcal{E}_1 = \{(a,b): -\infty
&lt; a \leq b &lt; \infty\}\)</span></em></p></li>
<li><p><em><span class="math inline">\(\mathcal{E}_2 = \{[a,b]: -\infty
&lt; a \leq b &lt; \infty\}\)</span></em></p></li>
<li><p><em><span class="math inline">\(\mathcal{E}_3 = \{(a,b]: -\infty
&lt; a \leq b &lt; \infty\}\)</span></em></p></li>
<li><p><em><span class="math inline">\(\mathcal{E}_4 = \{(-\infty,a): a
\in \mathbb{R}\}\)</span></em></p></li>
<li><p><em><span class="math inline">\(\mathcal{E}_5 = \{(-\infty,a]: a
\in \mathbb{R}\}\)</span></em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em> We only prove <span
class="math inline">\(\sigma(\mathcal{E}_1) =
\mathcal{B}(\mathbb{R})\)</span>, the remaining statements are left as
an exercise. Since any open interval <span
class="math inline">\((a,b)\)</span> is open in <span
class="math inline">\(\mathbb{R}\)</span> we have <span
class="math inline">\(\mathcal{E}_1 \subset \{O \subset \mathbb{R}: O
\text{ open}\}\)</span> and therefore <span
class="math display">\[\label{eq:gen1}
\sigma(\mathcal{E}_1) \subset \sigma\big(\big\{O \subset \mathbb{R}: O
\text{ open}\big\}\big) = \mathcal{B}(\mathbb{R}).\]</span> Conversely,
let <span class="math inline">\(O \subset \mathbb{R}\)</span> be an
arbitrary open set. Recall that <span class="math inline">\(O\)</span>
can then be written as a countable union of open intervals, that is, we
can find sequences <span class="math inline">\((a_n)_{n \in \mathbb{N}},
(b_n)_{n \in \mathbb{N}}\)</span> such that <span
class="math inline">\(O = \bigcup_{n \in \mathbb{N}} (a_n,b_n)\)</span>.
Since <span class="math inline">\((a_n,b_n) \in \mathcal{E}_1 \subset
\sigma(\mathcal{E}_1)\)</span> for all <span
class="math inline">\(n\)</span>, property (iii) of a <span
class="math inline">\(\sigma\)</span>-algebra implies that <span
class="math display">\[O = \bigcup_{n \in \mathbb{N}}
\underbrace{(a_n,b_n)}_{\in \sigma(\mathcal{E}_1)} \in
\sigma(\mathcal{E}_1).\]</span> Since <span
class="math inline">\(O\)</span> was chosen arbitrarily we conclude that
<span class="math display">\[\big\{O \subset \mathbb{R}: O \text{
open}\} \subset \sigma(\mathcal{E}_1),\]</span> and therefore also <span
class="math display">\[\label{eq:gen2}
\mathcal{B}(\mathbb{R}) = \sigma\big(\big\{O \subset \mathbb{R}: O
\text{ open}\big\}\big) \subset \sigma(\mathcal{E}_1).\]</span>
Combining <a href="#eq:gen1" data-reference-type="eqref"
data-reference="eq:gen1">[eq:gen1]</a> and <a href="#eq:gen2"
data-reference-type="eqref" data-reference="eq:gen2">[eq:gen2]</a> gives
the result. ◻</p>
</div>
<p>Now that we have understood what a <span
class="math inline">\(\sigma\)</span>-algebra is, let us move on to the
notion of a probability measure. We start a bit more general.</p>
<div class="definition">
<p><strong>Definition 1.8</strong>. A <em>measure</em> <span
class="math inline">\(\mu\)</span> on a measurable space <span
class="math inline">\((\Omega,\mathcal{F})\)</span> is a function <span
class="math inline">\(\mu\colon \mathcal{F} \to [0,\infty]\)</span> that
satisfies the following properties:</p>
<ol>
<li><p><span class="math inline">\(\mu(\varnothing) =
0\)</span></p></li>
<li><p>if <span class="math inline">\((A_n)_{n \in \mathbb{N}}\)</span>
is a pairwise disjoint sequence in <span
class="math inline">\(\mathcal{F}\)</span>, it holds that <span
class="math display">\[\mu\Big(\bigcup_{n \in \mathbb{N}} A_n \Big) =
\sum_{n \in \mathbb{N}} \mu(A_n)
\tag{$\sigma$\text{-additivity}}\]</span></p></li>
</ol>
<p>The measure <span class="math inline">\(\mu\)</span> is called</p>
<ol>
<li><p><em>finite</em>, if <span class="math inline">\(\mu(\Omega) &lt;
\infty\)</span></p></li>
<li><p><span class="math inline">\(\sigma\)</span><em>-finite</em>, if
there is a sequence <span class="math inline">\((A_n)_{n \in
\mathbb{N}}\)</span> in <span class="math inline">\(\mathcal{F}\)</span>
such that <span class="math inline">\(\Omega = \bigcup_{n \in
\mathbb{N}} A_n\)</span> and <span class="math inline">\(\mu(A_n) &lt;
\infty\)</span> for all <span class="math inline">\(n\)</span>.</p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 1.9</em>. Note that by taking <span
class="math inline">\(\varnothing = A_{n+1} = A_{n+2} = \cdots\)</span>
it follows from <span class="math inline">\(\sigma\)</span>-additivity
that for any finite, mutually disjoint collection <span
class="math inline">\(A_1,\ldots,A_n \in \mathcal{F}\)</span> we have
<span class="math inline">\(\mu(A_1 \cup \cdots \cup A_n) = \sum_{k=1}^n
\mu(A_k)\)</span>.</p>
</div>
<div class="definition">
<p><strong>Definition 1.10</strong>. A finite measure <span
class="math inline">\(\mathbb{P}\)</span> on a measurable space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is called
<em>probability measure</em> if <span
class="math inline">\(\mathbb{P}(\Omega) = 1\)</span>. The triplet <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is called
<em>probability space</em>.</p>
</div>
<div class="definition">
<p><strong>Definition 1.11</strong>. A probability distribution (or
simply distribution) is a probability measure on <span
class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span>.</p>
</div>
<div id="lem:prob_calc" class="lemma">
<p><strong>Lemma 1.12</strong>. <em>Let <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> be a
probability space and <span class="math inline">\(A,B \in
\mathcal{F}\)</span> be arbitrary events. Then,</em></p>
<ol>
<li><p><em>if <span class="math inline">\(A \subset B\)</span>, it holds
that <span class="math inline">\(\mathbb{P}(B\setminus A) =
\mathbb{P}(B)-\mathbb{P}(A)\)</span>. In particular, <span
class="math inline">\(\mathbb{P}(A^{\mathrm{c}}) = 1 -
\mathbb{P}(A)\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(\mathbb{P}(A \cup B) =
\mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)\)</span>. In
particular, <span class="math inline">\(\mathbb{P}(A \cup B) \leq
\mathbb{P}(A) + \mathbb{P}(B)\)</span>.</em></p></li>
<li><p><em>if <span class="math inline">\(A \subset B\)</span>, it holds
that <span class="math inline">\(\mathbb{P}(A) \leq
\mathbb{P}(B)\)</span>.</em></p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 1.13</em>. Analogous statements can be derived whenever we
deal more generally with a finite measure <span
class="math inline">\(\mu\)</span>. For infinite measures we need to be
a bit more careful. E.g., while it is always true that <span
class="math inline">\(\mu(A \cup B) \leq \mu(A) + \mu(B)\)</span>, we
can only make sense of <span class="math inline">\(\mu(A) + \mu(B) -
\mu(A \cap B)\)</span> if <span class="math inline">\(\mu(A \cap B) &lt;
\infty\)</span>, in which case indeed also <span
class="math inline">\(\mu(A \cup B) = \mu(A) + \mu(B) - \mu(A \cap
B)\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p><span class="math inline">\(A \subset B\)</span> implies <span
class="math inline">\(B = A \uplus (B\setminus A)\)</span>, whence by
<span class="math inline">\(\sigma\)</span>-additivity, <span
class="math inline">\(\mathbb{P}(B) = \mathbb{P}(B\setminus A) +
\mathbb{P}(A)\)</span>, or equivalently, <span
class="math inline">\(\mathbb{P}(B\setminus A) =
\mathbb{P}(B)-\mathbb{P}(A)\)</span>. Letting <span
class="math inline">\(B = \Omega\)</span>, we obtain from this <span
class="math display">\[\mathbb{P}(A^{\mathrm{c}}) = \mathbb{P}(\Omega
\setminus A) = \mathbb{P}(\Omega) - \mathbb{P}(A) = 1 -
\mathbb{P}(A).\]</span></p></li>
<li><p>Let <span class="math inline">\(C = A \cap B\)</span>. We can
write <span class="math inline">\(A \cup B = (A\setminus C) \uplus (B
\setminus C) \uplus C\)</span>, which gives (using <span
class="math inline">\(C \subset A, C \subset B\)</span> and <span
class="math inline">\(\sigma\)</span>-additivity) <span
class="math display">\[\begin{aligned}
\mathbb{P}(A \cup B) = \mathbb{P}(A \setminus C) + \mathbb{P}(B
\setminus C) + \mathbb{P}(C) &amp;\overset{(i)}{=} \mathbb{P}(A) -
\mathbb{P}(C) + \mathbb{P}(B) - \mathbb{P}(C) + \mathbb{P}(C)\\
&amp;=  \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(C)\\
&amp;= \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B).
\end{aligned}\]</span></p></li>
<li><p>immediate from (i) since <span class="math inline">\(\mathbb{P}(B
\setminus A) \geq 0\)</span>.</p></li>
</ol>
<p> ◻</p>
</div>
<div id="lem:meas_cont" class="lemma">
<p><strong>Lemma 1.14</strong> (Continuity of measures). <em>Let <span
class="math inline">\((\Omega,\mathcal{F},\mu)\)</span> be a measure
space.</em></p>
<ol>
<li><p><em>If <span class="math inline">\((A_n)_{n \in \mathbb{N}}
\subset \mathcal{F}\)</span> is an increasing sequence in the sense that
<span class="math inline">\(A_n \subset A_{n+1}\)</span> for all <span
class="math inline">\(n \in \mathbb{N}\)</span>, then <span
class="math display">\[\mu\Big(\bigcup_{n \in \mathbb{N}} A_n \Big) =
\lim_{n \to \infty} \mu(A_n).\]</span></em></p></li>
<li><p><em>If <span class="math inline">\((A_n)_{n \in \mathbb{N}}
\subset \mathcal{F}\)</span> is a decreasing sequence in the sense that
<span class="math inline">\(A_n \supset A_{n+1}\)</span> for all <span
class="math inline">\(n \in \mathbb{N}\)</span>, and moreover <span
class="math inline">\(\mu(A_1) &lt; \infty\)</span>, then <span
class="math display">\[\mu\Big(\bigcap_{n \in \mathbb{N}} A_n \Big) =
\lim_{n \to \infty} \mu(A_n).\]</span></em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em> See Appendix <a href="#chap:app"
data-reference-type="ref" data-reference="chap:app">7</a>. ◻</p>
</div>
<p>Of special interest to us will be the following measures on <span
class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span>,
which are in a certain sense on opposite ends of the spectrum. The
<em>Lebesgue measure</em> <span class="math inline">\(\lambda\)</span>
is the unique measure that satisfies <span
class="math display">\[\lambda((a,b]) = b - a, \quad -\infty &lt; a \leq
b &lt; \infty,\]</span> and therefore assigns a volume to any set in
<span class="math inline">\(\mathcal{B}(\mathbb{R})\)</span> that we
would consider as natural based on our physical perception of the world.
The <em>Dirac measure</em> <span class="math inline">\(\delta_x\)</span>
at a point <span class="math inline">\(x \in \mathbb{R}\)</span> is
defined as <span class="math display">\[\delta_x(A) = \begin{cases} 1,
&amp; x \in A\\ 0, &amp; x \notin A,\end{cases}\]</span> i.e., it is a
point mass that assigns unit volume to a measurable set <span
class="math inline">\(A\)</span> iff <span class="math inline">\(x \in
A\)</span>. In particular we have <span
class="math inline">\(\delta_x(\{x\}) = 1 =
\delta_x(\mathbb{R})\)</span>, so that <span
class="math inline">\(\delta_x\)</span> is our first example of a
probability measure. Conversely to this, for the Lebesgue measure it
holds <span class="math display">\[\lambda(\{x\}) =
\lambda\Big(\bigcap_{n \in \mathbb{N}} (x-1/n,x+1/n]\Big) = \lim_{n \to
\infty} \lambda((x-1/n,x+1/n]) = \lim_{n \to \infty} \frac{2}{n} =
0.\]</span> For the the second equality we used continuity of measures
from Lemma <a href="#lem:meas_cont" data-reference-type="ref"
data-reference="lem:meas_cont">1.14</a>. This means that any singleton
<span class="math inline">\(\{x\}\)</span> is a <em>nullset</em> for the
Lebesgue measure according to the next definition.</p>
<div class="definition">
<p><strong>Definition 1.15</strong>. Let <span
class="math inline">\(\mu\)</span> be a measure on some measurable space
<span class="math inline">\((\Omega,\mathcal{F})\)</span>. A set <span
class="math inline">\(N \in \mathcal{F}\)</span> such that <span
class="math inline">\(\mu(N) = 0\)</span> is called a <span
class="math inline">\(\mu\)</span>-nullset. If some property holds for
all <span class="math inline">\(\omega \in \Omega \setminus N\)</span>,
where <span class="math inline">\(N\)</span> is a <span
class="math inline">\(\mu\)</span>-nullset, we say that this property
holds <span class="math inline">\(\mu\)</span>-almost everywhere (<span
class="math inline">\(\mu\)</span>-a.e.). If <span
class="math inline">\(\mu\)</span> is a probability measure we say
instead <span class="math inline">\(\mu\)</span>-almost surely (<span
class="math inline">\(\mu\)</span>-a.s.).</p>
</div>
<div class="exercise">
<p><em>Exercise 1.16</em>. Show the following:</p>
<ol>
<li><p>If <span class="math inline">\(\mathbb{P}_1,\mathbb{P}_2\)</span>
are probability measures and <span
class="math inline">\(\lambda_1,\lambda_2 \geq 0\)</span>, then <span
class="math inline">\(\lambda_1 \mathbb{P}_1 + \lambda_2
\mathbb{P}_2\)</span> is a probability measure iff <span
class="math inline">\(\lambda_1+ \lambda_2 = 1\)</span>.</p></li>
<li><p>For any <span class="math inline">\(a,b \in \mathbb{R}\)</span>
such that <span class="math inline">\(a &lt; b\)</span> it holds that
<span class="math display">\[\lambda([a,b]) = \lambda([a,b)) =
\lambda((a,b]) = \lambda((a,b)).\]</span></p></li>
<li><p>The Lebesgue measure <span class="math inline">\(\lambda\)</span>
is <span class="math inline">\(\sigma\)</span>-finite but not
finite.</p></li>
</ol>
</div>
<h2 id="independence-and-conditional-probability">Independence and
Conditional Probability</h2>
<p>Throughout this section we fix a probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>.</p>
<div class="definition">
<p><strong>Definition 1.17</strong> (Independence). Two events <span
class="math inline">\(A,B \in \mathcal{F}\)</span> are defined to be
<em>independent</em> if <span class="math display">\[\mathbb{P}(A \cap
B) = \mathbb{P}(A)\mathbb{P}(B).\]</span></p>
</div>
<div class="example">
<p><em>Example 1.18</em>. Let the probability space from Example <a
href="#ex:prob_model" data-reference-type="ref"
data-reference="ex:prob_model">1.1</a> be given. Consider the events
<span class="math inline">\(A = \{HT,HH\} \triangleq \text{``heads
appears in first throw&#39;&#39;}\)</span> and <span
class="math inline">\(B = \{HT,TT\} \triangleq \text{``tails appears in
second throw&#39;&#39;}\)</span>. Then <span
class="math display">\[\mathbb{P}(A \cap B) = \{HT\} = 1/4 = \frac{1}{2}
\cdot \frac{1}{2} = \mathbb{P}(\{HT,HH\})\mathbb{P}(\{HT,TT\}) =
\mathbb{P}(A)\mathbb{P}(B),\]</span> so <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> are independent.</p>
</div>
<div class="definition">
<p><strong>Definition 1.19</strong> (Conditional Probability). Let <span
class="math inline">\(A \in \mathcal{F}\)</span> s.t. <span
class="math inline">\(\mathbb{P}(A) &gt; 0\)</span>. The conditional
probability <span class="math inline">\(\mathbb{P}(\cdot \mid
A)\)</span> on <span class="math inline">\((\Omega,\mathcal{F})\)</span>
is defined by <span class="math display">\[\mathbb{P}(B \mid A) =
\frac{\mathbb{P}(A \cap B)}{\mathbb{P}(A)}, \quad \forall B \in
\mathcal{F},\]</span> and we call <span
class="math inline">\(\mathbb{P}(B\mid A)\)</span> the <em>conditional
probability of <span class="math inline">\(B\)</span> given <span
class="math inline">\(A\)</span></em>.</p>
</div>
<p>The definition entails that if <span
class="math inline">\(\mathbb{P}(A) &gt; 0\)</span>, an event <span
class="math inline">\(B \in \mathcal{F}\)</span> is independent of <span
class="math inline">\(A\)</span>, iff <span
class="math inline">\(\mathbb{P}(B \mid A) = \mathbb{P}(B)\)</span>.</p>
<div class="proposition">
<p><strong>Proposition 1.20</strong>. <em>The conditional probability
<span class="math inline">\(\mathbb{P}(\cdot \mid A)\)</span> is a
probability measure on <span
class="math inline">\((\Omega,\mathcal{F})\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> We need to show that (i) <span
class="math inline">\(\mathbb{P}(\varnothing \mid A) = 0\)</span>, (ii)
<span class="math inline">\(\mathbb{P}(\Omega \mid A) = 1\)</span> and
(iii) for pairwise disjoint events <span class="math inline">\((A_n)_{n
\in \mathbb{N}}\)</span> in <span
class="math inline">\(\mathcal{F}\)</span> we have <span
class="math inline">\(\mathbb{P}(\bigcup_n A_n \mid A) = \sum_n
\mathbb{P}(A_n \mid A)\)</span>. (i) is clear because <span
class="math inline">\(A \cap \varnothing = \varnothing\)</span>. Since
<span class="math inline">\(\Omega \cap A = A\)</span>, it also follows
<span class="math display">\[\mathbb{P}(\Omega \mid A) =
\frac{\mathbb{P}(\Omega \cap A)}{\mathbb{P}(A)} =
\frac{\mathbb{P}(A)}{\mathbb{P}(A)} = 1,\]</span> which establishes
(ii). For (iii), note that we have <span class="math inline">\(A \cap
\bigcup_n A_n = \bigcup_n (A_n \cap A)\)</span> and since <span
class="math inline">\((A_n)_n\)</span> are pairwise disjoint, the same
remains true for <span class="math inline">\((A_n \cap A)_n\)</span>.
Thus, <span class="math inline">\(\sigma\)</span>-additivity of <span
class="math inline">\(\mathbb{P}\)</span> yields <span
class="math display">\[\mathbb{P}\big(\bigcup_{n \in \mathbb{N}} A_n
\mid A\big) = \frac{\mathbb{P}\big(\bigcup_{n \in \mathbb{N}} (A_n \cap
A)\big)}{\mathbb{P}(A)} = \sum_{n \in \mathbb{N}} \frac{\mathbb{P}(A_n
\cap A)}{\mathbb{P}(A)} = \sum_{n \in \mathbb{N}} \mathbb{P}(A_n \mid
A).\]</span> ◻</p>
</div>
<div class="theorem">
<p><strong>Theorem 1.21</strong> (Bayes’ formula). <em>Let <span
class="math inline">\(A,B \in \mathcal{F}\)</span> such that <span
class="math inline">\(\mathbb{P}(A),\mathbb{P}(B) &gt; 0\)</span>. Then,
for any <span class="math inline">\(B \in \mathcal{F}\)</span>, <span
class="math display">\[\overbrace{\mathbb{P}(B \mid
A)}^{\text{posterior}} = \frac{\mathbb{P}(A \mid B)
\overbrace{\mathbb{P}(B)}^{\text{prior}}}{\mathbb{P}(A)} =
\frac{\mathbb{P}(A \mid B) \mathbb{P}(B)}{\mathbb{P}(A \mid
B)\mathbb{P}(B) + \mathbb{P}(A \mid
B^{\mathrm{c}})\mathbb{P}(B^{\mathrm{c}})}.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> We have <span class="math inline">\(\mathbb{P}(A \mid
B) = \mathbb{P}(A \cap B)/\mathbb{P}(B)\)</span>, or equivalently, <span
class="math inline">\(\mathbb{P}(A \cap B) = \mathbb{P}(A \mid B)
\mathbb{P}(B)\)</span>. Plugging this expression for <span
class="math inline">\(\mathbb{P}(A \cap B)\)</span> into <span
class="math inline">\(\mathbb{P}(A \mid B) = \mathbb{P}(A \cap
B)/\mathbb{P}(B)\)</span> gives the first stated equality. The second
one follows from the first after decomposing <span
class="math inline">\(A = (A \cap B) \uplus (A \cap
B^{\mathrm{c}})\)</span>, which gives <span
class="math display">\[\begin{aligned}
\mathbb{P}(A) &amp;= \mathbb{P}(A \cap B) + \mathbb{P}(A \cap
B^{\mathrm{c}}) \tag{\text{law of total probability}}\\
&amp;= \mathbb{P}(A \mid B) \mathbb{P}(B) + \mathbb{P}(A \mid
B^{\mathrm{c}}) \mathbb{P}(B^{\mathrm{c}}) \tag{\text{partition
formula}}
\end{aligned}\]</span> ◻</p>
</div>
<div class="example">
<p><em>Example 1.22</em>. A doping test is performed after a football
match. The league is just a little bit crooked this year so that <span
class="math inline">\(0.5\%\)</span> of the players are doped. Moreover,
the test detects a doped player with <span
class="math inline">\(95\%\)</span> accuracy, but is also positive in
<span class="math inline">\(1\%\)</span> of the cases when a non-doped
player is tested (<em>false positive</em>). Let us calculate the
probability that a player has actually doped if the test returns
positive: if we let <span class="math inline">\(A = \text{``test
positive&#39;&#39;}\)</span> and <span class="math inline">\(B =
\text{``player is doped&#39;&#39;}\)</span>, then <span
class="math inline">\(\mathbb{P}(B) = 0.005\)</span>, <span
class="math inline">\(\mathbb{P}(A \mid B) = 0.95\)</span> and <span
class="math inline">\(\mathbb{P}(A \mid B^{\mathrm{c}}) = 0.01\)</span>.
Thus, using Bayes’ formula <span
class="math display">\[\mathbb{P}(\underbrace{B \mid
A}_{\mathclap{\text{``player is doped given that test is
positive&#39;&#39;}}}) = \frac{\mathbb{P}(A \mid B)
\mathbb{P}(B)}{\mathbb{P}(A \mid B)\mathbb{P}(B) + \mathbb{P}(A \mid
B^{\mathrm{c}})\mathbb{P}(B^{\mathrm{c}})} = \frac{0.95 \cdot
0.005}{0.95 \cdot 0.005 + 0.01 \cdot (1 - 0.005)} = \frac{0.95}{2.94}
\approx 0.32.\]</span> This is why in sports there is always a B-sample
taken.</p>
</div>
<h1 id="chap:rv">Random variables</h1>
<h2 id="random-variables-and-their-distributions">Random variables and
their distributions</h2>
<h3 id="measurability">Measurability</h3>
<div class="definition">
<p><strong>Definition 2.1</strong>. Let <span
class="math inline">\((E,\mathcal{A})\)</span> be a measurable space. A
function <span class="math inline">\(f\colon E \to \mathbb{R}\)</span>
is called <em>measurable</em> if for any <span class="math inline">\(A
\in \mathcal{B}(\mathbb{R})\)</span> it holds that <span
class="math inline">\(f^{-1}(A) \in \mathcal{A}\)</span>.</p>
</div>
<p>This definition appears rather cumbersome at first sight, since <span
class="math inline">\(\sigma\)</span>-algebras such as <span
class="math inline">\(\mathcal{B}(\mathbb{R})\)</span> are too
complicated to check the measurability condition by hand in most
circumstances. Fortunately, we can reduce this often impossible task by
just checking the preimage condition for generating sets of the Borel
<span class="math inline">\(\sigma\)</span>-algebra, that is open sets
or – even simpler – families of intervals as established in Lemma <a
href="#lem:borel_gen" data-reference-type="ref"
data-reference="lem:borel_gen">1.7</a>. The formal statement is the
following.</p>
<div id="prop:meas_gen" class="proposition">
<p><strong>Proposition 2.2</strong>. <em>Let <span
class="math inline">\((E,\mathcal{A})\)</span> be a measurable space and
let <span class="math inline">\(\mathcal{E}\)</span> be a generator of
<span class="math inline">\(\mathcal{B}(\mathbb{R})\)</span>, i.e.,
<span class="math inline">\(\mathcal{B}(\mathbb{R}) =
\sigma(\mathcal{E})\)</span>. Then, a function <span
class="math inline">\(f \colon E \to \mathbb{R}\)</span> is measurable
if, and only if, <span class="math inline">\(f^{-1}(\mathcal{E}) \subset
\mathcal{A}\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> We skip the proof in the lecture. The proof is
however quite enlightening, as it contains a powerful idea that is
commonly applied in measure theory. I highly recommend to have a look at
it in Appendix <a href="#chap:app" data-reference-type="ref"
data-reference="chap:app">7</a>. ◻</p>
</div>
<div class="example">
<p><em>Example 2.3</em>. </p>
<ol>
<li><p>Let <span class="math inline">\((E,\mathcal{A})\)</span> be a
measurable space and define the <em>indicator function</em> of a set
<span class="math inline">\(A \in \mathcal{A}\)</span> as <span
class="math display">\[\bm{1}_A\colon E \to \mathbb{R}, \quad x \mapsto
\begin{cases} 1, &amp; x \in A,\\0, &amp;x \notin A.\end{cases}\]</span>
For any set <span class="math inline">\(B \in
\mathcal{B}(\mathbb{R})\)</span> we have <span
class="math display">\[\bm{1}_A^{-1}(B) = \{x \in E: \bm{1}_A(x) \in B\}
= \begin{cases} A, &amp; 1 \in B, 0 \notin B,\\ A^{\mathrm{c}}, &amp;0
\in B, 1 \notin B,\\ E, &amp; 0,1\in B\\ \varnothing, &amp;0,1 \notin
B,\end{cases}\]</span> which shows <span
class="math inline">\(\bm{1}_A^{-1}(B) \in \mathcal{A}\)</span> <span
class="math inline">\(\implies\)</span> <span
class="math inline">\(\bm{1}_A\)</span> is measurable.</p></li>
<li><p>Any continuous function <span class="math inline">\(f\colon
\mathbb{R}\to \mathbb{R}\)</span> is measurable: Let <span
class="math inline">\(O \subset \mathbb{R}\)</span> be open. By
continuity <span class="math inline">\(f^{-1}(O)\)</span> is open as
well and since <span
class="math inline">\(\mathcal{B}(\mathbb{R})\)</span> is generated by
open sets, this shows that <span class="math inline">\(f^{-1}(O) \in
\mathcal{B}(\mathbb{R})\)</span>. By Proposition <a
href="#prop:meas_gen" data-reference-type="ref"
data-reference="prop:meas_gen">2.2</a> this is sufficient to prove
measurability.</p></li>
</ol>
</div>
<p>Measurable functions are well-behaved under the usual analytic
manipulations. We just record here a couple of important properties
properties without proof (if you would like to try to prove some of
these, Proposition <a href="#prop:meas_gen" data-reference-type="ref"
data-reference="prop:meas_gen">2.2</a> is very helpful).</p>
<div id="lem:meas_manip" class="lemma">
<p><strong>Lemma 2.4</strong>. <em>Let <span
class="math inline">\((E,\mathcal{A})\)</span> be a measurable
space.</em></p>
<ol>
<li><p><em>If <span class="math inline">\(f,g\)</span> are measurable
functions on <span class="math inline">\((E,\mathcal{A})\)</span>, then
<span class="math inline">\(f+g\)</span> and <span
class="math inline">\(f \cdot g\)</span> are also
measurable.</em></p></li>
<li><p><em>If <span class="math inline">\(f \colon E \to
\mathbb{R}\)</span> and <span class="math inline">\(g\colon
\mathbb{R}\to \mathbb{R}\)</span> are measurable, so is there
composition <span class="math inline">\(g \circ
f\)</span>.</em></p></li>
<li><p><em>Let <span class="math inline">\((f_n)_{n \in
\mathbb{N}}\)</span> be a sequence of measurable functions mapping from
<span class="math inline">\(E\)</span> to <span
class="math inline">\(\mathbb{R}\)</span> such that there exists a
function <span class="math inline">\(f\colon E \to \mathbb{R}\)</span>
for which the pointwise convergence <span class="math inline">\(\lim_{n
\to \infty} f_n(x) = f(x)\)</span> holds for any <span
class="math inline">\(x \in E\)</span>. Then, <span
class="math inline">\(f\)</span> is measurable.</em></p></li>
</ol>
</div>
<h3
id="definition-of-random-variables-and-their-distributions">Definition
of random variables and their distributions</h3>
<div class="definition">
<p><strong>Definition 2.5</strong>. A random variable on a probability
space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is a
measurable mapping <span class="math inline">\(X\colon \Omega \to
\mathbb{R}\)</span>, i.e., <span class="math inline">\(X^{-1}(A) \in
\mathcal{F}\)</span> for any <span class="math inline">\(A \in
\mathcal{B}(\mathbb{R})\)</span>.</p>
</div>
<div class="remark">
<p><em>Remark 2.6</em>. In the following we will use the notation <span
class="math inline">\(\{X \in A\} \coloneq X^{-1}(A)\)</span>, which is
motivated from the definition of the preimage <span
class="math inline">\(X^{-1}(A) = \{\omega \in \Omega: X(\omega) \in
A\}\)</span>. A random variable is therefore a mapping from the sample
space <span class="math inline">\(\Omega\)</span> into the real numbers
such that for any measurable set <span class="math inline">\(A\)</span>
in <span class="math inline">\(\mathbb{R}\)</span> the preimage <span
class="math inline">\(\{X \in A\}\)</span> is a proper event on the
probability space.</p>
</div>
<p>Since random variables are nothing else but measurable mappings in
the context of probability spaces, we may recast Lemma <a
href="#lem:meas_manip" data-reference-type="ref"
data-reference="lem:meas_manip">2.4</a> probabilistically.</p>
<div id="lem:rv_manip" class="lemma">
<p><strong>Lemma 2.7</strong>. <em>Let <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> be a
probability space.</em></p>
<ol>
<li><p><em>If <span class="math inline">\(X,Y\)</span> are random
variables, then also <span class="math inline">\(X+Y\)</span> and <span
class="math inline">\(X\cdot Y\)</span> are random
variables.</em></p></li>
<li><p><em>If <span class="math inline">\(X\)</span> is a random
variable and <span class="math inline">\(g\colon \mathbb{R}\to
\mathbb{R}\)</span> is measurable, then <span class="math inline">\(Y =
g(X)\)</span> is also a random variable.</em></p></li>
<li><p><em>Let <span class="math inline">\((X_n)_{n \in
\mathbb{N}}\)</span> be a sequence of random variables such that there
exists <span class="math inline">\(X\colon \Omega \to
\mathbb{R}\)</span> for which the pointwise convergence <span
class="math inline">\(\lim_{n \to \infty} X_n(\omega) =
X(\omega)\)</span> holds for any <span class="math inline">\(\omega \in
\Omega\)</span>. Then, <span class="math inline">\(X\)</span> is also a
random variable.</em></p></li>
</ol>
</div>
<div class="definition">
<p><strong>Definition 2.8</strong>. The distribution <span
class="math inline">\(\mathbb{P}_X\colon \mathcal{B}(\mathbb{R}) \to
[0,1]\)</span> of a random variable <span
class="math inline">\(X\)</span> on a probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is
defined by <span class="math display">\[\mathbb{P}_X(B) =
\mathbb{P}(X^{-1}(B)), \quad B \in \mathcal{B}(\mathbb{R}).\]</span></p>
</div>
<div class="remark">
<p><em>Remark 2.9</em>. Analogously to before, we write interchangeably
<span class="math display">\[\mathbb{P}_X(B) = \mathbb{P}(X^{-1}(B)) =
\mathbb{P}(\{X \in B\}) = \mathbb{P}(X \in B).\]</span> For an interval
<span class="math inline">\([a,b]\)</span> we also write <span
class="math inline">\(\mathbb{P}(X \in [a,b]) = \mathbb{P}(a \leq X \leq
b)\)</span> with analogous conventions for open and half-open intervals.
We also use the shorthand <span class="math inline">\(\mathbb{P}(X \in
(-\infty,x]) = \mathbb{P}(X \leq x)\)</span> and write <span
class="math inline">\(\mathbb{P}(X \in A, X \in B) = \mathbb{P}(\{X \in
A\} \cap \{X \in B\})\)</span>, <span
class="math inline">\(\mathbb{P}(\{X \in A\} \mid \{X \in B\}) =
\mathbb{P}(X \in A \mid X \in B)\)</span> for <span
class="math inline">\(A,B \in \mathcal{B}(\mathbb{R})\)</span>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 2.10</strong>. <em>Let <span
class="math inline">\(X\)</span> be a random variable on <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Its
distribution <span class="math inline">\(\mathbb{P}_X\)</span> is a
probability measure on <span
class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p><span class="math inline">\(\mathbb{P}_X(\varnothing) =
\mathbb{P}(X^{-1}(\varnothing)) = \mathbb{P}(\varnothing) =
0\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbb{P}_X(\mathbb{R}) =
\mathbb{P}(X^{-1}(\mathbb{R})) = \mathbb{P}(\Omega) =
1\)</span>.</p></li>
<li><p>It is easily checked that for a pairwise disjoint sequence <span
class="math inline">\((A_n)_{n \in \mathbb{N}} \subset
\mathcal{B}(\mathbb{R})\)</span>, the sequence <span
class="math inline">\((X^{-1}(A_n))_{n \in \mathbb{N}}\)</span> is also
disjoint and by measurability of <span class="math inline">\(X\)</span>
it is a sequence in <span class="math inline">\(\mathcal{F}\)</span>.
Consequently, <span class="math display">\[\begin{aligned}
\mathbb{P}_X\Big(\bigcup_{n \in \mathbb{N}} A_n\Big) &amp;=
\mathbb{P}\Big(X^{-1}\Big(\bigcup_{n \in \mathbb{N}} A_n \Big) \Big)\\
&amp;= \mathbb{P}\Big(\bigcup_{n \in \mathbb{N}}X^{-1}( A_n) \Big)\\
&amp;= \sum_{n \in \mathbb{N}} \mathbb{P}(X^{-1}(A_n))\\
&amp;= \sum_{n \in \mathbb{N}} \mathbb{P}_X(A_n),
\end{aligned}\]</span> where we used <span
class="math inline">\(\sigma\)</span>-additivity of <span
class="math inline">\(\mathbb{P}\)</span> for the third line.</p></li>
</ol>
<p> ◻</p>
</div>
<div id="def:discrete" class="definition">
<p><strong>Definition 2.11</strong>. A random variable <span
class="math inline">\(X\)</span> is called <em>discrete</em> if there
exists <span class="math inline">\(N \in \mathbb{N}\cup
\{\infty\}\)</span>, weights <span class="math inline">\(p_1,\ldots,p_N
\geq 0\)</span> and points <span class="math inline">\(x_1,\ldots,x_N
\in \mathbb{R}\)</span> (both interpreted as sequences if <span
class="math inline">\(N = \infty)\)</span> such that <span
class="math inline">\(\sum_{k=1}^N p_k = 1\)</span> and <span
class="math display">\[\mathbb{P}_X = \sum_{k=1}^N p_k
\delta_{x_k}.\]</span> We call <span class="math display">\[f_X(x) =
\mathbb{P}_X(\{x\}) = \mathbb{P}(X = x) = \sum_{k=1}^N p_k \bm{1}_{\{
x_k\}}(x), \quad x \in \mathbb{R},\]</span> either the <em>discrete
density function</em> or <em>probability mass function (pmf)</em>.</p>
</div>
<div id="ex:coin_toss" class="example">
<p><em>Example 2.12</em>. Consider a simple coin toss with probability
of heads equal to <span class="math inline">\(p \in [0,1]\)</span>. We
may model <span class="math inline">\(\Omega = \{H,T\}, \mathcal{F}=
2^\Omega = \{\{H\},\{T\},\{H,T\},\varnothing\}\)</span> and <span
class="math inline">\(\mathbb{P}(\{H\}) = p\)</span> and then set <span
class="math inline">\(X(H) = 1\)</span>, <span
class="math inline">\(X(T) = 0\)</span>. The corresponding distribution
<span class="math inline">\(\mathbb{P}_X\)</span> can then be written as
<span class="math display">\[\mathbb{P}_X = p\delta_0 +
(1-p)\delta_1,\]</span> and we call <span
class="math inline">\(\mathbb{P}_X\)</span> a <em>Bernoulli
distribution</em> with success rate <span
class="math inline">\(p\)</span>. Alternatively, we can start with <span
class="math inline">\(\mathbb{P}_X\)</span> as above and use it as a
distributional model for the coin toss experiment with random outcome
<span class="math inline">\(X\)</span> directly, without specifying the
underlying probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>.<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> The latter modelling approach is
particularly useful in situations, where a random phenomenon is far too
complex to allow an explicit construction of the underlying probability
space (think of a stock price for example) and is therefore the
appropriate one for our statistical purposes.</p>
</div>
<div class="definition">
<p><strong>Definition 2.13</strong>. The distribution function <span
class="math inline">\(F_X\colon \mathbb{R}\to [0,1]\)</span> of a random
variable <span class="math inline">\(X\)</span> on a probability space
<span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is
defined by <span class="math display">\[F_X(x) =
\mathbb{P}_X((-\infty,x]) = \mathbb{P}(X \leq x),\quad x \in
\mathbb{R}.\]</span></p>
</div>
<div class="remark">
<p><em>Remark 2.14</em>. Distribution functions are often also called
<em>cumulative distributions functions</em>, abbreviated as
<em>cdf</em>; we shall use this abbreviation from here on.</p>
</div>
<div class="exercise">
<p><em>Exercise 2.15</em>. </p>
<ol>
<li><p>Sketch the cdf from Example <a href="#ex:coin_toss"
data-reference-type="ref" data-reference="ex:coin_toss">2.12</a> for
<span class="math inline">\(p=1/4\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(\mathbb{P}(X \in (a,b]) =
F(b) - F(a)\)</span> for all <span
class="math inline">\(a&lt;b\)</span>.</p></li>
</ol>
</div>
<p>Distribution functions play a special role because they are much
simpler objects compared to distributions (function vs. measure), but
are sufficient to fully characterise the distribution.</p>
<div id="theo:chara_cdf" class="theorem">
<p><strong>Theorem 2.16</strong>. <em>Let <span
class="math inline">\(\mathbb{P}_X\)</span> and <span
class="math inline">\(\mathbb{P}_Y\)</span> be two distributions. Then,
<span class="math inline">\(\mathbb{P}_X = \mathbb{P}_Y\)</span> (that
is, <span class="math inline">\(\mathbb{P}_X(B) =
\mathbb{P}_Y(B)\)</span> for all <span class="math inline">\(B \in
\mathcal{B}(\mathbb{R}\)</span>)) if, and only if, <span
class="math inline">\(F_X = F_Y\)</span> (that is, <span
class="math inline">\(F_X(x) = F_Y(x)\)</span> for all <span
class="math inline">\(x \in \mathbb{R}\)</span>).</em></p>
</div>
<div class="proof">
<p><em>Proof (Sketch).</em> Generally, the following can be shown to be
true: If <span class="math inline">\(\mathbb{P}\)</span>, <span
class="math inline">\(\mathbb{Q}\)</span> are two probability measures
with underlying <span class="math inline">\(\sigma\)</span>-algebra
<span class="math inline">\(\mathcal{F}\)</span> generated by a <span
class="math inline">\(\cap\)</span>-stable family of sets <span
class="math inline">\(\mathcal{E}\)</span>, i.e., <span
class="math inline">\(\mathcal{F}= \sigma(\mathcal{E})\)</span> and
<span class="math inline">\(A \cap B \in \mathcal{E}\)</span> if <span
class="math inline">\(A,B \in \mathcal{E}\)</span>, then <span
class="math inline">\(\mathbb{P}= \mathbb{Q}\)</span> iff <span
class="math inline">\(\mathbb{P}(B) = \mathbb{Q}(B)\)</span> for all
<span class="math inline">\(B \in \mathcal{E}\)</span>. Here, we have
<span class="math inline">\(\mathcal{B}(\mathbb{R}) =
\sigma(\mathcal{E})\)</span> for <span class="math inline">\(\mathcal{E}
= \{(\infty,x]: x \in \mathbb{R}\}\)</span>, see Lemma <a
href="#lem:borel_gen" data-reference-type="ref"
data-reference="lem:borel_gen">1.7</a>, and <span
class="math inline">\(\mathcal{E}\)</span> is <span
class="math inline">\(\cap\)</span>-stable since <span
class="math inline">\((-\infty,x] \cap (-\infty, y] = (-\infty,x\wedge
y]\)</span>. Hence, <span class="math inline">\(\mathbb{P}_X =
\mathbb{P}_Y\)</span> iff <span class="math display">\[\forall x \in
\mathbb{R}: \quad \underbrace{\mathbb{P}_X((-\infty,x])}_{= F_X(x)} =
\underbrace{\mathbb{P}_Y((-\infty,x])}_{= F_Y(x)}.\]</span> ◻</p>
</div>
<div class="proposition">
<p><strong>Proposition 2.17</strong> (Properties of a cdf). <em>A cdf
<span class="math inline">\(F_X\)</span> has the following
properties</em></p>
<ol>
<li><p><em><span class="math inline">\(x \mapsto F_X(x)\)</span> is
non-decreasing;</em></p></li>
<li><p><em><span class="math inline">\(\lim_{x \to -\infty} F_X(x) =
0\)</span> and <span class="math inline">\(\lim_{x \to \infty} F_X(x) =
1\)</span>;</em></p></li>
<li><p><em><span class="math inline">\(x \mapsto F_X(x)\)</span> is
right-continuous with left limits, i.e., for any <span
class="math inline">\(a \in \mathbb{R}\)</span>, <span
class="math inline">\(\lim_{x \uparrow a} F(x)\)</span> exists and <span
class="math inline">\(\lim_{x \downarrow a} F_X(x) =
F(a)\)</span>.</em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p>For <span class="math inline">\(x &lt; y\)</span> we have <span
class="math inline">\((-\infty,x] \subset (-\infty,y]\)</span> and hence
by Lemma <a href="#lem:prob_calc" data-reference-type="ref"
data-reference="lem:prob_calc">1.12</a> <span
class="math inline">\(F_X(x) = \mathbb{P}_X((-\infty,x]) \leq
\mathbb{P}_X((-\infty,y]) = F(y)\)</span>.</p></li>
<li><p>By the just established monotonicity and boundedness of <span
class="math inline">\(F_X\)</span>, both limits exist and it is enough
to check <span class="math inline">\(\lim_{n \to\infty} F_X(-n) =
0\)</span> and <span class="math inline">\(\lim_{n \to \infty} F_X(n) =
1\)</span>. We only show the first claim, the second is left as an
exercise: <span class="math inline">\(((-\infty,-n])_{n \in
\mathbb{N}}\)</span> is a decreasing sequence, so continuity of measures
from Lemma <a href="#lem:meas_cont" data-reference-type="ref"
data-reference="lem:meas_cont">1.14</a> gives <span
class="math display">\[\lim_{n \to \infty} F_X(-n) =
\mathbb{P}_X\Big(\bigcap_{n \in \mathbb{N}} (-\infty,-n]\Big) =
\mathbb{P}_X(\varnothing) = 0.\]</span></p></li>
<li><p>Existence of left limits is a consequence of <span
class="math inline">\(F_X\)</span> being increasing and bounded.
Right-continuity can again be proven with continuity of measures (try
it!).</p></li>
</ol>
<p> ◻</p>
</div>
<h2
id="continuous-distributions-and-a-very-short-sketch-of-integration-theory">Continuous
distributions and a very short sketch of integration theory</h2>
<p>In Definition <a href="#def:discrete" data-reference-type="ref"
data-reference="def:discrete">2.11</a> we have already encountered
discrete distributions that place probability mass on single points
only. In undergrad probability modules you will also have encountered
continuous distributions, which are defined via the cdf as follows: a
random variable <span class="math inline">\(X\)</span> is continuous if
its cdf is given by <span class="math display">\[F_X(x) =
\int_{-\infty}^x f(y) \mathop{}\!\mathrm{d} {y}\]</span> for a
probability density function <span class="math inline">\(f\colon
\mathbb{R}\to \mathbb{R}\)</span>, which is nice enough for the above
integral to be well-defined as a Riemann integral. This gives rise to
formulas such as <span class="math display">\[\mathbb{P}(a \leq X \leq
b) = \int_{a}^b f(y) \mathop{}\!\mathrm{d} {y} = \int_{[a,b]} f(y)
\mathop{}\!\mathrm{d} {y},\]</span> so that we are tempted to define the
corresponding distribution as <span
class="math display">\[\mathbb{P}_X(B) = \int_B f(y)
\mathop{}\!\mathrm{d} {y}, \quad B \in \mathcal{B}(\mathbb{R}).\]</span>
However, the meaning of such an integral in the sense of Riemann is
unclear if the set <span class="math inline">\(B\)</span> is not as nice
as an interval (say <span class="math inline">\(B =
\mathbb{Q}\)</span>). We therefore need a different notion of an
integral, which is the <em>Lebesgue integral</em>.</p>
<h3 id="lebesgue-integral">Lebesgue integral</h3>
<p>We let <span class="math inline">\((E,\mathcal{A},\mu)\)</span> again
be a general space. Integrals are supposed to calculate volumes or areas
enclosed by functions. We have already interpreted <span
class="math inline">\(\mu(A)\)</span> as the volume of a set <span
class="math inline">\(A \in \mathcal{A}\)</span>, which may be
interpreted as well as an integral of the indicator <span
class="math inline">\(\bm{1}_A\)</span> w.r.t. the measure <span
class="math inline">\(\mu\)</span>. So, given some scalar <span
class="math inline">\(\alpha \geq 0\)</span> it is natural for the
function <span class="math display">\[f(x) = \alpha \bm{1}_{A}(x), \quad
x \in A,\]</span> to assign the scaled volume <span
class="math inline">\(\alpha\mu(A)\)</span> as an integral, that is we
define <span class="math display">\[\int_E f(x) \,\mathop{}\!\mathrm{d}
\mu(x) \coloneq\alpha \mu(A).\]</span> Moreover, integrals should be
linear, so for any <em>simple function</em> of the form <span
class="math display">\[f(x) \coloneq\sum_{k=1}^n \underbrace{\alpha_k
\bm{1}_{A_k}(x)}_{f_k(x)}, \quad x \in E,\]</span> for some <span
class="math inline">\(n \in \mathbb{N}\)</span>, <span
class="math inline">\(\alpha_1,\ldots,\alpha_n \geq 0\)</span>, and
<span class="math inline">\(A_1,\ldots, A_n \in \mathcal{A}\)</span>
pairwise disjoint, we define <span class="math display">\[\int_E f(x)
\mathop{}\!\mathrm{d} {\mu(x)} \coloneq\sum_{k=1}^n \alpha_k \mu(A_k) =
\sum_{k=1}^n \int_E f_k(x) \mathop{}\!\mathrm{d} {\mu(x)}.\]</span> To
extend the notion of the Lebesgue integral for simple functions to more
general function classes, we use the following fundamental result.</p>
<div class="theorem">
<p><strong>Theorem 2.18</strong>. <em>For any non-negative, measurable
function <span class="math inline">\(f\colon E \to \mathbb{R}\)</span>,
there exists an increasing sequence of simple functions <span
class="math inline">\((f_n)_{n \in \mathbb{N}}\)</span> such that we
have the pointwise convergence <span class="math display">\[\forall x
\in E: \lim_{n \to \infty} f_n(x) = f(x).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Let <span class="math display">\[f_n(x)
\coloneq\sum_{k=0}^{n2^n-1} \frac{k}{2^n}
\bm{1}_{\underbrace{f^{-1}\big(\big[\tfrac{k}{2^n},
\tfrac{k+1}{2^n}\big)}_{\in \mathcal{A}}\big)}(x) +
n\bm{1}_{\underbrace{f^{-1}([n,\infty))}_{\in \mathcal{A}}}(x), \quad x
\in \mathbb{R}.\]</span> Then <span class="math inline">\(f_n\)</span>
is simple and for any <span class="math inline">\(x \in
\mathbb{R}\)</span> it clearly holds that <span
class="math inline">\(f_n(x) \to f(x)\)</span> as <span
class="math inline">\(n \to \infty\)</span>. Moreover, if <span
class="math inline">\(x \in f^{-1}([k2^{-n},(k+1)2^{-n}))\)</span>, for
some <span class="math inline">\(k \leq n2^n-1\)</span>, then <span
class="math inline">\(f_n(x) = k2^{-n} \leq f(x)\)</span> and similarly,
<span class="math inline">\(f_n(x) = n \leq f(x)\)</span> for <span
class="math inline">\(x \in f^{-1}([n,\infty))\)</span>. Thus, <span
class="math inline">\(f_n \leq f\)</span>. Finally, it follows from
<span class="math display">\[[k2^{-n},(k+1)2^{-n}) =
\biguplus_{l=2k}^{2k+1} \big[l2^{-(n+1)}, (l+1)2^{-(n+1)}\big), \quad
[n,n+1) = \biguplus_{l=2(n+1)(2^n-1)}^{(n+1)2^{n+1}-1}
\big[l2^{-(n+1)},(l+1)2^{-(n+1)}\big)\]</span> that <span
class="math inline">\(f_n \leq f_{n+1}\)</span> as desired. ◻</p>
</div>
<div class="remark">
<p><em>Remark 2.19</em>. We call a sequence of simple functions as above
an approximating sequence.</p>
</div>
<p>With this result and the intuitive definition of the Lebesgue
integral for simple functions, we now define the general Lebesgue
integral for <em>any</em> measurable function by taking limits. To this
end, we let <span class="math inline">\(f^+(x) = \max\{f(x),0\}\)</span>
be the positive part and <span class="math inline">\(f^-(x) =
\max\{-f(x),0\}\)</span> be the negative part of a function <span
class="math inline">\(f\)</span>. Note that <span
class="math inline">\(f = f^+ - f^-\)</span> and <span
class="math inline">\(\lvert f \rvert = f^+ + f^-\)</span>. Moreover, if
<span class="math inline">\(f\)</span> is measurable, so are <span
class="math inline">\(f^+\)</span> and <span
class="math inline">\(f^-\)</span> and therefore also <span
class="math inline">\(\lvert f\rvert\)</span>.</p>
<div class="definition">
<p><strong>Definition 2.20</strong>. Let <span
class="math inline">\(f\colon E \to \mathbb{R}\)</span> be a
non-negative measurable function and <span
class="math inline">\((f_n)_{n \in \mathbb{N}}\)</span> be an
approximating sequence of simple functions. The Lebesgue integral of
<span class="math inline">\(f\)</span> is defined by <span
class="math display">\[\int_E f \mathop{}\!\mathrm{d} {\mu} \equiv
\int_E f(x) \mathop{}\!\mathrm{d} \mu(x) \coloneq\lim_{n \to \infty}
\int_E f_n(x) \mathop{}\!\mathrm{d} {\mu(x)}.\]</span> We call a
measurable function <span class="math inline">\(f\colon E \to
\mathbb{R}\)</span> <span class="math inline">\(\mu\)</span>-integrable
if <span class="math inline">\(\int_E \lvert f \rvert
\mathop{}\!\mathrm{d} {\mu} &lt; \infty\)</span> and define the Lebesgue
integral of an integrable function by <span
class="math display">\[\int_E f \mathop{}\!\mathrm{d} {\mu} = \int_E f^+
\mathop{}\!\mathrm{d} {\mu} - \int_E f^- \mathop{}\!\mathrm{d}
{\mu}.\]</span></p>
</div>
<div class="remark">
<p><em>Remark 2.21</em>. </p>
<ol>
<li><p>It can be shown that if <span
class="math inline">\((f_n)_n\)</span> and <span
class="math inline">\((g_n)_n\)</span> are two approximating functions
of a non-negative measurable function <span
class="math inline">\(f\)</span>, then <span
class="math inline">\(\lim_{n \to \infty} \int_E f_n
\mathop{}\!\mathrm{d} {\mu} = \lim_{n \to \infty} \int_E g_n
\mathop{}\!\mathrm{d} {\mu}\)</span>, so that the Lebesgue integral is
well-defined.</p></li>
<li><p>We will use the notation <span class="math inline">\(\int_A f
\mathop{}\!\mathrm{d} {\mu} \coloneq\int_E f \bm{1}_A
\mathop{}\!\mathrm{d} {\mu}\)</span>.</p></li>
<li><p>If <span class="math inline">\(\mu = \lambda\)</span> is the
Lebesgue measure, we usually write <span class="math inline">\(\int_A
f(x) \mathop{}\!\mathrm{d} {\lambda(x)} = \int_A f(x)
\mathop{}\!\mathrm{d} {x}.\)</span></p></li>
</ol>
</div>
<p>Next, we state some important properties of the Lebesgue integral. We
omit the proof but the strategy is always the same: first establish the
desired statement for simple functions, then show it for non-negative
measurable functions by taking limits and conclude for <span
class="math inline">\(\mu\)</span>-integrable functions by decomposing
into positive and negative parts.</p>
<div id="prop:prop_int" class="proposition">
<p><strong>Proposition 2.22</strong>. <em>Suppose that <span
class="math inline">\(f,g\colon E \to \mathbb{R}\)</span> are <span
class="math inline">\(\mu\)</span>-integrable.</em></p>
<ol>
<li><p><em>Linearity: for any <span class="math inline">\(\alpha, \beta
\in \mathbb{R}\)</span>, the function <span class="math inline">\(\alpha
f + \beta g\)</span> is <span
class="math inline">\(\mu\)</span>-integrable and <span
class="math display">\[\int_E (\alpha f + \beta g) \mathop{}\!\mathrm{d}
{\mu} = \alpha \int_E f \mathop{}\!\mathrm{d} {\mu} + \beta \int_E g
\mathop{}\!\mathrm{d} {\mu}.\]</span></em></p></li>
<li><p><em>Monotonicity: if <span class="math inline">\(f \leq
g\)</span> <span class="math inline">\(\mu\)</span>-a.e., then <span
class="math display">\[\int_E f \mathop{}\!\mathrm{d} {\mu} \leq \int_E
g \mathop{}\!\mathrm{d} {\mu}.\]</span></em></p></li>
<li><p><em>Triangle inequality: <span class="math display">\[\Big\lvert
\int_E f \mathop{}\!\mathrm{d} {\mu} \Big\rvert \leq \int_E \lvert f
\rvert \mathop{}\!\mathrm{d} {\mu}.\]</span></em></p></li>
<li><p><em>If <span class="math inline">\(\mu(N) = 0\)</span> then <span
class="math inline">\(\int_N f \mathop{}\!\mathrm{d} {\mu} =
0\)</span>.</em></p></li>
</ol>
</div>
<p>In many situations it is desirable to switch the order of integration
and taking limits and the next two powerful results identify situations
where this is allowed.</p>
<div class="theorem">
<p><strong>Theorem 2.23</strong> (Monotone convergence). <em>Let <span
class="math inline">\((f_n)_{n \in \mathbb{N}}\)</span> be an increasing
sequence of measurable non-negative functions converging <span
class="math inline">\(\mu\)</span>-a.e. to a function <span
class="math inline">\(f\colon E \to \mathbb{R}\)</span>, i.e., <span
class="math inline">\(0 \leq f_1 \leq f_2 \leq \cdots f_n \leq
\cdots\)</span> and <span class="math inline">\(\lim_{n \to \infty} f_n
= f\)</span>, <span class="math inline">\(\mu\)</span>-a.e. Then, <span
class="math display">\[\label{eq:mon_conv}
\lim_{n \to \infty} \int_E f_n \mathop{}\!\mathrm{d} {\mu} = \int_E f
\mathop{}\!\mathrm{d} {\mu}.\]</span></em></p>
</div>
<div class="exercise">
<p><em>Exercise 2.24</em>. Use continuity of measures to show <a
href="#eq:mon_conv" data-reference-type="eqref"
data-reference="eq:mon_conv">[eq:mon_conv]</a> for the special case
<span class="math inline">\(f_n = \bm{1}_{A_n}\)</span>, <span
class="math inline">\(A_n \in \mathcal{A}\)</span>, and <span
class="math inline">\(A_n \subset A_{n+1}\)</span> for any <span
class="math inline">\(n \in \mathbb{N}\)</span>.</p>
</div>
<div id="theo:dom" class="theorem">
<p><strong>Theorem 2.25</strong> (Dominated convergence). <em>Let <span
class="math inline">\(f,f_1,f_2,\ldots\)</span> be <span
class="math inline">\(\mu\)</span>-integrable functions such
that</em></p>
<ol>
<li><p><em><span class="math inline">\(\lim_{n \to \infty} f_n =
f\)</span> <span
class="math inline">\(\mu\)</span>-a.e. and</em></p></li>
<li><p><em>there exists some non-negative <span
class="math inline">\(\mu\)</span>-integrable function <span
class="math inline">\(g\)</span> s.t. <span class="math inline">\(\lvert
f_n \rvert \leq g\)</span> <span
class="math inline">\(\mu\)</span>-a.e. for any <span
class="math inline">\(n \in \mathbb{N}\)</span>,</em></p></li>
</ol>
<p><em>Then, <span class="math display">\[\lim_{n \to \infty} \int_E f_n
\mathop{}\!\mathrm{d} {\mu} = \int_E f \mathop{}\!\mathrm{d}
{\mu}.\]</span></em></p>
</div>
<h3 id="absolutely-continuous-distributions">Absolutely continuous
distributions</h3>
<p>With these preparations we can now finally construct continuous
distributions.</p>
<div id="prop:meas_change" class="proposition">
<p><strong>Proposition 2.26</strong> (Change of measure). <em>Let <span
class="math inline">\(\mu\)</span> be a measure on <span
class="math inline">\((E,\mathcal{A})\)</span> and <span
class="math inline">\(f \colon E \to \mathbb{R}\)</span> be a
non-negative measurable function such that <span
class="math inline">\(\int_E f \mathop{}\!\mathrm{d} {\mu} = 1.\)</span>
Then, the set function <span class="math inline">\(\nu\)</span> defined
by <span class="math display">\[\nu(B) \coloneq\int_B f
\mathop{}\!\mathrm{d} {\mu}, \quad B \in \mathcal{A},\]</span> is a
probability measure on <span
class="math inline">\((E,\mathcal{A})\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p><span class="math inline">\(\nu(\varnothing) = \int_\varnothing f
\mathop{}\!\mathrm{d} {\mu} = \int \underbrace{f
\bm{1}_{\varnothing}}_{\equiv 0} \mathop{}\!\mathrm{d} {\mu} =
0\)</span>.</p></li>
<li><p><span class="math inline">\(\nu(E) = \int_E f
\mathop{}\!\mathrm{d} {\mu} = 1\)</span> by assumption.</p></li>
<li><p>Let <span class="math inline">\((A_n)_n \subset
\mathcal{A}\)</span> be pairwise disjoint. Then <span
class="math inline">\(\sum_{n=1}^{N} \bm{1}_{A_n} =
\bm{1}_{\bigcup_{n=1}^N A_n}\)</span> for all <span
class="math inline">\(N \in \mathbb{N}\cup \{\infty\}\)</span> and <span
class="math inline">\(0 \leq f \sum_{k=1}^n \bm{1}_{A_k} \leq
f\sum_{k=1}^{n+1} \bm{1}_{A_k} \leq f\)</span>. Thus, <span
class="math display">\[\begin{aligned}
\nu\Big(\bigcup_{n \in \mathbb{N}} A_n\Big) &amp;= \int_E
f\bm{1}_{\bigcup_{n \in \mathbb{N}} A_n} \mathop{}\!\mathrm{d} {\mu}\\
&amp;= \int_E f\lim_{n \to \infty} \sum_{k=1}^n \bm{1}_{A_k}
\mathop{}\!\mathrm{d} {\mu}\\  
&amp;= \lim_{n \to \infty} \int_E f\sum_{k=1}^n \bm{1}_{A_k}
\mathop{}\!\mathrm{d} {\mu}\\
&amp;=\lim_{n \to \infty} \int_E \sum_{k=1}^n f \bm{1}_{A_k}
\mathop{}\!\mathrm{d} {\mu}\\
&amp;= \lim_{n \to \infty} \sum_{k=1}^n \int_E  f \bm{1}_{A_k}
\mathop{}\!\mathrm{d} {\mu}\\
&amp;= \sum_{n=1}^\infty \int_E  f \bm{1}_{A_n} \mathop{}\!\mathrm{d}
{\mu}\\
&amp;= \sum_{n=1}^\infty \mu(A_n),
\end{aligned}\]</span> where we used monotone convergence for the third
and linearity for the fifth equality.</p></li>
</ol>
<p> ◻</p>
</div>
<div class="definition">
<p><strong>Definition 2.27</strong>. Let <span
class="math inline">\(X\)</span> be a random variable with distribution
<span class="math inline">\(\mathbb{P}_X\)</span> that is given by <span
class="math inline">\(\mathbb{P}_X(B) = \int_B f \mathop{}\!\mathrm{d}
{\mu}\)</span> for a measure <span class="math inline">\(\mu\)</span> on
<span
class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span> and
a non-negative measurable function <span class="math inline">\(f\colon
\mathbb{R}\to \mathbb{R}\)</span> such that <span
class="math inline">\(\int f \mathop{}\!\mathrm{d} {\mu} = 1\)</span>.
Then we say that <span class="math inline">\(\mathbb{P}_X\)</span> is
absolutely continuous w.r.t. <span class="math inline">\(\mu\)</span>
(denoted <span class="math inline">\(\mathbb{P}_X \ll \mu\)</span>) and
call <span class="math inline">\(f\)</span> its <span
class="math inline">\(\mu\)</span>-density. If <span
class="math inline">\(\mu = \lambda\)</span> is the Lebesgue measure, we
say that <span class="math inline">\(\mathbb{P}_X\)</span> is absolutely
continuous and that <span class="math inline">\(X\)</span> is a
continuous random variable. We then call <span
class="math inline">\(f\)</span> the <em>probability density function
(pdf)</em> of <span class="math inline">\(\mathbb{P}_X\)</span>.
Generally, we call any non-negative measurable function <span
class="math inline">\(f\)</span> such that <span
class="math inline">\(\int_{\mathbb{R}} f(x) \mathop{}\!\mathrm{d} {x} =
1\)</span> a pdf and specify its associated distribution by <span
class="math inline">\(\mathcal{B}(\mathbb{R}) \ni B \mapsto \int_B f(x)
\mathop{}\!\mathrm{d} {x}\)</span>.</p>
</div>
<div class="remark">
<p><em>Remark 2.28</em>. If <span class="math inline">\(\mathbb{P}_X \ll
\mu\)</span> we also say that <span class="math inline">\(\mu\)</span>
dominates <span class="math inline">\(\mathbb{P}_X\)</span>. The density
is often symbolically written as <span class="math inline">\(f =
\tfrac{\mathop{}\!\mathrm{d} {\mathbb{P}_X}}{\mathop{}\!\mathrm{d}
{\mu}}\)</span> (because then <span
class="math inline">\(\mathbb{P}_X(B) = \int_B
\tfrac{\mathop{}\!\mathrm{d} {\mathbb{P}_X}}{\mathop{}\!\mathrm{d}
{\mu}} \mathop{}\!\mathrm{d} {\mu}\)</span>) and called the
<em>Radon–Nikodym derivative</em> of <span
class="math inline">\(\mathbb{P}_X\)</span> w.r.t. <span
class="math inline">\(\mu\)</span>.</p>
</div>
<div id="ex:dist_f" class="exercise">
<p><em>Exercise 2.29</em>. Let <span class="math inline">\(X\)</span> be
a continuous random variable. Show that <span
class="math inline">\(\mathbb{P}_X(\{x\}) = 0\)</span> for every <span
class="math inline">\(x \in \mathbb{R}\)</span>. Deduce from this that
<span class="math inline">\(F_X\)</span> is a continuous function.</p>
</div>
<h2 id="expectation-of-transformed-random-variables">Expectation of
(transformed) random variables</h2>
<p>Introducing the Lebesgue integral in the previous section now also
allows us to define the <em>expectation</em> of a random variable.
Throughout this section we fix a probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> and
implicitly understand all random variables to be defined there upon.</p>
<div class="definition">
<p><strong>Definition 2.30</strong>. Let <span
class="math inline">\(X\)</span> be a random variable that is either
non-negative or <span
class="math inline">\(\mathbb{P}\)</span>-integrable. The expectation of
<span class="math inline">\(X\)</span> is defined by <span
class="math display">\[\mathbb{E}[X] = \int_\Omega X
\mathop{}\!\mathrm{d} {P}.\]</span></p>
</div>
<p>Since the expectation is just a Lebesgue integral w.r.t. <span
class="math inline">\(\mathbb{P}\)</span>, we can recast Proposition <a
href="#prop:prop_int" data-reference-type="ref"
data-reference="prop:prop_int">2.22</a> probabilistically.</p>
<div id="coro:prop_exp" class="corollary">
<p><strong>Corollary 2.31</strong>. <em>Suppose that <span
class="math inline">\(X,Y\)</span> are <span
class="math inline">\(\mathbb{P}\)</span>-integrable random
variables.</em></p>
<ol>
<li><p><em>Linearity: for any <span class="math inline">\(\alpha,\beta
\in \mathbb{R}\)</span>, <span class="math inline">\(\alpha X + \beta
Y\)</span> is <span class="math inline">\(\mathbb{P}\)</span>-integrable
and <span class="math inline">\(\mathbb{E}[\alpha X + \beta Y] =
\alpha\mathbb{E}[X] + \beta\mathbb{E}[Y]\)</span>.</em></p></li>
<li><p><em>Monotonicity: if <span class="math inline">\(X \leq
Y\)</span>, <span class="math inline">\(\mathbb{P}\)</span>-a.s., then
<span class="math display">\[\mathbb{E}[X] \leq
\mathbb{E}[Y].\]</span></em></p></li>
<li><p><em>Triangle inequality: <span class="math display">\[\lvert
\mathbb{E}[X] \rvert \leq \mathbb{E}[\lvert X
\rvert].\]</span></em></p></li>
<li><p><em>If <span class="math inline">\(X=Y\)</span> <span
class="math inline">\(\mathbb{P}\)</span>-a.s., then <span
class="math inline">\(\mathbb{E}[X] =
\mathbb{E}[Y]\)</span>.</em></p></li>
</ol>
</div>
<p>Recall that if <span class="math inline">\(g\colon \mathbb{R}\to
\mathbb{R}\)</span> is measurable, <span class="math inline">\(Y =
g(X)\)</span> is also a random variable, so that the expectation <span
class="math inline">\(\mathbb{E}[g(X)]\)</span> is well defined provided
<span class="math inline">\(g\)</span> is non-negative or <span
class="math inline">\(\int_\Omega \lvert g(X) \rvert
\mathop{}\!\mathrm{d} {\mathbb{P}} &lt; \infty\)</span>. To see how to
calculate an expected value, let us first look at the case <span
class="math inline">\(g = \bm{1}_A\)</span> for some <span
class="math inline">\(A \in \mathcal{B}(\mathbb{R})\)</span>. Then,
<span class="math display">\[\label{eq:trans_ind}
\mathbb{E}[g(X)] = \mathbb{E}[\bm{1}_A(X)] = \int_\Omega \bm{1}_A(X)
\mathop{}\!\mathrm{d} {\mathbb{P}} = \int_\Omega \bm{1}_{\{X \in A\}}
\mathop{}\!\mathrm{d} {\mathbb{P}} =  \mathbb{P}(X \in A) =
\mathbb{P}_X(A) = \int_{\mathbb{R}} \bm{1}_A \mathop{}\!\mathrm{d}
{\mathbb{P}_X} = \int_{\mathbb{R}} g \mathop{}\!\mathrm{d}
{\mathbb{P}_X},\]</span> by the definition of the integral for simple
functions. As it turns out, this result is generally true.</p>
<div id="theo:trafo" class="theorem">
<p><strong>Theorem 2.32</strong> (Transformation theorem for random
variables). <em>Let <span class="math inline">\(X\)</span> be a random
variable and <span class="math inline">\(g\colon \mathbb{R}\to
\mathbb{R}\)</span> be a measurable function that is either non-negative
or such that <span class="math inline">\(\int_{\mathbb{R}} \lvert g
\rvert \mathop{}\!\mathrm{d} {\mathbb{P}_X} &lt; \infty\)</span>. Then,
<span class="math display">\[\mathbb{E}[g(X)] = \int_{\mathbb{R}} g
\mathop{}\!\mathrm{d} {\mathbb{P}_X}.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Consider first the case that <span
class="math inline">\(g = \sum_{k=1}^n \alpha_k \bm{1}_{A_k}\)</span> is
a simple function. Then, using <a href="#eq:trans_ind"
data-reference-type="eqref"
data-reference="eq:trans_ind">[eq:trans_ind]</a> and linearity it
follows <span class="math display">\[\int_{\mathbb{R}} g
\mathop{}\!\mathrm{d} {\mathbb{P}_X} = \sum_{k=1}^n \alpha_k
\int_{\mathbb{R}} \bm{1}_{A_k} \mathop{}\!\mathrm{d} {\mathbb{P}_X}
=  \sum_{k=1}^n \alpha_k \mathbb{E}[\bm{1}_{A_k}(X)] =
\mathbb{E}\Big[\sum_{k=1}^n \alpha_k \bm{1}_{A_k}(X) \Big] =
\mathbb{E}[g(X)].\]</span> Next, let <span class="math inline">\(g\geq
0\)</span> be measurable and let <span class="math inline">\((g_n)_{n
\in \mathbb{N}}\)</span> be an approximating sequence of simple
functions (recall: increasing and converges pointwise to <span
class="math inline">\(g\)</span>. Then also <span
class="math inline">\((g_n(X))_{n \in \mathbb{N}}\)</span> increasing
sequence of measurable functions on <span
class="math inline">\(\Omega\)</span> and <span
class="math inline">\(\lim_{n \to \infty} g_n(X) = g(X)\)</span>). From
above, <span class="math inline">\(\mathbb{E}[g_n(X)] =
\int_{\mathbb{R}} g_n \mathop{}\!\mathrm{d} {\mathbb{P}_X}\)</span> and
therefore, applying monotone convergence twice <span
class="math display">\[\int_{\mathbb{R}} g \mathop{}\!\mathrm{d}
{\mathbb{P}_X} = \int_{\mathbb{R}} \lim_{n \to \infty} g_n
\mathop{}\!\mathrm{d} {\mathbb{P}_X} = \lim_{n \to \infty}
\int_{\mathbb{R}}  g_n \mathop{}\!\mathrm{d} {\mathbb{P}_X} = \lim_{n
\to \infty} \mathbb{E}[g_n(X)] = \mathbb{E}[g(X)].\]</span> Finally,
suppose that <span class="math inline">\(g\)</span> is measurable and
<span class="math inline">\(\int_{\mathbb{R}} \lvert g \rvert
\mathop{}\!\mathrm{d} {\mathbb{P}_X} &lt; \infty\)</span>. We have just
shown that <span class="math display">\[\int_{\mathbb{R}} \lvert g
\rvert \mathop{}\!\mathrm{d} {\mathbb{P}_X} = \int_\Omega \lvert g(X)
\rvert \mathop{}\!\mathrm{d} {\mathbb{P}},\]</span> so that <span
class="math inline">\(g(X)\)</span> is <span
class="math inline">\(\mathbb{P}\)</span>-integrable. Consequently, the
above yields <span class="math display">\[\int_{\mathbb{R}} g
\mathop{}\!\mathrm{d} {\mathbb{P}_X} = \int_{\mathbb{R}} g^+
\mathop{}\!\mathrm{d} {\mathbb{P}_X} - \int_{\mathbb{R}} g^-
\mathop{}\!\mathrm{d} {\mathbb{P}_X} = \mathbb{E}[g^+(X)] -
\mathbb{E}[g^-(X)] = \mathbb{E}[g(X)]\]</span> as claimed. ◻</p>
</div>
<p>As a consequence, the expectations of transformations of a random
variable <span class="math inline">\(X\)</span> do not depend on the
underlying probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>, but can
be entirely expressed in terms of the distribution <span
class="math inline">\(\mathbb{P}_X\)</span>. This is particularly handy
for modelling and explains why in statistics we wish to draw inference
on <span class="math inline">\(\mathbb{P}_X\)</span> for a given sample
of random variables following this distribution. The above observation
also motivates the following definition.</p>
<div class="definition">
<p><strong>Definition 2.33</strong>. </p>
<ol>
<li><p>Let <span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> be two random variables (not
necessarily defined on the same probability space). We say that they are
<em>equal in distribution</em> if <span
class="math inline">\(\mathbb{P}_X = \mathbb{P}_Y\)</span> and denote
this by <span class="math inline">\(X \overset{d}{=}
Y\)</span>.</p></li>
<li><p>If <span class="math inline">\(\nu\)</span> is some distribution,
we write <span class="math inline">\(X \sim \nu\)</span> if <span
class="math inline">\(\mathbb{P}_X = \nu\)</span>. If <span
class="math inline">\(\mathbb{P}_X\)</span> is absolutely continuous
with density <span class="math inline">\(f\)</span>, we simply write
<span class="math inline">\(X \sim f\)</span>.</p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 2.34</em>. Since distribution functions uniquely
characterise the distribution, we have <span class="math inline">\(X
\overset{d}{=} Y\)</span> iff <span class="math inline">\(F_X =
F_Y\)</span>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 2.35</strong> (Calculation rules). </p>
<ol>
<li><p><em>Let <span class="math inline">\(X\)</span> be a continuous
random variable with pdf <span class="math inline">\(f\)</span>. Let
<span class="math inline">\(g\colon \mathbb{R}\to \mathbb{R}\)</span> be
a measurable function that is either non-negative or such that <span
class="math inline">\(\int_{\mathbb{R}} \lvert g(x) \rvert f(x)
\mathop{}\!\mathrm{d} {x} &lt; \infty\)</span>. It then holds that <span
class="math display">\[\mathbb{E}[g(X)] = \int_{\mathbb{R}} g(x) f(x)
\mathop{}\!\mathrm{d} {x}.\]</span></em></p></li>
<li><p><em>Let <span class="math inline">\(X\)</span> be a discrete
random variable with discrete density function <span
class="math inline">\(f = \sum_{k=1}^N p_k \bm{1}_{\{x_k\}}\)</span> for
some <span class="math inline">\(N \in \mathbb{N}\cup
\{\infty\}\)</span>, <span class="math inline">\(p_k \geq 0\)</span>,
<span class="math inline">\(x_k \in \mathbb{R}\)</span>. Let also <span
class="math inline">\(g\colon \mathbb{R}\to \mathbb{R}\)</span> be a
measurable function that is either non-negative or such that <span
class="math inline">\(\sum_{k=1}^N \lvert g(x_k) \rvert p_k &lt;
\infty\)</span>. It then holds that <span
class="math display">\[\mathbb{E}[g(X)] = \sum_{k=1}^N  g(x_k) p_k =
\sum_{k=1}^N g(x_k) \mathbb{P}(X = x_k).\]</span></em></p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 2.36</em>. In particular, for the expectation of <span
class="math inline">\(X\)</span> we get <span
class="math inline">\(\mathbb{E}[X] = \int_{\mathbb{R}} xf(x)
\mathop{}\!\mathrm{d} {x}\)</span> and <span
class="math inline">\(\sum_{k=1}^N x_k p_k\)</span>, respectively,
provided integral and sum are well-defined.</p>
</div>
<div class="proof">
<p><em>Proof.</em> By Theorem <a href="#theo:trafo"
data-reference-type="ref" data-reference="theo:trafo">2.32</a> it
suffices to show <span class="math display">\[\int_{\mathbb{R}}
g\mathop{}\!\mathrm{d} {\mathbb{P}_X} = \begin{cases} \int_{\mathbb{R}}
g(x) f(x) \mathop{}\!\mathrm{d} {x}, &amp;X \text{ continuous},\\
\mathbb{E}[g(X)] = \sum_{k=1}^N  g(x_k) p_k, &amp; X \text{
discrete}.\end{cases}\]</span> This can be proved analogously to Theorem
<a href="#theo:trafo" data-reference-type="ref"
data-reference="theo:trafo">2.32</a>: (1) show the statement for simple
<span class="math inline">\(g\)</span> using linearity and the
definition of <span class="math inline">\(\mathbb{P}_X\)</span>; (2)
extend to non-negative measurable functions via monotone convergence;
(3) use (2) to show it for <span class="math inline">\(g\)</span>
satisfying the integrability criteria by splitting <span
class="math inline">\(g = g^+ - g^-\)</span>. We leave the details to
you. ◻</p>
</div>
<p>You may still be concerned about the expression <span
class="math inline">\(\int_{\mathbb{R}} f(x) g(x) \mathop{}\!\mathrm{d}
{x}\)</span>: the notation looks quite inviting as it reminds us of the
(improper) Riemann integral <span
class="math inline">\(\int_{-\infty}^\infty f(x) g(x)
\mathop{}\!\mathrm{d} {x}\)</span>, which you have learned to calculate
for many different choices of <span class="math inline">\(f,g\)</span>.
Fortunately, under mild assumptions (that will always be satisfied in
any example/exercise of the module!) the integrals coincide and you can
calculate as usual.</p>
<div class="theorem">
<p><strong>Theorem 2.37</strong>. <em>Let <span
class="math inline">\(X\)</span> be a continuous random variable with
pdf <span class="math inline">\(f\)</span> that is piecewise continuous.
Let <span class="math inline">\(g\colon \mathbb{R}\to
\mathbb{R}\)</span> be a also a piecewise continuous function that is
either non-negative or such that <span
class="math inline">\(\int_{-\infty}^\infty \lvert g(x) \rvert f(x)
\mathop{}\!\mathrm{d} {x} &lt; \infty\)</span> (read as a Riemann
integral). It then holds that <span
class="math display">\[\mathbb{E}[g(X)] = \int_{-\infty}^\infty g(x)
f(x) \mathop{}\!\mathrm{d} {x} = \lim_{n \to \infty} \int_{-n}^n f(x)
g(x) \mathop{}\!\mathrm{d} {x}.\]</span></em></p>
</div>
<div id="ex:exp" class="exercise">
<p><em>Exercise 2.38</em>. Let <span class="math inline">\(\lambda &gt;
0\)</span> and <span class="math inline">\(f_\lambda \colon
\mathbb{R}\to \mathbb{R}\)</span> be given by <span
class="math display">\[f_\lambda(x) = \lambda \mathrm{e}^{-\lambda x}
\bm{1}_{[0,\infty)}(x), \quad x \in \mathbb{R}.\]</span></p>
<ol>
<li><p>Show that <span class="math inline">\(\int_{\mathbb{R}}
f_\lambda(x) \mathop{}\!\mathrm{d} {x} = 1\)</span> and for any <span
class="math inline">\(k \in \mathbb{N}\)</span>, <span
class="math inline">\(\int_{\mathbb{R}} \lvert x \rvert^k f_\lambda(x)
\mathop{}\!\mathrm{d} {x} &lt; \infty\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X\)</span> be a random variable
with pdf <span class="math inline">\(f_\lambda\)</span> as above. Show
that <span class="math inline">\(F_X(x) = (1 - \mathrm{e}^{-\lambda
x})\bm{1}_{[0,\infty)}(x)\)</span>, <span
class="math inline">\(\mathbb{E}[X] = 1/\lambda\)</span> and <span
class="math inline">\(\mathbb{E}[X^2] = 2/\lambda^2\)</span>.</p></li>
</ol>
</div>
<div class="exercise">
<p><em>Exercise 2.39</em>. Let <span class="math inline">\(X\)</span> be
a continuous random variable with continuous pdf <span
class="math inline">\(f\)</span>. Show that <span
class="math inline">\(F^\prime_X(x) = f(x)\)</span> for all <span
class="math inline">\(x \in \mathbb{R}\)</span>.</p>
</div>
<h2 id="moments-and-moment-generating-functions">Moments and moment
generating functions</h2>
<p>We finish this chapter with some important transformations that are
particularly important in statistics.</p>
<div class="definition">
<p><strong>Definition 2.40</strong>. The variance <span
class="math inline">\(\mathop{\mathrm{Var}}(X)\)</span> of a random
variable <span class="math inline">\(X\)</span> such that <span
class="math inline">\(\mathbb{E}[\lvert X \rvert^2] &lt; \infty\)</span>
is defined by <span class="math display">\[\mathop{\mathrm{Var}}(X)
\coloneq\mathbb{E}\big[(X - \mathbb{E}[X])^2\big].\]</span> The standard
deviation is defined by <span class="math display">\[\sigma_X
\coloneq\sqrt{\mathop{\mathrm{Var}}(X)}.\]</span></p>
</div>
<p>We first note that the variance is well-defined because <span
class="math inline">\(\mathbb{E}[\lvert X\rvert^2] &lt; \infty\)</span>
implies <span class="math inline">\(\mathbb{E}[\lvert X \rvert] &lt;
\infty\)</span>. This follows from the Cauchy–Schwarz inequality for
random variables.</p>
<div id="theo:cs" class="theorem">
<p><strong>Theorem 2.41</strong>. <em>Let <span
class="math inline">\(X,Y\)</span> be two random variables on <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Then,
<span class="math display">\[\mathbb{E}[\lvert X Y \rvert] \leq
\big(\mathbb{E}[X^2]\big)^{1/2}\big(\mathbb{E}[Y^2]\big)^{1/2}.
\tag{\text{Cauchy--Schwarz inequality}}\]</span> More generally, it
holds for any <span class="math inline">\(p,q \geq 1\)</span> s.t. <span
class="math inline">\(1/p + 1/q = 1\)</span> that <span
class="math display">\[\mathbb{E}[\lvert X Y \rvert] \leq
\big(\mathbb{E}[X^p]\big)^{1/p}\big(\mathbb{E}[Y^q]\big)^{1/q}.
\tag{\text{Hölder inequality}}\]</span></em></p>
</div>
<div class="lemma">
<p><strong>Lemma 2.42</strong>. <em>Suppose that <span
class="math inline">\(\mathbb{E}[\lvert X \rvert^2] &lt;
\infty\)</span>. Then, <span
class="math display">\[\mathop{\mathrm{Var}}(X) = \mathbb{E}[X^2] -
\mathbb{E}[X]^2.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> By integrability we can use linearity of the
expectation and calculate as follows: <span
class="math display">\[\mathbb{E}\big[(X -\mathbb{E}[X])^2 \big] =
\mathbb{E}\big[X^2 - 2X\mathbb{E}[X] - \mathbb{E}[X]^2\big] =
\mathbb{E}[X^2] - 2\underbrace{\mathbb{E}\big[X \mathbb{E}[X]\big]}_{=
\mathbb{E}[X]\mathbb{E}[X]} +
\underbrace{\mathbb{E}[\mathbb{E}[X]^2]}_{=\mathbb{E}[X]^2} =
\mathbb{E}[X^2] - \mathbb{E}[X]^2.\]</span> ◻</p>
</div>
<div id="ex:var" class="exercise">
<p><em>Exercise 2.43</em>. Suppose that <span
class="math inline">\(\mathbb{E}[\lvert X \rvert^2] &lt;
\infty\)</span>. Show that for any <span class="math inline">\(a \in
\mathbb{R}\)</span>, we have <span
class="math inline">\(\mathop{\mathrm{Var}}(aX) = a^2
\mathop{\mathrm{Var}}(X)\)</span> and <span
class="math inline">\(\mathop{\mathrm{Var}}(X +a) =
\mathop{\mathrm{Var}}(X)\)</span>.</p>
</div>
<p>The variance is a quantity that roughly encodes how much a random
variable <span class="math inline">\(X\)</span> fluctuates around its
mean <span class="math inline">\(\mathbb{E}[X]\)</span>. To underline
this point we need a fundamental integral inequality that in spite of
its simplicity is of fundamental value in statistics.</p>
<div id="theo:markov" class="theorem">
<p><strong>Theorem 2.44</strong> (Markov’s inequality). <em>Let <span
class="math inline">\(X\)</span> be a random variable and <span
class="math inline">\(\varphi\colon [0,\infty) \to [0,\infty)\)</span>
be a non-negative, non-decreasing and measurable function such that
<span class="math inline">\(\varphi((0,\infty))\subset
(0,\infty)\)</span>. Then, for any <span class="math inline">\(t &gt;
0\)</span> it holds that <span
class="math display">\[\mathbb{P}\big(\lvert X \rvert \geq t \big) \leq
\frac{\mathbb{E}[\varphi(\lvert X
\rvert)]}{\varphi(t)}.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Since <span class="math inline">\(\varphi\)</span> is
increasing we have <span class="math display">\[\forall \omega \in
\Omega: \lvert X(\omega) \rvert \geq t \implies \varphi(\lvert
X(\omega)\rvert) \geq \varphi(t)\]</span> and therefore <span
class="math display">\[\label{eq:markov1}
\{\lvert X \rvert \geq t \} \subset \{\varphi(\lvert X \rvert) \geq
\varphi(t) \}.\]</span> Note also that <span
class="math display">\[\label{eq:markov2}
\bm{1}_{\{\varphi(\lvert X \rvert) \geq \varphi(t)\}} \leq
\bm{1}_{\{\varphi(\lvert X \rVert) \geq \varphi(t)\}}
\frac{\varphi(\lvert X \rvert)}{\varphi(t)}.\]</span> We therefore
obtain <span class="math display">\[\begin{aligned}
\mathbb{P}\big(\lvert X \rvert \geq t \big) \overset{\eqref{eq:markov1}}
{\leq}\mathbb{P}(\varphi(\lvert X \rvert) \geq \varphi(t)) &amp;=
\mathbb{E}\big[\bm{1}_{\{\varphi(\lvert X \rVert) \geq \varphi(t)\}}
\big]\\
&amp;\overset{\eqref{eq:markov2}}{\leq}
\mathbb{E}\Big[\bm{1}_{\{\varphi(\lvert X \rVert) \geq \varphi(t)\}}
\frac{\varphi(\lvert X \rvert)}{\varphi(t)}  \Big]\\
&amp;\leq \mathbb{E}\Big[\frac{\varphi(\lvert X \rvert)}{\varphi(t)}
\Big]\\
&amp;= \frac{\mathbb{E}[\varphi(\lvert X \rvert)]}{\varphi(t)},
\end{aligned}\]</span> where for the second and third inequality we used
monotonicity of the expectation, cf. Corollary <a href="#coro:prop_exp"
data-reference-type="ref" data-reference="coro:prop_exp">2.31</a>. ◻</p>
</div>
<div id="coro:cheby" class="corollary">
<p><strong>Corollary 2.45</strong> (Chebyshev’s inequality). <em>For any
random variable <span class="math inline">\(X\)</span> such that <span
class="math inline">\(\mathbb{E}[X^2]&lt; \infty\)</span> it holds that
<span class="math display">\[\mathbb{P}\big(\lvert X - \mathbb{E}[X]
\rvert \geq t \big) \leq \frac{\mathop{\mathrm{Var}}(X)}{t^2}, \quad t
&gt; 0.\]</span> In particular, we have <span
class="math display">\[\mathbb{P}\Big(\Big\lvert \frac{X -
\mathbb{E}[X]}{\sigma_X} \Big\rvert \geq t \Big) \leq \frac{1}{t^2},
\quad t &gt; 0.\]</span></em></p>
</div>
<div class="remark">
<p><em>Remark 2.46</em>. We call <span class="math inline">\((X-
\mathbb{E}[X])/\sigma_X\)</span> the standardisation of a random
variable <span class="math inline">\(X\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> Exercise! ◻</p>
</div>
<div class="definition">
<p><strong>Definition 2.47</strong>. Let <span class="math inline">\(k
\in \mathbb{N}\)</span>. If <span
class="math inline">\(\mathbb{E}[\lvert X \rvert^k] &lt;
\infty\)</span>, we define the <span class="math inline">\(k\)</span>-th
moment of <span class="math inline">\(X\)</span> as <span
class="math display">\[\mu^\prime_k(X) \coloneq\mathbb{E}[X^k],\]</span>
and the <span class="math inline">\(k\)</span>-th centered moment of
<span class="math inline">\(X\)</span> as <span
class="math display">\[\mu_k(X) \coloneq\mathbb{E}[(X -
\mathbb{E}[X])^k].\]</span></p>
</div>
<p>We have already encountered the second centered moment as the
variance of <span class="math inline">\(X\)</span>. The third and and
fourth centered moment also yield quantities with specific names:</p>
<ul>
<li><p><em>Skewness:</em> <span
class="math inline">\(\frac{\mu_3}{\sigma_X^3} =
\mathbb{E}\Big[\Big(\frac{X -
\mathbb{E}[X]}{\sigma_X}\Big)^3\Big]\)</span>. Indicates graphically
whether a density is left-leaning (skewness positive) or right-leaning
(skewness negative).</p></li>
<li><p><em>Kurtosis:</em> <span
class="math inline">\(\frac{\mu_4}{\sigma_X^4} =
\mathbb{E}\Big[\Big(\frac{X -
\mathbb{E}[X]}{\sigma_X}\Big)^4\Big]\)</span>. By comparing it to
kurtosis of a normal density (see next chapter) used to indicate how
heavy the tails of the distribution are, i.e. how likely it is to
observe outliers in a sample.</p></li>
</ul>
<div class="definition">
<p><strong>Definition 2.48</strong>. The <em>moment generating
function</em> (mgf) of a random variable <span
class="math inline">\(X\)</span> or a distribution <span
class="math inline">\(\mathbb{P}_X\)</span> is defined as <span
class="math display">\[\psi_X(t) \coloneq\mathbb{E}[\mathrm{e}^{tX}] =
\int_{\mathbb{R}} \mathrm{e}^{tx} \mathop{}\!\mathrm{d}
{\mathbb{P}_X(x)}, \quad t \in \mathbb{R}.\]</span> We say that the mgf
exists at <span class="math inline">\(\in \mathbb{R}\)</span>, if <span
class="math inline">\(\psi_X(t) &lt; \infty\)</span>.</p>
</div>
<p>The name originates from the fact that for a random variable, whose
mgf around the origin, all moments can be derived from differentiation
of the mgf.</p>
<div id="theo:mom_gen" class="theorem">
<p><strong>Theorem 2.49</strong>. <em>Suppose that <span
class="math inline">\(\psi_X\)</span> exists on <span
class="math inline">\((-h,h)\)</span> for some <span
class="math inline">\(h &gt; 0\)</span>. Then, we have for any <span
class="math inline">\(n \in \mathbb{N}\)</span>, <span
class="math display">\[\mathbb{E}[X^n] = \frac{\mathop{}\!\mathrm{d}
^n}{\mathop{}\!\mathrm{d} {t^n}} \psi_X(t) \big\vert_{t =
0}.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof (Sketch).</em> It holds that <span
class="math display">\[\frac{\mathop{}\!\mathrm{d}
^n}{\mathop{}\!\mathrm{d} {t^n}} \mathrm{e}^{tX} = X^n
\mathrm{e}^{tX}.\]</span> So, supposing that we may switch the order of
differentiation and integration on <span
class="math inline">\((-h,h)\)</span>, it follows that <span
class="math display">\[\frac{\mathop{}\!\mathrm{d}
^n}{\mathop{}\!\mathrm{d} {t^n}} \psi_X(t) = \frac{\mathop{}\!\mathrm{d}
^n}{\mathop{}\!\mathrm{d} {t^n}} \mathbb{E}\big[\mathrm{e}^{tX}\big] =
\mathbb{E}\Big[\frac{\mathop{}\!\mathrm{d} ^n}{\mathop{}\!\mathrm{d}
{t^n}} \mathrm{e}^{tX}\Big] = \mathbb{E}\big[X^n \mathrm{e}^{tX}], \quad
t \in (-h,h),\]</span> which gives the result by plugging in <span
class="math inline">\(t = 0\)</span>. The fact that pulling the
derivative inside the expectation is allowed can be proven by dominated
convergence. ◻</p>
</div>
<p>We have already seen that the distribution function <span
class="math inline">\(F_X\)</span> uniquely characterises <span
class="math inline">\(\mathbb{P}_X\)</span>. The same holds true for the
moment generating function, provided it exists. The proof is
unfortunately out of scope of this lecture.</p>
<div class="theorem">
<p><strong>Theorem 2.50</strong>. <em>Suppose that <span
class="math inline">\(X,Y\)</span> are random variables such that their
mgfs <span class="math inline">\(\psi_X,\psi_Y\)</span> exist on some
open interval <span class="math inline">\((-h,h)\)</span>, <span
class="math inline">\(h &gt; 0\)</span>. Then, <span
class="math display">\[X \overset{d}{=} Y \iff \psi_X = \psi_Y \text{ on
} (-h,h).\]</span></em></p>
</div>
<div id="ex:exp2" class="exercise">
<p><em>Exercise 2.51</em>. Let <span
class="math inline">\(f_\lambda\)</span> be the density from Exercise <a
href="#ex:exp" data-reference-type="ref"
data-reference="ex:exp">2.38</a> and <span class="math inline">\(X \sim
f_\lambda\)</span>.</p>
<ol>
<li><p>Show that <span class="math inline">\(\psi_X(t)\)</span> exists
iff <span class="math inline">\(t &lt; \lambda\)</span> and calculate
<span class="math inline">\(\psi_X\)</span> for these values.</p></li>
<li><p>Deduce from (i) that <span class="math inline">\(\mathbb{E}[X^n]
= \frac{n!}{\lambda^n}\)</span>.</p></li>
</ol>
</div>
<h2 id="p-values-and-quantiles">P-values and quantiles</h2>
<p>Here we get to know two important summary statistics of a random
variable <span class="math inline">\(X\)</span> that will be of central
importance in our discussion of hypothesis testing later in the lecture.
The situation is the following: suppose we are given a test statistic
<span class="math inline">\(X\)</span> and we want to check whether the
hypothesis <span class="math inline">\(X \sim P_0\)</span> is plausible
for some given distribution <span class="math inline">\(P_0\)</span>
with associated cdf <span class="math inline">\(F_0\)</span>. There are
different ways to approach this problem:</p>
<ol>
<li><p>Check whether the observed realization <span
class="math inline">\(X(\omega)\)</span> is suspiciously <em>small</em>
by calculating <span class="math inline">\(P_0((-\infty,X(\omega)]) =
F_0(X)\)</span>.</p></li>
<li><p>Check whether the observed realization <span
class="math inline">\(X(\omega)\)</span> is suspiciously <em>large</em>
by calculating <span class="math inline">\(P_0([X(\omega),\infty)) =
1-F_0(X(\omega)-)\)</span>.</p></li>
<li><p>Check both simultaneously by calculating <span
class="math inline">\(2
\min\{F_0(X(\omega)),1-F_0(X(\omega)-)\}\)</span>.</p></li>
</ol>
<p>This motivates the definition of the <span
class="math inline">\(p\)</span>-value.</p>
<div class="definition">
<p><strong>Definition 2.52</strong> (p-value). Suppose that <span
class="math inline">\(X\)</span> is a random variable on a probability
space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P}_0)\)</span> such
that <span class="math inline">\(X \sim P_0\)</span> under <span
class="math inline">\(\mathbb{P}_0\)</span>.</p>
<ol>
<li><p>The left-sided <span class="math inline">\(p\)</span>-value <span
class="math inline">\(p_l\)</span> is defined by <span
class="math inline">\(p_l \coloneq F_0(X)\)</span>.</p></li>
<li><p>The right-sided <span class="math inline">\(p\)</span>-value
<span class="math inline">\(p_r\)</span> is defined by <span
class="math inline">\(p_r \coloneq 1- F_0(X-)\)</span>.</p></li>
<li><p>The two-sided <span class="math inline">\(p\)</span>-value <span
class="math inline">\(p_s\)</span> is defined by <span
class="math inline">\(p_s \coloneq 2
\min\{F_0(X,1-F_0(X-)\}\)</span>.</p></li>
</ol>
</div>
<p>A small <span class="math inline">\(p\)</span>-value always indicates
that the hypothesis <span class="math inline">\(X \sim P_0\)</span>
might <em>not</em> be true. More precisely:</p>
<div class="lemma">
<p><strong>Lemma 2.53</strong>. <em>Suppose that <span
class="math inline">\(X \sim P_0\)</span> under <span
class="math inline">\(\mathbb{P}_0\)</span>. Then, the following are
true for any <span class="math inline">\(\alpha \in (0,1)\)</span>:
<span
class="math display">\[\mathopen{}\mathclose\bgroup\left.\begin{array}{ll}
\text{(i)} &amp; \mathbb{P}_0(F_0(X) \leq \alpha)\\ \text{(ii)}  &amp;
\mathbb{P}_0(1 - F_0(X-) \leq \alpha)\\ \text{(iii)} &amp;
\mathbb{P}_0\big(2 \min\{F_0(X),1-F_0(X-)\} \leq
\alpha\big)\end{array}\aftergroup\egroup\right\}
\begin{array}{c}\phantom{(} \\ \leq \alpha, \\ \phantom{\big(}
\end{array}\]</span> with equality if <span
class="math inline">\(X\)</span> is continuous.</em></p>
</div>
<p>For the proof we introduce the pseudo-inverse of a distribution
function <span class="math inline">\(F_0\)</span> as <span
class="math display">\[q_0\colon (0,1) \to \mathbb{R}, \quad q_0(\alpha)
\coloneq\inf\{x \in \mathbb{R}: F_0(x) &gt; \alpha \big\}.\]</span></p>
<div class="proof">
<p><em>Proof.</em> For simplicity, we only consider the case that <span
class="math inline">\(X\)</span> is continuous. From Exercise <a
href="#ex:dist_f" data-reference-type="ref"
data-reference="ex:dist_f">2.29</a> we know that then <span
class="math inline">\(F_0\)</span> is a continuous function and we claim
that <span class="math display">\[\label{eq:p1}
F_0(q_0(\alpha)) = \alpha.\]</span> Indeed, observe that for any <span
class="math inline">\(x &lt; q_0(\alpha)\)</span> we have <span
class="math inline">\(F_0(x) \leq  \alpha\)</span>, and therefore by
continuity of <span class="math inline">\(F_0\)</span>, <span
class="math display">\[F_0(q_0(\alpha)) = \lim_{x \uparrow q_0(\alpha)}
F(x) \leq \alpha.\]</span> On the other hand, for <span
class="math inline">\(x &gt; q_0(\alpha)\)</span> it holds that <span
class="math inline">\(F_0(x) &gt; \alpha\)</span> and hence by
right-continuity <span class="math display">\[F_0(q_0(\alpha)) = \lim_{x
\downarrow q_0(\alpha)} F(x) \geq \alpha.\]</span> Combining both
statements gives <a href="#eq:p1" data-reference-type="eqref"
data-reference="eq:p1">[eq:p1]</a>. Let us also show that <span
class="math display">\[\label{eq:p2}
x \leq q_0(\alpha) \iff F_0(x) \leq F_0(q_0(\alpha)).\]</span> Direction
<span class="math inline">\(\implies\)</span> is clear since <span
class="math inline">\(F_0\)</span> is increasing. Conversely, if <span
class="math inline">\(F_0(x) \leq F(q_0(\alpha))\)</span>, then by <a
href="#eq:p1" data-reference-type="eqref"
data-reference="eq:p1">[eq:p1]</a>, we have <span
class="math inline">\(F_0(x) \leq \alpha\)</span>, whence <span
class="math inline">\(x \leq q_0(\alpha)\)</span>. Thus, <span
class="math display">\[\mathbb{P}_0(F_0(X) \leq \alpha)
\overset{\eqref{eq:p1}}{=} \mathbb{P}_0(F_0(X) \leq F_0(q_0(\alpha))
\overset{\eqref{eq:p2}}{=} \mathbb{P}_0(X \leq q_0(\alpha)) =
F_0(q_0(\alpha)) \overset{\eqref{eq:p1}}{=} \alpha.\]</span> The
remaining statements are easily derived from the first (try
this!). ◻</p>
</div>
<div class="definition">
<p><strong>Definition 2.54</strong> (<span
class="math inline">\(\gamma\)</span>-quantile). Let <span
class="math inline">\(\gamma \in (0,1)\)</span>. A real number <span
class="math inline">\(q_\gamma\)</span> is called <span
class="math inline">\(\gamma\)</span>-quantile of a distribution <span
class="math inline">\(P\)</span>, if <span
class="math display">\[P((-\infty,q_\gamma]) \geq \gamma \quad
\text{and} \quad P([q_\gamma,\infty)) \geq 1 - \gamma.\]</span></p>
</div>
<div class="remark">
<p><em>Remark 2.55</em>. </p>
<ol>
<li><p>Interpretation: <span class="math inline">\(q_\gamma\)</span>
splits the real axis in left and right half-lines with probability at
least <span class="math inline">\(\gamma\)</span> and <span
class="math inline">\(1-\gamma\)</span>, respectively.</p></li>
<li><p>Equivalently, <span class="math inline">\(q_\gamma\)</span> is a
<span class="math inline">\(\gamma\)</span>-quantile iff <span
class="math inline">\(F(q_\gamma-) \leq \gamma \leq
F(q_\gamma)\)</span>.</p></li>
<li><p>If <span class="math inline">\(F_0\)</span> is strictly
increasing, <span class="math inline">\(\gamma\)</span>-quantiles are
unique.</p></li>
</ol>
</div>
<h2 id="some-basic-univariate-distributions">Some basic univariate
distributions</h2>
<h3 id="discrete-distributions">Discrete distributions</h3>
<h4 id="bernoulli-distribution">Bernoulli distribution</h4>
<p>We say that <span class="math inline">\(X\)</span> has a Bernoulli
distribution with success probability <span class="math inline">\(p \in
[0,1]\)</span> if <span class="math display">\[\mathbb{P}(X = x) =
\begin{cases} p, &amp;x= 1\\ 1-p, &amp; x=0,\\ 0,
&amp;\text{else}\end{cases}\]</span> and we then write <span
class="math inline">\(X \sim \mathcal{B}(p)\)</span>. The distribution
of <span class="math inline">\(X\)</span> can be equivalently written as
<span class="math display">\[\mathbb{P}_X = p \delta_1 + (1-p)
\delta_0.\]</span> We have <span class="math display">\[\mathbb{E}[X] =
1 \cdot \mathbb{P}(X=1) + 0 \cdot \mathbb{P}(X = 0) = p,\]</span> and
since <span class="math display">\[\mathbb{E}[X^2] = 1^2\cdot
\mathbb{P}(X=1) + 0^2 \cdot \mathbb{P}(X = 0) = p,\]</span> it follows
that <span class="math display">\[\mathop{\mathrm{Var}}(X) =
\mathbb{E}[X^2] - \mathbb{E}[X]^2 = p - p^2 = p(1-p).\]</span> The mgf
exists for all <span class="math inline">\(t \in \mathbb{R}\)</span> and
is given by <span class="math display">\[\psi_X(t) =
\mathbb{E}[\exp(tX)] = \mathrm{e}^{t \cdot 1} \mathbb{P}(X=1) +
\mathrm{e}^{t \cdot 0} \mathbb{P}(X = 0) = \mathrm{e}^{t}p + (1-p) = 1 +
p(\mathrm{e}^{t}-1), \quad t \in \mathbb{R}.\]</span>
<em>Interpretation:</em> <span class="math inline">\(X\)</span> models a
single trial of a random experiment with probability of success <span
class="math inline">\(p\)</span> and probability of failure <span
class="math inline">\(1-p\)</span>.</p>
<h4 id="binomial-distribution">Binomial distribution</h4>
<p>We say that <span class="math inline">\(X\)</span> has a Binomial
distribution with success probability <span class="math inline">\(p \in
[0,1]\)</span> and number of trials <span class="math inline">\(n \in
\mathbb{N}\)</span> if <span class="math display">\[\mathbb{P}(X = x) =
\begin{cases} {n \choose k} p^k(1-p)^{n-k} , &amp;x = k \in
\{0,1,\ldots,n\},\\ 0, &amp;\text{else},\end{cases}\]</span> where the
binomial coefficient <span class="math display">\[{n \choose k}
\coloneq\frac{n!}{k! (n-k)!},\]</span> describes the number of
possibilities to choose <span class="math inline">\(k\)</span> unordered
elements (without replacement) from a set of <span
class="math inline">\(n\)</span> elements. We then write <span
class="math inline">\(X \sim \mathrm{Bin}(n,p)\)</span>. The
distribution of the discrete random variable <span
class="math inline">\(X\)</span> can be equivalently written as <span
class="math display">\[\mathbb{P}_X = \sum_{k=0}^n \underbrace{{n
\choose k} p^k (1-p)^{n-k}}_{= \mathbb{P}(X = k) = p_k}
\delta_k.\]</span> The fact that <span
class="math inline">\(\mathbb{P}_X\)</span> is a probability
distribution follows from the binomial theorem: <span
class="math display">\[\sum_{k=0}^n {n \choose k} p^k (1-p)^{n-k} = (p +
(1-p))^n = 1.\]</span> For <span class="math inline">\(p = 0\)</span>
(<span class="math inline">\(p=1\)</span>) we have <span
class="math inline">\(X = n\)</span> a.s. (<span class="math inline">\(X
= 0\)</span> a.s.) and hence in both cases <span
class="math inline">\(\mathbb{E}[X] = np, \mathop{\mathrm{Var}}(X) = 0 =
np(1-p)\)</span>. For <span class="math inline">\(p \in (0,1)\)</span>
we get <span class="math display">\[\begin{aligned}
\mathbb{E}[X] = \sum_{k=0}^n k p_k &amp;= \sum_{k=0}^n k {n \choose k}
p^k (1-p)^{n-k}\\
&amp;= \sum_{k=1}^{n-1}\frac{n!}{(k-1)!(n-k)!} p^k (1-p)^{n-k}\\
&amp;= np \sum_{k=1}^{n-1} \frac{(n-1)!}{(k-1)!(n-1-(k-1))!} p^{k-1}
(1-p)^{n-1-(k-1)} \\
&amp;= np \sum_{l=0}^{n-1} {n -1 \choose l} p^l (1-p)^{n-l}\\
&amp;= np,
\end{aligned}\]</span> where we substituted <span
class="math inline">\(l = k-1\)</span> for the penultimate line. To show
that generally <span class="math inline">\(\mathop{\mathrm{Var}}(X) =
np(1-p)\)</span> we could try to calculate <span
class="math inline">\(\mathbb{E}[X^2]\)</span> directly by invoking some
combinatorial transformations as above, or we may try a different route
by calculating the mgf. The latter is simple: by the binomial theorem,
<span class="math display">\[\psi_X(t) = \sum_{k=0}^n \mathrm{e}^{tk} {n
\choose k} p^k (1-p)^{n-k} = \sum_{k=0}^n {n \choose k}
(p\mathrm{e}^{t})^k (1-p)^{n-k} = (p\mathrm{e}^{t} + (1-p))^n, \quad t
\in \mathbb{R}.\]</span> Since <span
class="math display">\[\psi^\prime_X(t) = np\mathrm{e}^{t}(p
\mathrm{e}^t + (1-p))^{n-1}, \quad \psi^{\prime\prime}_X(t) =
np\mathrm{e}^{t}(p \mathrm{e}^t + (1-p))^{n-1} +
n(n-1)p^2\mathrm{e}^{2t}(p \mathrm{e}^t + (1-p))^{n-2},\]</span> it
follows that <span class="math display">\[\mathbb{E}[X^2] = \psi^{\prime
\prime}_X(0) = np + n(n-1)p^2,\]</span> and therefore <span
class="math display">\[\mathop{\mathrm{Var}}(X) = \mathbb{E}[X^2] -
\mathbb{E}[X]^2 = np + n(n-1)p^2 - n^2p^2 = np - np^2 =
np(1-p).\]</span> <em>Interpretation:</em> <span
class="math inline">\(X\)</span> models the number of successes in <span
class="math inline">\(n\)</span> <em>independent</em> Bernoulli
trials.</p>
<h4 id="geometric-distribution">Geometric distribution</h4>
<p>We say that a random variable <span class="math inline">\(X\)</span>
has a geometric distribution with success probability <span
class="math inline">\(p \in (0,1]\)</span>, if <span
class="math display">\[\mathbb{P}(X = x) = \begin{cases} p(1-p)^{k-1},
&amp;x = k \in \{1,2,\ldots\}\\ 0, &amp;\text{else}\end{cases}\]</span>
and we then write <span class="math inline">\(X \sim
\mathrm{Geo}(p)\)</span>. Equivalently, we may express the distribution
as <span class="math display">\[\mathbb{P}_X = \sum_{k=1}^\infty
p(1-p)^{k-1}\delta_k.\]</span></p>
<div class="proposition">
<p><strong>Proposition 2.56</strong> (Memorylessness). <em>If <span
class="math inline">\(X \sim \mathrm{Geo}(p)\)</span>, then for any
<span class="math inline">\(m,n \in \mathbb{N}\)</span> it holds that
<span class="math display">\[\mathbb{P}(X &gt; n+m \mid X &gt; n) =
\mathbb{P}(X &gt; m).\]</span></em></p>
</div>
<p><em>Interpretation</em>: <span class="math inline">\(X\)</span>
models the number of independent Bernoulli trials with success
probability <span class="math inline">\(p\)</span>, until the first
occurrence of success (<span class="math inline">\(X=k\)</span> means
that the first <span class="math inline">\(k-1\)</span> trials were
unsuccessful, which happens with probability <span
class="math inline">\((1-p)^{-1}\)</span>, and the <span
class="math inline">\(k\)</span>-th trial is a success. Be aware that
there are different conventions as to how to define the geometric
distribution. Some authors prefer to model it as the number of
<em>failures</em> until a success occurs, which changes the distribution
to <span class="math inline">\(\mathbb{P}_X = \sum_{k=0}^\infty
p(1-p)^k\)</span>.</p>
<div class="exercise">
<p><em>Exercise 2.57</em>. Show that <span
class="math inline">\(\mathbb{P}_X\)</span> is indeed a distribution.
Determine the values <span class="math inline">\(t \in
\mathbb{R}\)</span>, at which the mgf <span
class="math inline">\(\psi_X(t)\)</span> exists and calculate it for
these. Use the mgf to show that <span
class="math inline">\(\mathbb{E}[X] = \frac{1}{p}\)</span> and <span
class="math inline">\(\mathop{\mathrm{Var}}(X) = (1-p)/p^2\)</span>.</p>
</div>
<h4 id="poisson-distribution">Poisson distribution</h4>
<p>We say that a random variable <span class="math inline">\(X\)</span>
has a Poisson distribution with with rate <span
class="math inline">\(\lambda &gt; 0\)</span>, if <span
class="math display">\[\mathbb{P}(X = x) = \begin{cases}
\frac{\lambda^k}{k!} \mathrm{e}^{-\lambda}, &amp;x = k \in
\{0,1,2,\ldots\}\\ 0, &amp;\text{else}\end{cases}\]</span> and we then
write <span class="math inline">\(X \sim \mathrm{Poi}(\lambda)\)</span>.
<span class="math inline">\(\mathbb{P}_X\)</span> is accordingly given
by <span class="math display">\[\mathbb{P}_X = \sum_{k=0}^\infty
\frac{\lambda^k}{k!}\mathrm{e}^{-\lambda} \delta_k.\]</span></p>
<div class="exercise">
<p><em>Exercise 2.58</em>. Show that <span
class="math inline">\(\mathbb{P}_X\)</span> is indeed a distribution.
Show that the mgf exists for all <span class="math inline">\(t \in
\mathbb{R}\)</span> and is given by <span
class="math display">\[\psi_X(t) =
\exp\big(\lambda(\mathrm{e}^{t}-1)\big), \quad t \in
\mathbb{R}.\]</span> Use the mgf to show that <span
class="math inline">\(\mathbb{E}[X] = \mathop{\mathrm{Var}}(X)
=  \lambda\)</span>.</p>
</div>
<p><em>Interpretation:</em> consider a situation, where random events
occur subsequently at rate <span class="math inline">\(\lambda\)</span>
(i.e. on average <span class="math inline">\(\lambda\)</span> events per
time unit) and the interarrival time between two events is
<em>independent</em> of the arrival times of previous events. If we let
<span class="math inline">\(X\)</span> be the number of events that have
occurred in a unit time interval, then <span class="math inline">\(X
\sim \mathrm{Poi}(\lambda)\)</span>.</p>
<h3 id="continuous-distributions">Continuous distributions</h3>
<h4 id="uniform-distribution">Uniform distribution</h4>
<p>A continuous random variable <span class="math inline">\(X\)</span>
is said to be uniformly distributed on an interval <span
class="math inline">\([a,b]\)</span> with <span class="math inline">\(a
&lt; b\)</span> if its pdf is given by <span class="math display">\[f(x)
= \frac{1}{b-a} \bm{1}_{[a,b]}(x), \quad x \in \mathbb{R},\]</span> and
we then write <span class="math inline">\(X \sim
\mathcal{U}([a,b])\)</span>. The piecewise linear cdf is given by <span
class="math display">\[F_X(x) = \int_{-\infty}^x \frac{1}{b-a}
\bm{1}_{[a,b]}(y) \mathop{}\!\mathrm{d} {y} = \begin{cases} 0, &amp; x
&lt; a\\ \frac{x-a}{b-a}, &amp; x \in [a,b],\\ 1, &amp;\text{else}.
\end{cases}\]</span> Expectation and variance are easily calculated as
follows, <span class="math display">\[\begin{aligned}
\mathbb{E}[X] &amp;= \int_{\mathbb{R}} x f(x) \mathop{}\!\mathrm{d} {x}
= \frac{1}{b-a} \int_a^b x \mathop{}\!\mathrm{d} {x}
=\frac{1}{2(b-a)}\underbrace{(b^2-a^2)}_{= (a+b)(b-a)} = \frac{a+b}{2}\\
\mathop{\mathrm{Var}}(X) &amp;= \int_{\mathbb{R}} (x - \mathbb{E}[X])^2
f(x) \mathop{}\!\mathrm{d} {x} =  \frac{1}{b-a} \int_a^b \big(x -
\frac{a+b}{2}\big)^2 \mathop{}\!\mathrm{d} {x} =
\frac{1}{b-a}\int_{(a-b)/2}^{(b-a)/2} x^2 \mathop{}\!\mathrm{d} {x}\\
&amp;= \frac{2}{b-a} \int_0^{(b-a)/2} x^2 \mathop{}\!\mathrm{d} {x}=
\frac{2((b-a)/2)^3}{3(b-a)} = \frac{(b-a)^2}{12},
\end{aligned}\]</span> and the mgf exists everywhere and is given by
<span class="math display">\[\psi_X(t) = \frac{1}{b-a} \int_a^b
\mathrm{e}^{tx} \mathop{}\!\mathrm{d} {x} = \begin{cases}
\frac{\mathrm{e}^{tb} - \mathrm{e}^{ta}}{t(b-a)}, &amp; t \neq 0,\\ 1,
&amp; t= 0.\end{cases}\]</span></p>
<h4 id="exponential-distribution">Exponential distribution</h4>
<p>We say that a continuous random variable <span
class="math inline">\(X\)</span> is exponentially distributed with rate
<span class="math inline">\(\lambda &gt; 0\)</span> if its pdf is given
by <span class="math display">\[f(x) = \lambda \mathrm{e}^{-\lambda x}
\bm{1}_{[0,\infty)}(x), \quad x \in \mathbb{R},\]</span> and we then
write <span class="math inline">\(X \sim \mathrm{Exp}(\lambda)\)</span>.
We recognize this as the pdf explored in Exercise <a href="#ex:exp"
data-reference-type="ref" data-reference="ex:exp">2.38</a> and Exercise
<a href="#ex:exp2" data-reference-type="ref"
data-reference="ex:exp2">2.51</a>, so we already know that <span
class="math display">\[\mathbb{E}[X^n] = \frac{n!}{\lambda^n}, \quad
\mathop{\mathrm{Var}}(X) = \frac{1}{\lambda^2}, \quad F_X(x) = 1 -
\mathrm{e}^{-\lambda x},\]</span> and that the mgf exists on <span
class="math inline">\((-\infty,\lambda)\)</span> and is there given by
<span class="math display">\[\psi_X(t) = \frac{\lambda}{\lambda -t},
\quad t &lt; \lambda.\]</span> Like the discrete geometric distribution,
the continuous exponential distribution has a lack of memory
property.</p>
<div class="proposition">
<p><strong>Proposition 2.59</strong>. <em>Let <span
class="math inline">\(X \sim \mathrm{Exp}(\lambda)\)</span> for some
<span class="math inline">\(\lambda &gt; 0\)</span>. Then, for any <span
class="math inline">\(x,y \geq 0\)</span> we have <span
class="math display">\[\mathbb{P}(X &gt; x+y \mid X &gt; x) =
\mathbb{P}(X &gt; y).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> By definition of the conditional probability, we have
<span class="math display">\[\begin{aligned}
\mathbb{P}(X &gt; x+y \mid X &gt; x) = \frac{\mathbb{P}(X &gt; x+y, X
&gt; x)}{\mathbb{P}(X &gt; x)} = \frac{\mathbb{P}(X &gt;
x+y)}{\mathbb{P}( X &gt; x)} = \frac{1 - F_X(x+y)}{1-F_X(x)} &amp;=
\frac{\mathrm{e}^{-\lambda(x+y)}}{\mathrm{e}^{-\lambda x}}\\
&amp;= \mathrm{e}^{-\lambda y} \\
&amp;= \mathbb{P}(X &gt; y),
\end{aligned}\]</span> where we used <span class="math inline">\(\{X
&gt; x+y\} \subset \{X &gt; x\}\)</span> for the second equality. ◻</p>
</div>
<div class="remark">
<p><em>Remark 2.60</em>. It can be shown that exponential distributions
are the <em>only</em> class of continuous probability distributions that
is memoryless.</p>
</div>
<p><em>Interpretation:</em> Suppose that <span
class="math inline">\(X\)</span> models the waiting time until the
occurrence of a random event that arrives at rate <span
class="math inline">\(\lambda\)</span> and the waiting time is
memoryless in the sense above. Then <span class="math inline">\(X \sim
\mathrm{Exp}(\lambda)\)</span>. Equivalently, we may describe an
exponential distribution as the distribution of the independent
interarrival times underlying the random events counted by a Poisson
distribution with rate <span class="math inline">\(\lambda\)</span>.</p>
<h4 id="normal-distribution">Normal distribution</h4>
<p>A continuous random variable <span class="math inline">\(X\)</span>
is said to be normally distributed with mean <span
class="math inline">\(\mu \in \mathbb{R}\)</span> and variance <span
class="math inline">\(\sigma^2\)</span> for <span
class="math inline">\(\sigma &gt; 0\)</span>, it its pdf is given by
<span class="math display">\[f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}
\mathrm{e}^{-\frac{(x- \mu)^2}{2\sigma^2}}, \quad x \in
\mathbb{R},\]</span> and we write <span class="math inline">\(X \sim
\mathcal{N}(\mu,\sigma^2)\)</span>.</p>
<div class="exercise">
<p><em>Exercise 2.61</em>. Show that <span
class="math inline">\(f\)</span> is a pdf.<br />
<em>Hint:</em> Consider <span class="math inline">\((\int_{\mathbb{R}}
f(x) \mathop{}\!\mathrm{d} {x})^2 = \int_{\mathbb{R}} f(x)
\mathop{}\!\mathrm{d} {x} \int_{\mathbb{R}} f(y) \mathop{}\!\mathrm{d}
{y}\)</span> and use a polar substitution for <span
class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span>.</p>
</div>
<p>We call <span class="math inline">\(\mathcal{N}(0,1)\)</span> the
standard normal distribution and denotes its cdf by <span
class="math inline">\(\Phi\)</span>. The cdf cannot be expressed in
terms of elementary functions, but efficient numerical approximations
are available. We observe that <span class="math display">\[X \sim
\mathcal{N}(\mu, \sigma^2) \implies Y = a + bX \sim \mathcal{N}(a+ b\mu,
b^2 \sigma^2), \quad a,b \in \mathbb{R},\]</span> since <span
class="math display">\[F_Y(x) = \mathbb{P}(X \leq  (x - a)/b) =
\frac{1}{\sqrt{2 \pi\sigma^2}} \int_{-\infty}^{(x-a)/b}
\mathrm{e}^{-\frac{(y - \mu)^2}{2\sigma^2}} \mathop{}\!\mathrm{d} {y} =
\frac{1}{\sqrt{2\pi b^2\sigma^2}}\int_{-\infty}^{x}
\mathrm{e}^{-\frac{(z - (a+b\mu))^2}{2b^2\sigma^2}}
\mathop{}\!\mathrm{d} {z} = F_{\mathcal{N}(a + b\mu,
b^2\sigma^2)}(x).\]</span> In particular the normalisation <span
class="math inline">\(Z = (X - \mu)/\sigma\)</span> of <span
class="math inline">\(X \sim \mathcal{N}(\mu,\sigma^2)\)</span> is
standard normal, i.e., <span class="math inline">\(Z \sim
\mathcal{N}(0,1)\)</span>. The mgf exists everywhere and is calculated
as follows: assume first that <span class="math inline">\(Z \sim
\mathcal{N}(0,1)\)</span>. Then <span
class="math display">\[\begin{aligned}
\psi_Z(t) = \frac{1}{\sqrt{2\pi}}\int_{\mathbb{R}} \mathrm{e}^{tx}
\mathrm{e}^{-\frac{x^2}{2}} \mathop{}\!\mathrm{d} {x} &amp;=
\frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} \mathrm{e}^{tx -\frac{x^2}{2}}
\mathop{}\!\mathrm{d} {x} \notag\\
&amp;= \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} \mathrm{e}^{-\big(
\frac{(x-t)^2}{2} - \frac{t^2}{2}\big)} \mathop{}\!\mathrm{d} {x}
\tag{\text{completing the square}}\\
&amp;= \mathrm{e}^{\frac{t^2}{2}} \underbrace{\frac{1}{\sqrt{2\pi}}
\int_{\mathbb{R}} \mathrm{e}^{- \frac{(x-t)^2}{2}} \mathop{}\!\mathrm{d}
{x}}_{\mathclap{= \mathbb{P}(Y \in \mathbb{R}) = 1 \text{ for } Y \sim
\mathcal{N}(t,1)}}\notag\\
&amp;= \mathrm{e}^{\frac{t^2}{2}}. \notag
\end{aligned}\]</span> For general <span class="math inline">\(X \sim
\mathcal{N}(\mu,\sigma^2)\)</span>, we have <span
class="math inline">\(X \overset{d}{=} \mu + \sigma Z\)</span> for some
<span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span>, and hence
by the above, <span class="math display">\[\psi_X(t) =
\mathbb{E}[\exp(t(\mu + \sigma Z))] = \mathrm{e}^{t\mu}
\mathbb{E}[\exp(t\sigma Z)] = \mathrm{e}^{t\mu} \psi_Z(\sigma t) =
\mathrm{e}^{\mu t + \sigma^2 \frac{t^2}{2}}, \quad t \in
\mathbb{R}.\]</span> This gives <span
class="math display">\[\begin{aligned}
\mathbb{E}[X] &amp;= \psi^\prime_X(0) = (\mu + \sigma^2 t)\vert_{t = 0}
= \mu \\
\mathbb{E}[X^2] &amp;= \psi^{\prime\prime}_X(0) = \sigma^2 + \mu^2
\implies \mathop{\mathrm{Var}}(X) = \mathbb{E}[X^2] - \mathbb{E}[X]^2 =
\sigma^2,
\end{aligned}\]</span> justifying us calling <span
class="math inline">\(\mu\)</span> the mean and <span
class="math inline">\(\sigma^2\)</span> the variance of a normal
distribution. Recall that the skewness and kurtosis are defined as the
third and fourth moment, respectively of the standardised random
variable <span class="math inline">\(Z = (X -\mu)/\sigma\)</span>.</p>
<div class="exercise">
<p><em>Exercise 2.62</em>. Show that skewness of a normal random
variable <span class="math inline">\(X \sim
\mathcal{N}(\mu,\sigma^2)\)</span> is <span
class="math inline">\(0\)</span> and its kurtosis is <span
class="math inline">\(3\)</span>.</p>
</div>
<p><em>Interpretation:</em> Many natural phenomena follow approximately
a normal distribution, which can be mathematically explained by the
Central Limit Theorem, which we will encounter soon.</p>
<h1 id="multivariate-distributions">Multivariate distributions</h1>
<h2 id="random-vectors">Random vectors</h2>
<div class="definition">
<p><strong>Definition 3.1</strong>. Let <span
class="math inline">\(X_1,\ldots,X_n\)</span> be random variables, all
defined on the same probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. We call
<span class="math inline">\(X = (X_1,\ldots,X_n)^\top\)</span> an (<span
class="math inline">\(n\)</span>-dimensional) random vector.</p>
</div>
<p>Note that <span class="math inline">\(X\colon \Omega \to
\mathbb{R}^n\)</span> and we will now see that we can equivalently
characterise a random vector <span class="math inline">\(X\)</span> as a
<span class="math inline">\(\mathbb{R}^n\)</span>-valued random
variable. The Borel <span class="math inline">\(\sigma\)</span>-algebra
on <span class="math inline">\(\mathbb{R}^n\)</span> is defined
analogously to the one-dimensional case, <span
class="math display">\[\mathcal{B}(\mathbb{R}^n) \coloneq\sigma\big(\{O:
O \text{ open in } \mathbb{R}^n\} \big).\]</span></p>
<div class="definition">
<p><strong>Definition 3.2</strong>. An <span
class="math inline">\(\mathbb{R}^n\)</span>-valued random variable <span
class="math inline">\(X\)</span> on <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is a
measurable mapping between the measurable space <span
class="math inline">\((\Omega,\mathcal{F})\)</span> and <span
class="math inline">\((\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))\)</span>,
that is, <span class="math inline">\(X\colon \Omega \to
\mathbb{R}^n\)</span> and <span class="math display">\[\forall B \in
\mathcal{B}(\mathbb{R}^n): X^{-1}(B) \in \mathcal{F}.\]</span></p>
</div>
<p>To see the equivalence between both definitions, note that it can be
shown that <span class="math display">\[\mathcal{B}(\mathbb{R}^n) =
\sigma\big(\underbrace{\mathcal{B}(\mathbb{R}) \times \cdots \times
\mathcal{B}(\mathbb{R})}_{n \text{ times}}\big).\]</span> Thus,
according to Proposition <a href="#prop:meas_gen"
data-reference-type="ref" data-reference="prop:meas_gen">2.2</a>, to
show that a random vector <span class="math inline">\(X =
(X_1,\ldots,X_n)^\top\)</span> is <span
class="math inline">\(\mathcal{F}/\mathcal{B}(\mathbb{R}^n)\)</span>-measurable
and thereby an <span class="math inline">\(\mathbb{R}^n\)</span>-valued
random variable, it suffices to show that for any Cartesian product
<span class="math display">\[B = \bigtimes_{i=1}^n B_i, \quad
B_1,\ldots,B_n \in \mathcal{B}(\mathbb{R}),\]</span> it holds that <span
class="math inline">\(X^{-1}(B) \in \mathcal{F}\)</span>. This follows
from <span class="math display">\[X^{-1}(B_1 \times \cdots \times B_n)
=\big\{\omega \in \Omega: X_i(\omega) \in B_i \, \forall i =
1,\ldots,n\big\} = \bigcap_{i=1}^n \underbrace{X_i^{-1}(B_i)}_{\in
\mathcal{F}} \in \mathcal{F},\]</span> whence any <span
class="math inline">\(n\)</span>-dimensional random vector is an <span
class="math inline">\(\mathbb{R}^n\)</span>-valued random variable.
Conversely, if <span class="math inline">\(X =
(X_1,\ldots,X_n)^\top\)</span> is an <span
class="math inline">\(\mathbb{R}^n\)</span>-valued random variable, then
for any <span class="math inline">\(i=1,\ldots,n\)</span> and <span
class="math inline">\(B \in \mathcal{B}(\mathbb{R})\)</span>, <span
class="math display">\[X_i^{-1}(B) = X^{-1}(\overbrace{\mathbb{R}\times
\cdots \times \underbrace{B}_{\mathclap{i\text{-th entry}}} \times
\cdots \times \mathbb{R}}^{\in \mathcal{B}(\mathbb{R}^n)}) \in
\mathcal{F},\]</span> so each of the coordinate mappings <span
class="math inline">\(X_i\)</span> is a (<span
class="math inline">\(\mathbb{R}\)</span>-valued) random variable on
<span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. We
cast this observation in a lemma.</p>
<div class="lemma">
<p><strong>Lemma 3.3</strong>. <em>Every <span
class="math inline">\(n\)</span>-dimensional random vector is an <span
class="math inline">\(\mathbb{R}^n\)</span>-valued random variable and
vice versa.</em></p>
</div>
<p>With this observation, it makes sense to speak of the distribution
<span class="math inline">\(\mathbb{P}_X\)</span> of a random
vector.</p>
<div class="definition">
<p><strong>Definition 3.4</strong>. We call any probability measure on
<span
class="math inline">\((\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))\)</span>
a <em>multivariate distribution</em> and define the joint distribution
<span class="math inline">\(\mathbb{P}_X = \mathbb{P}_{X_1 \otimes
\cdots \otimes X_n}\)</span> of a random vector <span
class="math inline">\(X = (X_1,\ldots,X_n)^\top\)</span> by the
pushforward measure <span class="math display">\[\mathbb{P}_{X_1 \otimes
\cdots \otimes X_n}(B) \coloneq\mathbb{P}(X^{-1}(B)), \quad B \in
\mathcal{B}(\mathbb{R}^n).\]</span></p>
</div>
<p>In complete analogy to the one-dimensional case it can be shown that
this indeed defines a probability measure on <span
class="math inline">\((\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))\)</span>.
We leave the details to you.</p>
<div class="theorem">
<p><strong>Theorem 3.5</strong>. <em>The joint distribution of a random
vector is a multivariate distribution.</em></p>
</div>
<p>Let us now introduce the natural analogue to a cdf in the
multivariate case.</p>
<div class="definition">
<p><strong>Definition 3.6</strong>. Let <span class="math inline">\(X =
(X_1,\ldots,X_n)^\top\)</span> be a random vector. Its <em>multivariate
distribution function</em> <span class="math inline">\(F_X\colon
\mathbb{R}^n \to [0,1]\)</span> is defined by <span
class="math display">\[F_X(x_1,\ldots,x_n)
\coloneq\mathbb{P}_X\big((-\infty,x_1],\ldots,(-\infty,x_n]\big) =
\mathbb{P}(X_1 \leq x_1,\ldots,X_n \leq x_n), \quad x_1,\ldots,x_n \in
\mathbb{R}.\]</span> Moreover, we call <span
class="math inline">\(\mathbb{P}_{X_i}\)</span> the marginal
distribution of <span class="math inline">\(X_i\)</span>.</p>
</div>
<div class="remark">
<p><em>Remark 3.7</em>. Given a multivariate distribution, its marginal
distributions are obtained via the relation <span
class="math display">\[\mathbb{P}_{X_i}(B) = \mathbb{P}_{X_1 \otimes
\cdots \otimes X_n}(\mathbb{R}\times \cdots \times
\underbrace{B}_{\mathclap{i\text{-th entry}}} \times \cdots \times
\mathbb{R}).\]</span></p>
</div>
<p>As in the one-dimensional case, the multivariate cdf uniquely
characterises a multivariate distribution.</p>
<div id="theo:multi_cdf" class="theorem">
<p><strong>Theorem 3.8</strong>. <em>Suppose that <span
class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> are two random vectors. Then, <span
class="math display">\[\mathbb{P}_X = \mathbb{P}_Y \iff F_X =
F_Y.\]</span></em></p>
</div>
<p>We can again construct multivariate distributions in terms of an
appropriate change of measure. We will be primarily dealing with
continuous multivariate distribution, which are constructed via Lebesgue
integrals w.r.t. the multivariate Lebesgue measure, which is the unique
measure on <span
class="math inline">\((\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))\)</span>
that assigns a hypercuboid its natural volume, i.e., <span
class="math display">\[\lambda_n((a_1,b_1] \times \cdots \times
(a_n,b_n]) = \prod_{i=1}^n (b_i - a_i) = \prod_{i=1}^n
\lambda((a_i,b_i]), \quad a_i,b_i \in \mathbb{R}\text{ for all } i =1,
\ldots,n.\]</span></p>
<div class="definition">
<p><strong>Definition 3.9</strong>. We say that a random vector <span
class="math inline">\(X = (X_1,\ldots,X_n)^\top\)</span> is absolutely
continuous, if there exists a non-negative measurable function <span
class="math inline">\(f\colon \mathbb{R}^n \to \mathbb{R}\)</span> such
that <span class="math inline">\(\int_{\mathbb{R}^n} f(x)
\mathop{}\!\mathrm{d} {x} \equiv \int_{\mathbb{R}^d} f(x)
\mathop{}\!\mathrm{d} {\lambda_n(x)} = 1\)</span> and <span
class="math display">\[\mathbb{P}_X(B) = \int_B f(x)
\mathop{}\!\mathrm{d} {x} \equiv \int_B f(x_1,\ldots,x_n)
\mathop{}\!\mathrm{d} {\lambda_n(x_1,\ldots,x_n)}, \quad B \in
\mathcal{B}(\mathbb{R}^n).\]</span></p>
</div>
<div class="remark">
<p><em>Remark 3.10</em>. Using the general Proposition <a
href="#prop:meas_change" data-reference-type="ref"
data-reference="prop:meas_change">2.26</a>, it follows that any such
<span class="math inline">\(f\)</span> indeed yields a probability
measure.</p>
</div>
<p>Next we state the analogue to Theorem <a href="#theo:trafo"
data-reference-type="ref" data-reference="theo:trafo">2.32</a> that
tells us how to calculate the expectation of the one-dimensional random
variable <span class="math inline">\(g(X_1,\ldots,X_n)\)</span> obtained
from transforming the random vector with a function <span
class="math inline">\(g\colon \mathbb{R}^n \to \mathbb{R}\)</span>.</p>
<div id="theo:trans_multi" class="theorem">
<p><strong>Theorem 3.11</strong>. <em>Let <span class="math inline">\(X
= (X_1,\ldots,X_n)^\top\)</span> be a random vector. Suppose that <span
class="math inline">\(g\colon \mathbb{R}^n \to \mathbb{R}\)</span> is a
measurable function that is either non-negative or such that <span
class="math inline">\(\int_{\mathbb{R}^n} \lvert g(x_1,\ldots,x_n)\rvert
\mathop{}\!\mathrm{d} {\mathbb{P}_X(x_1,\ldots,x_n)} &lt;
\infty\)</span>. Then, <span
class="math display">\[\mathbb{E}[g(X_1,\ldots,X_n)] =
\int_{\mathbb{R}^n} g(x_1,\ldots,x_n) \mathop{}\!\mathrm{d}
{\mathbb{P}_{X_1 \otimes \cdots \otimes
X_n}(x_1,\ldots,x_n)}.\]</span></em></p>
</div>
<h3 id="product-measures-and-fubinis-theorem">Product measures and
Fubini’s theorem</h3>
<p>Calculating such expectations can be very challenging, unless the
joint distribution has a fairly nice structure. The essential tool in
such situations is Fubini’s theorem. This, however, first requires the
understanding of a <em>product measure</em>, which we will also heavily
encounter in the next section on independence. Let <span
class="math inline">\((E_1,\mathcal{A}_1,\mu_1)\)</span> and <span
class="math inline">\((E_2,\mathcal{A}_2,\mu_2)\)</span> be <span
class="math inline">\(\sigma\)</span>-finite measure spaces. The product
<span class="math inline">\(\sigma\)</span>-algebra is defined as <span
class="math display">\[\mathcal{A}_1 \otimes \mathcal{A}_2
\coloneq\sigma(\mathcal{A}_1 \times \mathcal{A}_2) = \sigma\big(\{A_1
\times A_2: A_1 \in \mathcal{A}_1, A_2 \in \mathcal{A}_2\}
\big),\]</span> and the product measure <span
class="math inline">\(\mu_1 \otimes \mu_2\)</span> is the unique measure
on <span class="math inline">\(\mathcal{A}_1 \otimes
\mathcal{A}_2\)</span> that satisfies <span
class="math display">\[\forall A_1 \times A_2 \in \mathcal{A}_1 \times
\mathcal{A}_2: \quad \mu_1 \otimes \mu_2(A_1 \times A_2) = \mu_1(A_1)
\mu_2(A_2).\]</span> Observe here that we have already encountered such
a product measure before: the multivariate Lebesgue measure <span
class="math inline">\(\lambda_n\)</span>.</p>
<p>Fubini’s theorem now tells us that for product measures and
non-negative transformations <span class="math inline">\(g\)</span>, we
may always integrate in arbitrary order.</p>
<div class="theorem">
<p><strong>Theorem 3.12</strong> (Fubini’s theorem). <em>Let <span
class="math inline">\((E_1,\mathcal{A}_1,\mu_1)\)</span> and <span
class="math inline">\((E_2,\mathcal{A}_2,\mu_2)\)</span> be <span
class="math inline">\(\sigma\)</span>-finite measure spaces. Let <span
class="math inline">\(g\colon E_1 \times E_2 \to [0,\infty)\)</span> be
a measurable function w.r.t. the product <span
class="math inline">\(\sigma\)</span>-algebra <span
class="math inline">\(\mathcal{A}_1 \otimes \mathcal{A}_2\)</span>.
Then,<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> <span
class="math display">\[\int_{E_1 \times E_2} g \mathop{}\!\mathrm{d}
{\mu_1 \otimes \mu_2} = \int_{E_2}\Big(\int_{E_1} g(x,y)
\mathop{}\!\mathrm{d} {\mu_1(x)} \Big) \mathop{}\!\mathrm{d} {\mu_2(y)}
=\int_{E_1}\Big(\int_{E_2} g(x,y) \mathop{}\!\mathrm{d} {\mu_2(y)} \Big)
\mathop{}\!\mathrm{d} {\mu_1(x)}.\]</span></em></p>
</div>
<p>Iterating this theorem yields the following for continuous random
vectors.</p>
<div class="corollary">
<p><strong>Corollary 3.13</strong>. <em>Let <span
class="math inline">\(X = (X_1,\ldots,X_n)^\top\)</span> be a random
vector with multivariate density <span class="math inline">\(f\)</span>
and <span class="math inline">\(g\colon \mathbb{R}^n \to
[0,\infty)\)</span> be measurable. Then, for any permutation <span
class="math inline">\((i_1,\ldots,i_n)\)</span> of <span
class="math inline">\(\{1,\ldots,n\}\)</span> it holds that <span
class="math display">\[\mathbb{E}[g(X_1,\ldots,X_n)] = \int_{\mathbb{R}}
\Big(\int_{\mathbb{R}} \Big(\cdots \int_{\mathbb{R}} g(x_1,\ldots,x_n)
f(x_1,\ldots,x_n) \mathop{}\!\mathrm{d} {x_{i_1}} \cdots
\Big)\mathop{}\!\mathrm{d} {x_{i_{n-1}}}\Big)\mathop{}\!\mathrm{d}
{x_{i_n}}.\]</span></em></p>
</div>
<div class="remark">
<p><em>Remark 3.14</em>. Because the order of integration does not
matter, in short we may therefore just write <span
class="math display">\[\mathbb{E}[g(X_1,\ldots,X_n)] =
\int_{\mathbb{R}^n} g(x_1,\ldots,x_n) f(x_1,\ldots,x_n)
\mathop{}\!\mathrm{d} {x_1}\cdots \mathop{}\!\mathrm{d} {x_n}.\]</span>
In particular, for any <span class="math inline">\(i \in
\{1,\ldots,n\}\)</span> we get <span
class="math display">\[\mathbb{P}(X_i \in B) = \int_B
\Big(\int_{\mathbb{R}^{n-1}} f(x_1,\ldots,x_n) \mathop{}\!\mathrm{d}
{x_1} \cdots \mathop{}\!\mathrm{d} {x_{i-1}} \mathop{}\!\mathrm{d}
{x_{i+1}}\cdots \mathop{}\!\mathrm{d} {x_n}\Big) \mathop{}\!\mathrm{d}
{x_i},\]</span> so the marginal <span class="math inline">\(X_i\)</span>
is absolutely continuous with density <span
class="math display">\[f_i(x_i) \coloneq\int_{\mathbb{R}^{n-1}}
f(x_1,\ldots,x_n) \mathop{}\!\mathrm{d} {x_1} \cdots
\mathop{}\!\mathrm{d} {x_{i-1}} \mathop{}\!\mathrm{d} {x_{i+1}}\cdots
\mathop{}\!\mathrm{d} {x_n}, \quad x_i \in \mathbb{R},\]</span> which we
call the <span class="math inline">\(i\)</span>-th <em>marginal
density</em>.</p>
</div>
<h3 id="expectation-and-covariance">Expectation and covariance</h3>
<p>Given a random vector we define its expectation to be the vector of
expectations of the marginals.</p>
<div class="definition">
<p><strong>Definition 3.15</strong>. For a random vector <span
class="math inline">\(X = (X_1,\ldots,X_n)^\top\)</span> with
well-defined marginal expectations <span
class="math inline">\(\mathbb{E}[X_i]\)</span>, <span
class="math inline">\(i=1,\ldots,n\)</span>, its expectation is defined
as the vector <span class="math display">\[\mathbb{E}[X]
\coloneq(\mathbb{E}[X_1],\ldots,\mathbb{E}[X_n])^\top.\]</span></p>
</div>
<div class="definition">
<p><strong>Definition 3.16</strong>.  </p>
<ol>
<li><p>For two random variables <span class="math inline">\(X,Y\)</span>
that are defined on the same probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> and are
such that <span class="math inline">\(\mathbb{E}[X^2],\mathbb{E}[Y^2]
&lt; \infty\)</span>, their covariance is defined as <span
class="math display">\[\operatorname{Cov}(X,Y)\coloneq\mathbb{E}\big[(X
- \mathbb{E}[X])(Y - \mathbb{E}[Y])\big].\]</span> If <span
class="math inline">\(\mathop{\mathrm{Cov}}(X,Y) = 0\)</span> we call
<span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> uncorrelated. If <span
class="math inline">\(\mathop{\mathrm{Var}}{X}, \mathop{\mathrm{Var}}{Y}
&gt; 0\)</span>, their correlation is defined by <span
class="math display">\[\rho_{X,Y}
\coloneq\frac{\mathop{\mathrm{Cov}}(X,Y)}{\sqrt{\mathop{\mathrm{Var}}(X)\mathop{\mathrm{Var}}(Y)}}
= \frac{\mathop{\mathrm{Cov}}(X,Y)}{\sigma_X
\sigma_Y}.\]</span></p></li>
<li><p>The covariance matrix of a random vector <span
class="math inline">\(X = (X_1,\ldots,X_n)\)</span> is defined as <span
class="math display">\[\Sigma_X
\coloneq\big(\operatorname{Cov}(X_i,X_j)\big)_{i,j=1,\ldots,n} =
\begin{pmatrix} \mathop{\mathrm{Cov}}(X_1,X_1) &amp; \cdots &amp;
\mathop{\mathrm{Cov}}(X_1,X_n)\\ \vdots &amp; \ddots &amp; \vdots\\
\mathop{\mathrm{Cov}}(X_n,X_1) &amp; \cdots &amp;
\mathop{\mathrm{Cov}}(X_n,X_n)\end{pmatrix}.\]</span></p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 3.17</em>. We equivalently use the notation <span
class="math inline">\(\Sigma_X \equiv \mathbb{E}[(X - \mathbb{E}[X])(X-
\mathbb{E}[X])^\top]\)</span>.</p>
</div>
<div class="exercise">
<p><em>Exercise 3.18</em>. Show that</p>
<ol>
<li><p>for any <span class="math inline">\(a,b \in \mathbb{R}\)</span>,
<span class="math inline">\(\mathop{\mathrm{Cov}}(aX,bY) = ab
\mathop{\mathrm{Cov}}(X,Y)\)</span>.</p></li>
<li><p><span class="math inline">\(\mathop{\mathrm{Cov}}(X,Y) =
0\)</span> if <span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> are independent (see next subsection
for definition of independence).</p></li>
<li><p><span class="math inline">\(\rho_{X,Y} \in [-1,1]\)</span> if the
correlation is well-defined.</p></li>
</ol>
</div>
<div id="ex:var_sum" class="exercise">
<p><em>Exercise 3.19</em>. Suppose that <span
class="math inline">\((X_1,\ldots,X_n)^\top\)</span> is a random vector
such that <span class="math inline">\(\mathbb{E}[X_i^2] &lt;
\infty\)</span> for all <span class="math inline">\(i
=1,\ldots,n\)</span>. Show that <span
class="math display">\[\mathop{\mathrm{Var}}(X_1 + \cdots + X_n) =
\sum_{i=1}^n \mathop{\mathrm{Var}}(X_i) + \sum_{i \neq j}
\mathop{\mathrm{Cov}}(X_i,X_j).\]</span> Conclude that <span
class="math inline">\(\mathop{\mathrm{Var}}(X_1 + \cdots + X_n) =
\sum_{i=1}^n \mathop{\mathrm{Var}}(X_i)\)</span>, if <span
class="math inline">\(X_1,\ldots,X_n\)</span> are pairwise
uncorrelated.</p>
</div>
<div class="exercise">
<p><em>Exercise 3.20</em>. Let <span class="math inline">\(X\)</span> be
an <span class="math inline">\(n\)</span>-dimensional random vector.
Show that</p>
<ol>
<li><p><span class="math inline">\(\Sigma_X\)</span> is positive
semi-definite, i.e., for any column vector <span class="math inline">\(a
\in \mathbb{R}^n\)</span> it holds that <span
class="math inline">\(a^\top \Sigma_X a \geq 0\)</span>.</p></li>
<li><p>for <span class="math inline">\(b \in \mathbb{R}^k\)</span> and
<span class="math inline">\(A \in \mathbb{R}^{k \times n}\)</span> a
<span class="math inline">\((k \times n)\)</span>-matrix, it holds that
<span class="math inline">\(\Sigma_{b + AX} =
A\Sigma_XA^\top\)</span>.</p></li>
</ol>
</div>
<h2 id="independence">Independence</h2>
<p>The standard assumption in statistics is the following: we are given
<span class="math inline">\(n\)</span> random samples <span
class="math inline">\(X_1,\ldots,X_n\)</span> that are
<em>independent</em> and follow a common distribution <span
class="math inline">\(P\)</span> that we wish to infer from the data.
The definition of independence of random variables naturally derives
from independence of events that we discussed in Chapter <a
href="#chap:prob" data-reference-type="ref"
data-reference="chap:prob">1</a>.</p>
<div class="definition">
<p><strong>Definition 3.21</strong> (Independence of random variables).
 </p>
<ol>
<li><p>Let <span class="math inline">\(X_1,\ldots,X_n\)</span> be random
variables, all defined on the same probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. We say
that <span class="math inline">\(X_1,\ldots,X_n\)</span> are
<em>independent</em> if <span class="math display">\[\forall
B_1,\ldots,B_n \in \mathcal{B}(\mathbb{R}): \quad \mathbb{P}(X_1 \in
B_1,\ldots, X_n \in B_n) = \prod_{i=1}^n \mathbb{P}(X_i \in
B_i).\]</span> If additionally <span
class="math inline">\(\mathbb{P}_{X_1} = \cdots =
\mathbb{P}_{X_n}\)</span> we say that <span
class="math inline">\(X_1,\ldots,X_n\)</span> are i.i.d. (independent
and identically distributed). We then also call <span
class="math inline">\(X_1,\ldots,X_n\)</span> an
<em>i.i.d. sample</em></p></li>
<li><p>A sequence of random variables <span
class="math inline">\(X_1,X_2,\ldots\)</span> on a common probability
space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> is
defined to be independent (resp., i.i.d) if for any <span
class="math inline">\(n \in \mathbb{N}\)</span> the random variables
<span class="math inline">\(X_1,\ldots,X_n\)</span> are independent
(resp., i.i.d.).</p></li>
</ol>
</div>
<p>In terms of the joint distribution and the product distribution, the
definition of independence reads equivalently <span
class="math display">\[\mathbb{P}_{X_1 \otimes \cdots \otimes X_n}(B) =
\mathbb{P}_{X_1}\otimes \cdots \otimes \mathbb{P}_{X_n}(B), \quad
\forall B \in \bigtimes_{i=1}^n \mathcal{B}(\mathbb{R}).\]</span> Since
<span class="math inline">\(\times_{i=1}^n
\mathcal{B}(\mathbb{R})\)</span> is a <span
class="math inline">\(\cap\)</span>-stable generator of <span
class="math inline">\(\mathcal{B}(\mathbb{R}^n)\)</span> and probability
measures are uniquely characterised on such, we obtain the following
nice formula.</p>
<div id="prop:indep" class="proposition">
<p><strong>Proposition 3.22</strong>. <em>A family of random variables
<span class="math inline">\(X_1,\ldots,X_n\)</span> is independent if,
and only if, <span class="math display">\[\mathbb{P}_{X_1 \otimes \cdots
\otimes X_n} = \mathbb{P}_{X_1} \otimes \cdots \otimes
\mathbb{P}_{X_n}.\]</span></em></p>
</div>
<p>Based on this we collect other useful characterisations of
independence.</p>
<div class="corollary">
<p><strong>Corollary 3.23</strong>. <em>A family of random variables
<span class="math inline">\(X_1,\ldots,X_n\)</span> is independent if,
and only if, for every collection <span
class="math inline">\(g_1,\ldots,g_n \colon \mathbb{R}\to
\mathbb{R}\)</span> of measurable, non-negative functions it holds that
<span class="math display">\[\label{eq:indep}
\mathbb{E}\Big[\prod_{i=1}^n g_i(X_i) \Big] = \prod_{i=1}^n
\mathbb{E}[g_i(X_i)].\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Suppose that <span
class="math inline">\(X_1,\ldots,X_n\)</span> are independent. Then,
using Theorem <a href="#theo:trans_multi" data-reference-type="ref"
data-reference="theo:trans_multi">3.11</a>, Proposition <a
href="#prop:indep" data-reference-type="ref"
data-reference="prop:indep">3.22</a> and Fubini’s theorem, we have <span
class="math display">\[\begin{aligned}
\mathbb{E}\Big[\prod_{i=1}^n g_i(X_i) \Big] &amp;= \int_{\mathbb{R}^n}
g_1(x_1)\cdots g_n(x_n) \mathop{}\!\mathrm{d} {\mathbb{P}_{X_1} \otimes
\dots \otimes \mathbb{P}_{X_n}(x_1,\ldots,x_n})\\
&amp;= \int_{\mathbb{R}^{n-1}} \Big(\int_{\mathbb{R}}
g_1(x_1)\prod_{i=2}^n g_i(x_i) \mathop{}\!\mathrm{d}
{\mathbb{P}_{X_1}(x_1)}\Big) \mathop{}\!\mathrm{d}
{\mathbb{P}_{X_2}\otimes \cdots \otimes
\mathbb{P}_{X_n}(x_2,\ldots,x_n)}\\
&amp;\overset{\text{lin.}}{=} \int_{\mathbb{R}^{n-1}} \prod_{i=2}^n
g_i(x_i) \Big(\int_{\mathbb{R}} g_1(x_1) \mathop{}\!\mathrm{d}
{\mathbb{P}_{X_1}(x_1)}\Big) \mathop{}\!\mathrm{d}
{\mathbb{P}_{X_2}\otimes \cdots \otimes
\mathbb{P}_{X_n}(x_2,\ldots,x_n)}\\
&amp;\overset{\text{lin.}}{=} \int_{\mathbb{R}} g_1(x_1)
\mathop{}\!\mathrm{d} {\mathbb{P}_{X_1}(x_1)} \int_{\mathbb{R}^{n-1}}
\prod_{i=2}^n g_i(x_i) \mathop{}\!\mathrm{d} {\mathbb{P}_{X_2}\otimes
\cdots \otimes \mathbb{P}_{X_n}(x_2,\ldots,x_n)}.
\end{aligned}\]</span> Iterating the argument and then using Theorem <a
href="#theo:trafo" data-reference-type="ref"
data-reference="theo:trafo">2.32</a> yields <span
class="math display">\[\mathbb{E}\Big[\prod_{i=1}^n g_i(X_i) \Big] =
\prod_{i=1}^n \int_{\mathbb{R}} g_i(x_i) \mathop{}\!\mathrm{d}
{\mathbb{P}_{X_i}(x_i)} = \prod_{i=1}^n \mathbb{E}[g_i(X_i)].\]</span>
If conversely <a href="#eq:indep" data-reference-type="eqref"
data-reference="eq:indep">[eq:indep]</a> holds for any collection of
non-negative measurable functions, we choose <span
class="math inline">\(g_i = \bm{1}_{B_i}\)</span> for arbitrary <span
class="math inline">\(B_i \in \mathcal{B}(\mathbb{R})\)</span> to
conclude independence of <span
class="math inline">\(X_1,\ldots,X_n\)</span>. ◻</p>
</div>
<div class="corollary">
<p><strong>Corollary 3.24</strong>. <em>A family of random variables
<span class="math inline">\(X_1,\ldots,X_n\)</span> is independent if,
and only if, <span class="math display">\[\forall x_1,\ldots,x_n \in
\mathbb{R}: \quad F_{X_1 \otimes \cdots \otimes X_n}(x_1,\ldots,x_n) =
\prod_{i=1}^n F_{X_i}(x_i).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Follows from Proposition <a href="#prop:indep"
data-reference-type="ref" data-reference="prop:indep">3.22</a> and
Theorem <a href="#theo:multi_cdf" data-reference-type="ref"
data-reference="theo:multi_cdf">3.8</a>. ◻</p>
</div>
<div class="corollary">
<p><strong>Corollary 3.25</strong>. <em>If <span
class="math inline">\(X_1,\ldots,X_n\)</span> are independent and <span
class="math inline">\(g_1,\ldots,g_n \colon \mathbb{R}\to
\mathbb{R}\)</span> are measurable functions, then <span
class="math inline">\(g_1(X_1),\ldots,g_n(X_n)\)</span> are independent
as well.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Exercise! ◻</p>
</div>
<div class="corollary">
<p><strong>Corollary 3.26</strong>. <em>Suppose that <span
class="math inline">\(X = (X_1,\ldots,X_n)^\top\)</span> is a continuous
random vector with multivariate density <span
class="math inline">\(f\)</span> and marginal densities <span
class="math inline">\(f_i\)</span>. Then, <span
class="math inline">\(X_1,\ldots,X_n\)</span> are independent if, and
only if, for <span class="math inline">\(\lambda_n\)</span>-a.e. <span
class="math inline">\(x \in \mathbb{R}^n\)</span> we have <span
class="math display">\[f(x_1,\ldots,x_n) = \prod_{i=1}^n
f_i(x_i).\]</span></em></p>
</div>
<p>Our final corollary of this section pertains to sums of independent
random variables, which we will encounter frequently in the next
chapters.</p>
<div id="coro:mgf" class="corollary">
<p><strong>Corollary 3.27</strong>. <em>If <span
class="math inline">\(X_1,\ldots,X_n\)</span> are independent, then for
the mgf of <span class="math inline">\(\sum_{i=1}^n X_i\)</span> it
holds that <span class="math display">\[\psi_{\sum_{i=1}^n X_i}(t) =
\prod_{i=1}^n \psi_{X_i}(t), \quad t \in \mathbb{R}.\]</span> In
particular, if <span class="math inline">\(X_1,\ldots,X_n\)</span> are
i.i.d. with <span class="math inline">\(\mathbb{P}_{X_i} =
\mathbb{P}_X\)</span> for all <span class="math inline">\(i\)</span>, we
have <span class="math display">\[\psi_{\sum_{i=1}^n X_i}(t) =
\big(\psi_X(t))^n.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Exercise! ◻</p>
</div>
<div class="example">
<p><em>Example 3.28</em> (Revisiting the binomial distribution). When we
introduced the binomial distribution <span
class="math inline">\(\mathrm{Bin}(n,p)\)</span>, we interpreted it as
modeling the number of successes in <span
class="math inline">\(n\)</span> independent Bernoulli trials, without
having a meaningful definition of independence at hand. We can make this
precise now: let <span class="math inline">\(X_1,\ldots, X_n\)</span> be
i.i.d. random variables such that <span class="math inline">\(X_1 \sim
\mathcal{B}(p)\)</span>. Then, <span class="math inline">\(\psi_{X_i}(t)
= p\mathrm{e}^t + 1 - p\)</span> and by Corollary <a href="#coro:mgf"
data-reference-type="ref" data-reference="coro:mgf">3.27</a> it follows
that <span class="math display">\[\psi_{X_1 + \cdots + X_n}(t) =
(p\mathrm{e}^t + 1 -p)^n = \psi_X(t),\quad t \in \mathbb{R},\]</span>
where <span class="math inline">\(X \sim \mathrm{Bin}(n,p)\)</span>.
Since by Theorem <a href="#theo:mom_gen" data-reference-type="ref"
data-reference="theo:mom_gen">2.49</a> the mgf uniquely characterises
the distribution of a random variable it follows that <span
class="math display">\[X_1 + \cdots + X_n \overset{d}{=} X.\]</span></p>
</div>
<div class="exercise">
<p><em>Exercise 3.29</em>. Suppose that <span class="math inline">\(X,
Y\)</span> are independent and continuous random variables with
densities <span class="math inline">\(f_X, f_Y\)</span> respectively.
Show that the density <span class="math inline">\(f_{X+Y}\)</span> of
<span class="math inline">\(X + Y\)</span> is given by the convolution
<span class="math display">\[f_{X+Y}(z) = f_X \ast f_Y(z)
\coloneq\int_{\mathbb{R}} f_X(x) f_Y(z-x) \mathop{}\!\mathrm{d} {x},
\quad z \in \mathbb{R}.\]</span></p>
</div>
<div class="exercise">
<p><em>Exercise 3.30</em>. Let <span
class="math inline">\(\lambda_1,\lambda_2 &gt; 0\)</span> and let <span
class="math inline">\(X_1 \sim \operatorname{Exp}(\lambda_1)\)</span>
and <span class="math inline">\(X_2 \sim
\operatorname{Exp}(\lambda_2)\)</span> be independent. Show that <span
class="math inline">\(\min\{X_1,X_2\} \sim \operatorname{Exp}(\lambda_1
+ \lambda_2)\)</span>.</p>
</div>
<div class="exercise">
<p><em>Exercise 3.31</em>. Let <span class="math inline">\(X_1 \sim
\mathcal{N}(\mu_1,\sigma_1^2)\)</span> and <span
class="math inline">\(X_2 \sim \mathcal{N}(\mu_2,\sigma_2^2)\)</span> be
independent. Show that <span class="math inline">\(X_1 + X_2 \sim
\mathcal{N}(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)\)</span>.</p>
</div>
<h3 id="multivariate-normal-distribution">Multivariate normal
distribution</h3>
<div class="definition">
<p><strong>Definition 3.32</strong>. Let <span class="math inline">\(\mu
\in \mathbb{R}^n\)</span> and <span class="math inline">\(\Sigma \in
\mathbb{R}^{n \times n}\)</span> be a symmetric positive semi-definite
matrix. A random vector <span class="math inline">\(X =
(X_1,\ldots,X_n)^\top\)</span> is defined to have a multivariate normal
(or Gaussian) distribution with mean vector <span
class="math inline">\(\mu\)</span> and covariance matrix <span
class="math inline">\(\Sigma\)</span>, if for any real numbers <span
class="math inline">\(a_1,\ldots,a_n\)</span>, <span
class="math display">\[a^\top X = \sum_{i=1} a_i X_i \sim
\mathcal{N}\big(a^\top \mu, a^\top \Sigma a  \big) =
\mathcal{N}\Big(\sum_{i=1}^n a_i\mu_i, \sum_{i,j=1}^n a_ia_j
\Sigma_{i,j}\Big).\]</span></p>
</div>
<p>It is immediate from this definition that every entry <span
class="math inline">\(X_i\)</span> of a multivariate normal vector is
normally distributed as well with <span class="math inline">\(X_i \sim
\mathcal{N}(\mu_i, \Sigma_{i,i})\)</span>. It is important to remember
however that if we are given <span class="math inline">\(X_i \sim
\mathcal{N}(\mu,\sigma^2_i)\)</span>, <span class="math inline">\(i=
1,\ldots,n\)</span>, then <span
class="math inline">\((X_1,\ldots,X_n)^\top\)</span> is <em>not
necessarily</em> a multivariate random vector. If <span
class="math inline">\(\mu = 0\)</span> and <span
class="math inline">\(\Sigma = \mathbb{I}_n\)</span> is the identity,
i.e., <span class="math inline">\(\mathop{\mathrm{Cov}}(X_i,X_j) =
\bm{1}_{\{i\}}(j)\)</span>, <span class="math inline">\(X \sim
\mathcal{N}(0,\mathbb{I}_n)\)</span> is called a <em>standard normal
random vector</em>.</p>
<p>Multivariate normal distributions can always be generated by linearly
transforming a standard normal random vector. Let <span
class="math inline">\(\Sigma^{1/2} \in \mathbb{R}^{n \times n}\)</span>
denote the symmetric square root of a covariance matrix <span
class="math inline">\(\Sigma\)</span>, that is <span
class="math inline">\(\Sigma = \Sigma^{1/2} \Sigma^{1/2} = \Sigma^{1/2}
(\Sigma^{1/2})^\top\)</span> (the square root always exists because we
have seen that covariance matrices are symmetric positive
semi-definite).</p>
<div id="theo:mult_normal" class="theorem">
<p><strong>Theorem 3.33</strong>. <em><span class="math inline">\(X \sim
\mathcal{N}(\mu,\Sigma)\)</span> if, and only if, <span
class="math inline">\(X \overset{d}{=} \mu + \Sigma^{1/2} Z\)</span> for
a standard normal random vector <span
class="math inline">\(Z\)</span>.</em></p>
</div>
<p>For the proof we use the fact that the distribution of a random
vector is uniquely characterised by the distributions of all linear
combinations of its components, which can be proven via multivariate
characteristic functions (not part of this module).</p>
<div class="theorem">
<p><strong>Theorem 3.34</strong>. <em>For two <span
class="math inline">\(n\)</span>-dimensional random vectors <span
class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> it holds that <span
class="math display">\[X \overset{d}{=} Y \iff \forall a \in
\mathbb{R}^n:  a^\top X \overset{d}{=} a^\top Y.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof of Theorem <a href="#theo:mult_normal"
data-reference-type="ref"
data-reference="theo:mult_normal">3.33</a>.</em> By the previous theorem
it suffices to check that <span class="math inline">\(a^\top X
\overset{d}{=} a^\top(\mu + \Sigma^{1/2} Z)\)</span> for any <span
class="math inline">\(a \in \mathbb{R}^n\)</span> and some <span
class="math inline">\(Z \sim \mathcal{N}(0,\mathbb{I}_n)\)</span>. By
definition of <span class="math inline">\(X\)</span> and <span
class="math inline">\(Z\)</span> it holds that <span
class="math inline">\(a^\top X \sim \mathcal{N}(a^\top \mu, a^\top
\Sigma a)\)</span> and <span class="math display">\[a^\top(\mu +
\Sigma^{1/2} Z) = a^\top \mu + \underbrace{a^\top \Sigma^{1/2}
Z}_{\mathclap{\sim \mathcal{N}(0, a^\top \Sigma^{1/2}(a^\top
\Sigma^{1/2})^\top) = \mathcal{N}(0, a^\top
\Sigma^{1/2}(\Sigma^{1/2})^\top a) = \mathcal{N}(0,a^\top\Sigma a)}}
\sim \mathcal{N}(a^\top \mu, a^\top \Sigma a),\]</span> whence <span
class="math inline">\(a^\top X \overset{d}{=} a^\top(\mu +
\Sigma^{1/2}Z)\)</span>. ◻</p>
</div>
<div class="corollary">
<p><strong>Corollary 3.35</strong>. <em>If <span class="math inline">\(X
\sim \mathcal{N}(\mu,\Sigma)\)</span>, then <span
class="math inline">\(\mathop{\mathrm{Cov}}(X_i,X_j) =
\Sigma_{i,j}\)</span>.</em></p>
</div>
<p>Using a multivariate extension of the moment generating function, the
following can be established, which is a unique feature of normal random
vectors.</p>
<div id="theo:mult_normal_indep" class="theorem">
<p><strong>Theorem 3.36</strong>. <em>Let <span class="math inline">\(X
\sim \mathcal{N}(\mu,\Sigma)\)</span> be an <span
class="math inline">\(n\)</span>-dimensional normal random vector. Then
<span class="math inline">\(X_1,\ldots,X_n\)</span> are independent, if,
and only if, <span class="math inline">\(\Sigma =
\mathbb{I}_n\)</span>.</em></p>
</div>
<div class="remark">
<p><em>Remark 3.37</em>. In other words, for the components of a normal
random vector to be independent, it suffices to check that they are
pairwise uncorrelated.</p>
</div>
<p>By Theorem <a href="#theo:mult_normal_indep"
data-reference-type="ref"
data-reference="theo:mult_normal_indep">3.36</a> we know that the
multivariate density of a standard normal random vector <span
class="math inline">\(Z\)</span> is given by <span
class="math display">\[f_Z(x_1,\ldots,x_n) = \prod_{i=1}^n f_{Z_i}(x_i)
= \prod_{i=1}^n \frac{1}{\sqrt{2\pi}} \mathrm{e}^{-x_i^2/2} =
\frac{1}{(2\pi)^{n/2}} \exp\Big(-\frac{\sum_{i=1}^n x_i^2}{2} \Big) =
\frac{1}{(2\pi)^{n/2}} \exp\Big(-\frac{\lVert x \rVert^2}{2}
\Big).\]</span> Using the transformation formula from real analysis and
Theorem <a href="#theo:mult_normal" data-reference-type="ref"
data-reference="theo:mult_normal">3.33</a> it can then be shown that for
general <span class="math inline">\(X \sim
\mathcal{N}(\mu,\Sigma)\)</span> with invertible <span
class="math inline">\(\Sigma\)</span>, the density is given by <span
class="math display">\[f_X(x_1,\ldots,x_n) = f_{\mu + \Sigma^{1/2}
Z}(x_1,\ldots,x_n) = \frac{1}{\sqrt{(2\pi)^n \operatorname{det} \Sigma}}
\exp\big(-\tfrac{1}{2}(x-\mu)^\top \Sigma^{-1} (x -\mu) \big), \quad x
\in \mathbb{R}^n.\]</span></p>
<h3
id="univariate-distributions-related-to-independent-random-variables">Univariate
distributions related to independent random variables</h3>
<h4 id="gamma-distribution">Gamma distribution</h4>
<p>We say that a continuous random variable <span
class="math inline">\(X\)</span> has a Gamma distribution with shape
parameter <span class="math inline">\(\alpha\)</span> and scale
parameter <span class="math inline">\(\beta &gt; 0\)</span>, if its
density is given by <span class="math display">\[f_{\alpha,\beta}(x) =
\frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha -1} \mathrm{e}^{-\beta x}
\bm{1}_{(0,\infty)}(x),\]</span> where <span
class="math display">\[\Gamma(z) \coloneq\int_{(0,\infty)} x^{z-1}
\mathrm{e}^{-x} \mathop{}\!\mathrm{d} {x}, \quad z &gt; 0,\]</span> is
the Gamma function, which is easily shown to satisfy <span
class="math inline">\(\Gamma(1) = 1\)</span> and the recurrence relation
<span class="math display">\[\Gamma(z+1) = z \Gamma(z), \quad z &gt;
0.\]</span> Moreover, for later use we note that <span
class="math inline">\(\Gamma(1/2) = \sqrt{\pi}\)</span> since
substituting <span class="math inline">\(x = y^2\)</span> (<span
class="math inline">\(\rightsquigarrow \mathop{}\!\mathrm{d} {x} = 2y
\mathop{}\!\mathrm{d} {y})\)</span> yields <span
class="math display">\[\Gamma(1/2) = \int_{(0,\infty)} x^{-1/2}
\mathrm{e}^{-x}\mathop{}\!\mathrm{d} {x} =\int_0^\infty \frac{1}{y}
\mathrm{e}^{-y^2} 2y \mathop{}\!\mathrm{d} {y} = 2\int_0^\infty
\mathrm{e}^{-y^2} \mathop{}\!\mathrm{d} {y} = \int_{\mathbb{R}}
\mathrm{e}^{-y^2} \mathop{}\!\mathrm{d} {y} = \sqrt{\pi}.\]</span> We
then write <span class="math inline">\(X \sim
\Gamma(\alpha,\beta)\)</span>. We first note that for <span
class="math inline">\(\alpha = 1\)</span>, the Gamma distribution
coincides with an exponential distribution, that is, <span
class="math inline">\(\Gamma(1,\beta) = \mathrm{Exp}(\beta)\)</span>. As
it turns out, for <span class="math inline">\(\alpha \in
\mathbb{N}\)</span> the Gamma distribution is the distribution of the
sum of i.i.d. exponential random variables. More precisely, the mgf of
<span class="math inline">\(X \sim \Gamma(\alpha,\beta)\)</span> exists
for all <span class="math inline">\(t &lt; \beta\)</span> and is
obtained from the following calculation for <span
class="math inline">\(t &lt; \beta\)</span>: <span
class="math display">\[\begin{aligned}
\psi_X(t) &amp;= \frac{\beta^\alpha}{\Gamma(\alpha)} \int_{(0,\infty)}
\mathrm{e}^{tx} x^{\alpha -1} \mathrm{e}^{-\beta x}
\mathop{}\!\mathrm{d} {x} \notag\\
&amp;=\frac{\beta^\alpha}{\Gamma(\alpha)} \int_{(0,\infty)} x^{\alpha
-1} \mathrm{e}^{-(\beta - t) x} \mathop{}\!\mathrm{d} {x} \notag \\
&amp;=  \frac{\beta^\alpha}{\Gamma(\alpha)} \int_{(0,\infty)}(y/(\beta
-t))^{\alpha-1} \mathrm{e}^{-y} \frac{1}{\beta -t} \mathop{}\!\mathrm{d}
{y} \tag{substitution $y = (\beta -t) x$}\\
&amp;= \Big(\frac{\beta}{\beta -t}\Big)^\alpha
\underbrace{\frac{1}{\Gamma(\alpha)} \int_{(0,\infty)} y^{\alpha -1}
\mathrm{e}^{-y} \mathop{}\!\mathrm{d} {y}}_{\mathclap{= \mathbb{P}(Y
&gt; 0) = 1 \text{ for } Y \sim \Gamma(\alpha,1)}} \notag\\
&amp;= \Big(\frac{\beta}{\beta -t}\Big)^\alpha\notag.
\end{aligned}\]</span> This implies that if <span
class="math inline">\(X \sim \Gamma(\alpha,\beta)\)</span> and <span
class="math inline">\(Y \sim \Gamma(\gamma,\beta)\)</span> are
independent, then <span class="math display">\[\psi_{X+Y}(t) =
\psi_X(t)\psi_Y(t) = \Big(\frac{\beta}{\beta -t}\Big)^{\alpha + \gamma}
= \psi_{\Gamma(\alpha + \gamma,\beta)}, \quad t &lt; \beta,\]</span> and
therefore <span class="math inline">\(X+Y \sim \Gamma(\alpha +
\gamma,\beta)\)</span> by Theorem <a href="#theo:mom_gen"
data-reference-type="ref" data-reference="theo:mom_gen">2.49</a>.
Iterating this argument for <span class="math inline">\(n\)</span>
i.i.d. <span class="math inline">\(\mathrm{Exp}(\beta) =
\Gamma(1,\beta)\)</span> distributed random variables, yields <span
class="math inline">\(\sum_{i=1}^n X_i \sim \Gamma(n,\beta)\)</span>. We
cast this formally into a proposition.</p>
<div id="prop:gamma" class="proposition">
<p><strong>Proposition 3.38</strong>. <em>Let <span
class="math inline">\(\alpha,\gamma,\beta &gt; 0\)</span>. If <span
class="math inline">\(X \sim \Gamma(\alpha,\beta)\)</span> and <span
class="math inline">\(Y \sim \Gamma(\gamma,\beta)\)</span> are
independent, then <span class="math inline">\(X+ Y \sim \Gamma(\alpha +
\gamma,\beta).\)</span> In particular, if <span
class="math inline">\(X_1,\ldots,X_n\)</span> are i.i.d. with <span
class="math inline">\(X_1 \sim \mathop{\mathrm{Exp}}(\beta)\)</span> for
some <span class="math inline">\(\beta &gt; 0\)</span>, then <span
class="math inline">\(\sum_{i=1}^n X_i \sim
\Gamma(n,\beta)\)</span>.</em></p>
</div>
<h4 id="lem:chi"><span
class="math inline">\(\chi^2\)</span>-distribution</h4>
<p>The <span class="math inline">\(\chi^2\)</span>-distribution plays an
important role in statistical test theory. Its definition derives from
the following observation.</p>
<div class="lemma">
<p><strong>Lemma 3.39</strong>. <em>If <span class="math inline">\(X
\sim \mathcal{N}(0,1)\)</span>, then <span class="math inline">\(X^2
\sim \Gamma(1/2,1/2)\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Let <span class="math inline">\(g \geq 0\)</span> be
a measurable function. Then, by the transformation theorem <span
class="math display">\[\begin{aligned}
\mathbb{E}[g(X^2)] &amp;= \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}} g(x^2)
\mathrm{e}^{-\frac{x^2}{2}} \mathop{}\!\mathrm{d} {x} \notag\\
&amp;= \sqrt{\frac{2}{\pi}} \int_{(0,\infty)} g(x^2)
\mathrm{e}^{-\frac{x^2}{2}} \mathop{}\!\mathrm{d} {x}\notag\\
&amp;= \sqrt{\frac{2}{\pi}} \int_{(0,\infty)} g(y) \mathrm{e}^{-y/2}
\frac{1}{2\sqrt{y}} \mathop{}\!\mathrm{d} {y} \tag{substitution $y =
x^2$}\\
&amp;= \int_{(0,\infty)} g(y) \frac{(1/2)^{1/2}}{\Gamma(1/2)} y^{1/2-1}
\mathrm{e}^{-y/2} \mathop{}\!\mathrm{d} {y} \tag{$\Gamma(1/2) =
\sqrt{\pi}$}\\
&amp;= \mathbb{E}[g(Y)],\notag
\end{aligned}\]</span> for <span class="math inline">\(Y \sim
\Gamma(1/2,1/2)\)</span>. ◻</p>
</div>
<div class="definition">
<p><strong>Definition 3.40</strong>. The <span
class="math inline">\(\chi^2\)</span>-distribution with <span
class="math inline">\(n\)</span> degrees of freedom is defined by <span
class="math inline">\(\chi^2_n = \Gamma(n/2,1/2)\)</span>, so that the
density and mgf of <span class="math inline">\(X \sim \chi^2_n\)</span>
are respectively given by <span class="math display">\[f(x) =
\frac{1}{2^{n/2} \Gamma(n/2)} x^{n/2 -1} \mathrm{e}^{-x/2}
\bm{1}_{(0,\infty)}(x),\]</span> and <span
class="math display">\[\psi_X(t) = \frac{1}{(1-2t)^{n/2}}, \quad t &lt;
1/2.\]</span></p>
</div>
<p>Combining the previous lemma and Proposition <a href="#prop:gamma"
data-reference-type="ref" data-reference="prop:gamma">3.38</a> yields
the following.</p>
<div id="theo:normal_chi" class="theorem">
<p><strong>Theorem 3.41</strong>. <em>If <span
class="math inline">\(X_1,\ldots,X_n\)</span> are i.i.d. and <span
class="math inline">\(X_1 \sim \mathcal{N}(0,1)\)</span>, then <span
class="math display">\[\sum_{i=1}^n X_i^2 \sim
\chi^2_n.\]</span></em></p>
</div>
<h2 id="conditional-distributions-and-expectations">Conditional
distributions and expectations</h2>
<p>We now introduce conditional distributions and expectations. The
general measure theoretic route would go via specifying conditional
expectations first and then define conditional distributions from there.
For the purposes of this module, we don’t need that sort of generality
and will rather start with introducing the notion of a conditional
distribution in a restricted setting.</p>
<p>Let us therefore assume in this section that <span
class="math inline">\(X\)</span> is an <span
class="math inline">\(n\)</span>-dimensional random vector and <span
class="math inline">\(Y\)</span> is an <span
class="math inline">\(m\)</span>-dimensional random vector such that
their joint distribution can be expressed as <span
class="math display">\[\mathbb{P}_{X,Y}(B) = \int_B f_{X,Y}(x,y)
\mathop{}\!\mathrm{d} {\mu \otimes \nu(x,y)} \overset{\text{Fubini}}{=}
\int_B f_{X,Y}(x,y) \mathop{}\!\mathrm{d} {\mu(x)} \mathop{}\!\mathrm{d}
{\nu(y)} , \quad B \in \mathcal{B}(\mathbb{R}^{n+1}),\]</span> for some
dominating product measure <span class="math inline">\(\mu \otimes
\nu\)</span> (<span class="math inline">\(\mu,\nu\)</span> <span
class="math inline">\(\sigma\)</span>-finite). If both <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(\nu\)</span> are Lebesgue measures, <span
class="math inline">\((X,Y)\)</span> would simply be absolutely
continuous, but with the above we also allow situations where <span
class="math inline">\(X\)</span> is continuous, <span
class="math inline">\(Y\)</span> is discrete, etc. We let <span
class="math display">\[f_X(x) \coloneq\int_{\mathbb{R}^m} f_{X,Y}(x,y)
\mathop{}\!\mathrm{d} {\nu(y)}, \quad f_Y(y) \coloneq\int_{\mathbb{R}^n}
f_{X,Y}(x,y) \mathop{}\!\mathrm{d} {\mu(x)},\]</span> be the marginal
densities of <span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span>, respectively.</p>
<p>Inspired by the definition of conditional probability from Chapter <a
href="#chap:prob" data-reference-type="ref"
data-reference="chap:prob">1</a>, we then introduce the conditional
density of <span class="math inline">\(X\)</span> given <span
class="math inline">\(Y = y\)</span> as <span
class="math display">\[f_{X \mid Y}(x \mid y) \coloneq\begin{cases}
\frac{f_{X,Y}(x,y)}{f_Y(y)}, &amp;f_Y(y) \neq 0\\ 0.
&amp;\text{else}\end{cases}\]</span> and define the <em>conditional
distribution</em> of <span class="math inline">\(X\)</span> given <span
class="math inline">\(Y = y\)</span> via <span
class="math display">\[\mathbb{P}_{X \mid Y = y}(B) \coloneq\int_B f_{X
\mid Y}(x \mid y) \mathop{}\!\mathrm{d} {\mu(x)}, \quad B \in
\mathbb{R}^n.\]</span> Note that for any <span
class="math inline">\(y\)</span> such that <span
class="math inline">\(f_{Y}(y) \neq 0\)</span>, <span
class="math inline">\(\mathbb{P}_{X \mid Y = y}\)</span> is indeed a
distribution because then <span class="math display">\[\mathbb{P}_{X
\mid Y = y}(\mathbb{R}^n) = \frac{1}{f_X(x)}
\underbrace{\int_{\mathbb{R}^n} f_{X,Y}(x,y) \mathop{}\!\mathrm{d}
{\mu(x)}}_{= f_X(x)} = 1.\]</span> If <span class="math inline">\(n
=1\)</span>, i.e., <span class="math inline">\(X\)</span> is a random
variable, we define <span class="math display">\[\mathbb{E}\big[X \mid Y
= y] \coloneq\int_{\mathbb{R}} x \mathop{}\!\mathrm{d} {\mathbb{P}_{X
\mid Y = y}(x)} = \int_{\mathbb{R}} x f_{X \mid Y}(x \mid y)
\mathop{}\!\mathrm{d} {\mu(x)}, \quad y \in \mathbb{R}^m,\]</span> as
the <em>conditional expectation</em> of <span
class="math inline">\(X\)</span> given <span class="math inline">\(Y =
y\)</span> provided that <span class="math inline">\(\mathbb{E}[\lvert X
\rvert] &lt; \infty\)</span> (check that the integral on the rhs is then
well-defined!). If we understand this as a function, i.e. <span
class="math inline">\(y \mapsto g(y) = \mathbb{E}[X \mid Y =
y]\)</span>, the conditional expectation given <span
class="math inline">\(Y = y\)</span> then induces a random variable by
plugging in, <span class="math display">\[\mathbb{E}\big[X \mid Y]
\coloneq g(Y) = \int_{\mathbb{R}} x f_{X \mid Y}(x \mid Y)
\mathop{}\!\mathrm{d} {\mu}(x), \quad \text{provided } \mathbb{E}[\lvert
X \rvert] &lt; \infty.\]</span> that we call the <em>conditional
expectation of <span class="math inline">\(X\)</span> given <span
class="math inline">\(Y\)</span></em>. This now also motivates the the
definition of the <em>conditional distribution of <span
class="math inline">\(X\)</span> given <span
class="math inline">\(Y\)</span></em>, <span
class="math inline">\(\mathbb{P}_{X \mid Y}\)</span>, which is defined
via <span class="math display">\[\mathbb{P}_{X \mid Y}(B) \coloneq\int_B
f_{X \mid Y}(x \mid Y) \mathop{}\!\mathrm{d} {\mu(x)}, \quad B \in
\mathcal{B}(\mathbb{R}^n),\]</span> such that (for <span
class="math inline">\(n=1\)</span>) <span
class="math inline">\(\mathbb{E}[X \mid Y] = \int_{\mathbb{R}} x
\mathop{}\!\mathrm{d} {\mathbb{P}_{X \mid Y}(x)}\)</span>. Conceptually,
it is important to acknowledge that</p>
<ol>
<li><p>for any <span class="math inline">\(B \in
\mathcal{B}(\mathbb{R}^n)\)</span>, <span
class="math inline">\(\mathbb{P}_{X \mid Y}(B)\)</span> is again a
random variable;</p></li>
<li><p><span class="math inline">\(B \mapsto \mathbb{P}_{X \mid
Y}(B)\)</span> is a probability measure <span
class="math inline">\(\mathbb{P}\)</span>-a.s.,<a href="#fn3"
class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p></li>
</ol>
<p>which is why we call it a <em>random probability measure</em>.</p>
<p>We now state Bayes’ formula (recall the one for events from Chapter
<a href="#chap:prob" data-reference-type="ref"
data-reference="chap:prob">1</a>), which is at the heart of Bayesian
statistics.</p>
<div class="theorem">
<p><strong>Theorem 3.42</strong> (Bayes’ formula). <em>It holds that
<span class="math display">\[\underbrace{f_{Y \mid X}(y \mid
x)}_{\mathclap{\text{posterior density}}} = \frac{f_{X \mid Y}(x \mid y)
\overbrace{f_{Y}(y)}^{\mathclap{\text{prior density}}}}{f_X(x)}, \quad
f_X(x) &gt; 0,f_Y(y) &gt; 0.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> If <span class="math inline">\(x,y\)</span> are such
that <span class="math inline">\(f_X(x), f_Y(y) &gt; 0\)</span>, then
<span class="math display">\[f_{Y \mid X}(y \mid x) f_X(x) =
f_{X,Y}(x,y) = f_{X \mid Y}(x \mid y) f_{Y}(y).\]</span> ◻</p>
</div>
<p>For completeness, we also give some important properties of the
conditional expectation, which we justify in the appendix.</p>
<div id="prop:cond_exp" class="proposition">
<p><strong>Proposition 3.43</strong>. <em>Let <span
class="math inline">\(X, X_1, X_2, Y\)</span> be as above s.t. <span
class="math inline">\(\mathbb{E}[\lvert X \rvert], \mathbb{E}[\lvert X_i
\rvert] &lt; \infty\)</span>, <span
class="math inline">\(i=1,2\)</span>.</em></p>
<ol>
<li><p><em>For any <span class="math inline">\(\alpha,\beta \in
\mathbb{R}\)</span> we have the <span
class="math inline">\(\mathbb{P}\)</span>-a.s. equality <span
class="math display">\[\mathbb{E}[\alpha X_1 + \beta X_2 \mid Y] =\alpha
\mathbb{E}[X_1 \mid Y] + \beta \mathbb{E}[X_2 \mid Y].
\tag{\text{Linearity}}\]</span></em></p></li>
<li><p><em><span class="math display">\[\mathbb{E}\big[ \mathbb{E}[X
\mid Y ] \big] = \mathbb{E}[X]. \tag{\text{tower
property}}\]</span></em></p></li>
<li><p><em>if <span class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> are independent,<a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>
then <span class="math inline">\(\mathbb{E}[X \mid Y] =
\mathbb{E}[X]\)</span>, <span
class="math inline">\(\mathbb{P}\)</span>-a.s.</em></p></li>
</ol>
</div>
<h1 id="asymptotic-theory">Asymptotic Theory</h1>
<h2 id="convergence-of-random-variables">Convergence of random
variables</h2>
<h3 id="convergence-concepts">Convergence concepts</h3>
<div class="definition">
<p><strong>Definition 4.1</strong>. Let <span
class="math inline">\(X\)</span> be a random variable and <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> be a sequence of
random variables that are all defined on a common probability space
<span class="math inline">\((\Omega, \mathcal{F},\mathbb{P})\)</span>.
We say that</p>
<ol>
<li><p><span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
converges almost surely to <span class="math inline">\(X\)</span>, if
<span class="math display">\[\mathbb{P}\Big(\lim_{n \to \infty} X_n = X
\Big) = 1 \qquad \big(\iff \mathbb{P}\big(\big\{\omega \in \Omega :
\lim_{n \to \infty} X_n(\omega) = X(\omega)\big\}\big) =
1.\big)\]</span> We then write <span class="math inline">\(X_n
\overset{\text{a.s.}}{\longrightarrow} X\)</span>.</p></li>
<li><p>given a real number <span class="math inline">\(p \geq
1\)</span>, <span class="math inline">\((X_n)_{n \in
\mathbb{N}}\)</span> converges in <span
class="math inline">\(p\)</span>-th mean to <span
class="math inline">\(X\)</span>, if <span
class="math display">\[\mathbb{E}\big[\lvert X_n - X \rvert^p  \big]
\underset{n \to \infty}{\longrightarrow} 0.\]</span> We then write <span
class="math inline">\(X_n \overset{\mathcal{L}^p}{\longrightarrow}
0\)</span>.</p></li>
<li><p><span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span>
converges in probability to <span class="math inline">\(X\)</span>, if
<span class="math display">\[\forall \varepsilon &gt; 0:
\mathbb{P}\big(\lvert X_n -X \rvert \geq \varepsilon \big) \underset{n
\to \infty}{\longrightarrow} 0 \qquad \Big(\iff \forall \varepsilon &gt;
0: \mathbb{P}\big(\lvert X_n -X \rvert &lt; \varepsilon \big)
\underset{n \to \infty}{\longrightarrow} 1 \Big).\]</span> We then write
<span class="math inline">\(X_n \overset{\mathbb{P}}{\longrightarrow}
X\)</span>.</p></li>
</ol>
</div>
<p>Let us state some important relations between the different
convergence concepts.</p>
<div id="theo:conv_rel" class="theorem">
<p><strong>Theorem 4.2</strong>. <em>The following implications
hold:</em></p>
<ol>
<li><p><em><span class="math inline">\(X_n
\overset{\text{a.s.}}{\longrightarrow} X \implies X_n
\overset{\mathbb{P}}{\longrightarrow} X\)</span></em></p></li>
<li><p><em><span class="math inline">\(X_n
\overset{\mathcal{L}^p}{\longrightarrow} X \implies X_n
\overset{\mathbb{P}}{\longrightarrow} X\)</span></em></p></li>
<li><p><em>if <span class="math inline">\(1 \leq r &lt; s\)</span>, then
<span class="math inline">\(X_n \overset{\mathcal{L}^s}{\longrightarrow}
X \implies X_n \overset{\mathcal{L}^r}{\longrightarrow}
X.\)</span></em></p></li>
</ol>
<p><em>The reverse implications generally do not hold.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em>  </p>
<ol>
<li><p>Let <span class="math inline">\(\Lambda \coloneq\{\omega \in
\Omega: \lim_{n \to \infty} X_n(\omega) = X(\omega)\}\)</span>. Then, by
the assumption <span class="math inline">\(X_n
\overset{\text{a.s.}}{\longrightarrow} X\)</span>, we have <span
class="math inline">\(\mathbb{P}(\Lambda^{\mathrm{c}}) = 0\)</span>. Let
<span class="math inline">\(\varepsilon\)</span> be arbitrarily chosen.
Since <span class="math inline">\(\bm{1}_{\{\lvert X_n - X\rvert\} \geq
\varepsilon}\bm{1}_\Lambda \leq 1\)</span> for any <span
class="math inline">\(n \in \mathbb{N}\)</span>. Moreover, by definition
of <span class="math inline">\(\Lambda\)</span>, <span
class="math display">\[\label{eq:conv1}
\forall \omega \in \Lambda: \lim_{n \to \infty} \bm{1}_{\{\lvert
X_n(\omega) - X(\omega) \rvert \geq \varepsilon\}} = 0,\]</span> which
shows that <span class="math display">\[\bm{1}_{\{\lvert X_n - X \rvert
\geq \varepsilon\}} \overset{\text{a.s.}}{\longrightarrow} 0.\]</span>
We therefore obtain from dominated convergence (cf. Theorem <a
href="#theo:dom" data-reference-type="ref"
data-reference="theo:dom">2.25</a>) that <span
class="math display">\[\begin{aligned}
\lim_{n \to \infty} \mathbb{P}(\lvert X_n - X \rvert \geq \varepsilon)
&amp;= \lim_{n \to \infty} \mathbb{E}\big[\bm{1}_{\{\lvert X_n - X
\rvert \geq \varepsilon\}} \big] = \mathbb{E}\Big[ \lim_{n \to \infty}
\bm{1}_{\{\lvert X_n - X \rvert \geq \varepsilon\}}\Big] = 0.
%&amp;=\lim_{n \to \infty} \int_{\Omega} \one_{\lvert X_n - X\rvert \geq
\varepsilon}\one_{\Lambda} \diff{\PP} +
\underbrace{\int_{\Lambda^{\mathrm{c}}}\one_{\{\lvert X_n - X\rvert \geq
\varepsilon\}} \diff{\PP}}_{\mathclap{= 0 \text{ by Proposition
\ref{prop:prop_int}.(iv)} }} \notag\\
%&amp;= \E\Big[ \lim_{n \to \infty} \one_{\{\lvert X_n - X \rvert \geq
\varepsilon\} \cap \Lambda}\Big] \tag{\text{by Theorem
\ref{theo:dom}}}\\
%&amp;= 0 \tag{\text{by \eqref{eq:conv1}}}
\end{aligned}\]</span> Since <span class="math inline">\(\varepsilon
&gt; 0\)</span> was arbitrary, this shows <span
class="math inline">\(X_n \overset{\mathbb{P}}{\longrightarrow}
X\)</span>.</p></li>
<li><p>We use Markov’s inequality (Theorem <a href="#theo:markov"
data-reference-type="ref" data-reference="theo:markov">2.44</a>) with
the strictly increasing function <span class="math inline">\(\varphi(x)
= x^p,\)</span> <span class="math inline">\(x \geq 0\)</span>. Then, for
any <span class="math inline">\(\varepsilon &gt; 0\)</span> <span
class="math display">\[\mathbb{P}\big(\lvert X_n - X \rvert \geq
\varepsilon \big) \leq \frac{\mathbb{E}[\varphi(\lvert X -
X_n\rvert)]}{\varphi(\varepsilon)} = \frac{\mathbb{E}[\lvert X_n - X
\rvert^p]}{\varepsilon^p} \underset{n \to \infty}{\longrightarrow}
0.\]</span></p></li>
<li><p>Using Hölder’s inequality (Theorem <a href="#theo:cs"
data-reference-type="ref" data-reference="theo:cs">2.41</a>) with <span
class="math inline">\(p = s/r\)</span> and <span class="math inline">\(q
= \tfrac{s/r}{s/r-1}\)</span> (note that then <span
class="math inline">\(1/p+1/q = 1\)</span>), <span
class="math display">\[\mathbb{E}[\lvert X_n - X \rvert^r] =
\mathbb{E}[\lvert X_n - X \rvert^r \cdot 1] \leq \big(\mathbb{E}[(\lvert
X_n - X \rvert^r)^{s/r}] \big)^{r/s} \big(\mathbb{E}[1^{q}])^{1/q} =
\big(\mathbb{E}[\lvert X_n - X \rvert^s]\big)^{r/s} \underset{n \to
\infty}{\longrightarrow} 0.\]</span></p></li>
</ol>
<p> ◻</p>
</div>
<div class="theorem">
<p><strong>Theorem 4.3</strong> (Continuous mapping theorem). <em>Let
<span class="math inline">\(\varphi\colon \mathbb{R}\to
\mathbb{R}\)</span> be a continuous function.</em></p>
<ol>
<li><p><em><span class="math inline">\(X_n
\overset{\text{a.s.}}{\longrightarrow} X \implies \varphi(X_n)
\overset{\text{a.s.}}{\longrightarrow}
\varphi(X)\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(X_n
\overset{\mathbb{P}}{\longrightarrow} X \implies \varphi(X_n)
\overset{\mathbb{P}}{\longrightarrow} \varphi(X)\)</span>.</em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p>Let again <span class="math inline">\(\Lambda \coloneq\{\omega
\in \Omega: \lim_{n \to \infty} X_n(\omega) = X(\omega)\}\)</span> such
that by assumption, <span class="math inline">\(\mathbb{P}(\Lambda) =
1\)</span>. By continuity of <span
class="math inline">\(\varphi\)</span>, <span
class="math display">\[\forall \omega \in \Lambda: \lim_{n \to \infty}
\varphi(X_n(\omega)) = \varphi\big(\lim_{n \to \infty} X_n(\omega) \big)
= \varphi(X(\omega)).\]</span> Thus, <span class="math inline">\(\Lambda
\subset \{\lim_{n \to \infty} \varphi(X_n) = \varphi(X)\}\)</span> and
therefore <span class="math inline">\(\mathbb{P}(\lim_{n \to \infty}
\varphi(X_n) = \varphi(X)) \geq \mathbb{P}(\Lambda) =
1\)</span>.</p></li>
<li><p>Let <span class="math inline">\(\varepsilon &gt; 0\)</span> be
given. Since <span class="math inline">\(\varphi\)</span> is continuous,
there exists <span class="math inline">\(\delta &gt; 0\)</span> such
that <span class="math inline">\(\lvert \varphi(X_n(\omega)) -
\varphi(X(\omega)) \rvert &lt; \varepsilon\)</span>, whenever <span
class="math inline">\(\lvert X_n(\omega) - X(\omega) \rvert &lt;
\delta\)</span>, which implies <span class="math inline">\(\{\lvert X_n
- X \rvert &lt; \delta\} \subset \{\lvert \varphi(X_n) - \varphi(X)
\rvert &lt; \varepsilon\}\)</span> and therefore <span
class="math display">\[\mathbb{P}(\lvert X_n - X \rvert &lt; \delta)
\leq \mathbb{P}(\lvert \varphi(X_n) - \varphi(X) \rvert &lt;
\varepsilon).\]</span> By our assumption that <span
class="math inline">\(X_n \overset{\mathbb{P}}{\longrightarrow}
X\)</span>, it follows that <span
class="math inline">\(\mathbb{P}(\lvert X_n - X \rvert &lt; \delta)
\underset{n \to \infty}{\longrightarrow} 1\)</span>, and thus by the
above also <span class="math inline">\(\mathbb{P}(\lvert \varphi(X_n) -
\varphi(X) \rvert &lt; \varepsilon) \underset{n \to
\infty}{\longrightarrow} 1\)</span>. Since <span
class="math inline">\(\varepsilon &gt; 0\)</span> was arbitrary, this
shows <span class="math inline">\(\varphi(X_n)
\overset{\mathbb{P}}{\longrightarrow} \varphi(X)\)</span>.</p></li>
</ol>
<p> ◻</p>
</div>
<h3 id="the-law-of-large-numbers">The Law of Large Numbers</h3>
<p>For a given sample <span
class="math inline">\(X_1,\ldots,X_n\)</span> we call <span
class="math display">\[\overline{X}_n \coloneq\frac{1}{n} \sum_{i=1}^n
X_i\]</span> the sample mean. If, <span
class="math inline">\(\mathbb{E}[X_1] = \cdots = \mathbb{E}[X_n] =
\mu\)</span>, the sample mean is an <em>unbiased estimator</em> of the
expectation <span class="math inline">\(\mu\)</span> in the sense that
<span class="math inline">\(\mathbb{E}[\overline{X}_n] = \mu\)</span>.
For i.i.d. data with second moment, we obtain convergence of the sample
mean in <span class="math inline">\(\mathcal{L}^2\)</span>.</p>
<div class="proposition">
<p><strong>Proposition 4.4</strong> (<span
class="math inline">\(\mathcal{L}^2\)</span>-version of the LLN).
<em>Let <span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> be
an i.i.d. sequence of random variables such that <span
class="math inline">\(\mathbb{E}[\lvert X_1 \rvert^2] &lt;
\infty\)</span>. Then, for <span class="math inline">\(\mu
\coloneq\mathbb{E}[X_1]\)</span> and <span
class="math inline">\(\sigma^2
\coloneq\mathop{\mathrm{Var}}(X_1)\)</span> it holds that <span
class="math display">\[\mathbb{E}\Big[\Big\lvert \frac{1}{n}
\sum_{i=1}^n X_i - \mu \Big\rvert^2\Big] = \frac{\sigma^2}{n},\]</span>
and hence in particular, <span
class="math display">\[\frac{1}{n}\sum_{i=1}^n X_i
\overset{\mathcal{L}^2}{\longrightarrow} \mu.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Using Exercise <a href="#ex:var"
data-reference-type="ref" data-reference="ex:var">2.43</a> and Exercise
<a href="#ex:var_sum" data-reference-type="ref"
data-reference="ex:var_sum">3.19</a> we find for the i.i.d. sample <span
class="math inline">\(X_1,\ldots,X_n\)</span> that <span
class="math display">\[\label{eq:var_sum}
\mathop{\mathrm{Var}}\Big(\frac{1}{n} \sum_{i=1}^n X_i\Big) =
\frac{1}{n^2} \mathop{\mathrm{Var}}\Big(\sum_{i=1}^n X_i\Big) =
\frac{1}{n^2} \Big(\underbrace{\sum_{i=1}^n
\mathop{\mathrm{Var}}(X_i)}_{\mathclap{= n\mathop{\mathrm{Var}}(X_1)
\text{ since } \mathbb{P}_{X_i}= \mathbb{P}_{X_j}}} + \sum_{i \neq j}
\underbrace{\mathop{\mathrm{Cov}}(X_i,X_j)}_{\mathclap{= 0 \text{ by
independence}}} \Big) = \frac{1}{n} \mathop{\mathrm{Var}}(X_1).\]</span>
Therefore, <span class="math display">\[\mathbb{E}\Big[\Big\lvert
\frac{1}{n} \sum_{i=1}^n X_i - \mu \Big\rvert^2\Big] =
\mathbb{E}\Big[\Big\lvert \frac{1}{n} \sum_{i=1}^n X_i -
\mathbb{E}\Big[\frac{1}{n}\sum_{i=1}^n X_i \Big] \Big\rvert^2\Big] =
\mathop{\mathrm{Var}}\Big(\frac{1}{n} \sum_{i=1}^n X_i\Big) =
\frac{\mathop{\mathrm{Var}}(X_1)}{n} \underset{n \to
\infty}{\longrightarrow} 0.\]</span> ◻</p>
</div>
<p>The strong Law of Large Numbers (LLN) now states that for an
i.i.d. sample, just the existence of the expectation is sufficient to
get almost sure convergence to it.</p>
<div id="Strong LLN" class="theorem">
<p><strong>Theorem 4.5</strong> (strong LLN). <em>Let <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> be an
i.i.d. sequence of random variables such that <span
class="math inline">\(\mathbb{E}[\lvert X_1 \rvert] &lt;
\infty\)</span>. Then, for <span class="math inline">\(\mu
\coloneq\mathbb{E}[X_1]\)</span> it holds that <span
class="math display">\[\frac{1}{n} \sum_{i=1}^n X_i
\overset{\text{a.s.}}{\longrightarrow} \mu.\]</span></em></p>
</div>
<p>The full proof of the strong LLN is rather involved and unfortunately
out of scope of these lectures. We therefore only give a fairly compact
proof under the additional (but not necessary!) assumption that the
samples have finite fourth moment. To this end, we need the following,
which is a direct consequence of the Borel–Cantelli lemma (see
appendix).</p>
<div id="coro:as" class="lemma">
<p><strong>Lemma 4.6</strong>. <em>Let <span
class="math inline">\(Y\)</span> be a random variable and <span
class="math inline">\((Y_n)_{n \in \mathbb{N}}\)</span> be a sequence of
random variables on a common probability space <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span>. Then,
<span class="math display">\[\sum_{n=1}^\infty \mathbb{P}(\lvert Y_n - Y
\rvert &gt; \varepsilon) &lt; \infty \text{ for all }\varepsilon &gt; 0
\implies Y_n \overset{\text{a.s.}}{\longrightarrow} Y.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof of LLN when fourth moment is finite.</em> Assume
additionally that <span class="math inline">\(\mathbb{E}[X_1^4] &lt;
\infty\)</span>. By the previous lemma it suffices to check that <span
class="math display">\[\label{eq:as}
\forall \varepsilon &gt; 0: \sum_{n=1}^\infty \mathbb{P}\big(\lvert
\overline{X}_n - \mu \rvert &gt; \varepsilon\big) &lt; \infty,\]</span>
where <span class="math inline">\(\overline{X}_n = n^{-1}\sum_{i=1}^n
X_i\)</span>, <span class="math inline">\(\mu =
\mathbb{E}[X_1]\)</span>. Fix <span class="math inline">\(\varepsilon
&gt; 0\)</span>. Using Markov’s inequality and the assumption <span
class="math inline">\(\mathbb{E}[X_1^4] &lt; \infty\)</span>, it follows
that <span class="math display">\[\begin{aligned}
\mathbb{P}(\lvert \overline{X}_n - \mu \rvert &gt; \varepsilon)
&amp;\leq \frac{\mathbb{E}\big[\lvert \overline{X}_n - \mu \rvert^4
\big]}{\varepsilon^4}.
\end{aligned}\]</span> Let <span class="math inline">\(Y_i = X_i -
\mu\)</span>. Then, for any <span class="math inline">\(i,j,k,l \in
\{1,\ldots,n\}\)</span> with <span class="math inline">\(i \notin
\{j,k,l\}\)</span> we get by independence and <span
class="math inline">\(\mathbb{E}[Y_i] = 0\)</span> that <span
class="math display">\[\mathbb{E}[Y_i Y_j Y_k Y_l] =
\mathbb{E}[Y_i]\mathbb{E}[Y_j Y_k Y_l] = 0,\]</span> and therefore <span
class="math display">\[\begin{aligned}
\mathbb{E}\big[\lvert \overline{X}_n - \mu \rvert^4 \big] &amp;=
\frac{1}{n^4}\sum_{i,j,k,l=1}^n \mathbb{E}[Y_iY_jY_kY_l]\\
&amp;= \frac{1}{n^4} \Big(\sum_{i=1}^n \mathbb{E}[Y_i^4] + {4\choose
2}\sum_{i \neq j} \mathbb{E}[Y_i^2Y_j^2]\Big) \\
&amp;= \frac{1}{n^4}\Big(n \mathbb{E}[Y_1^4] + 3n(n-1)
\mathbb{E}[Y_1^2]^2\Big).
\end{aligned}\]</span> Consequently, <span
class="math display">\[\mathbb{P}(\lvert \overline{X}_n - \mu \rvert
&gt; \varepsilon) \leq \frac{n \mathbb{E}[Y_1^4] + 3n(n-1)
\mathbb{E}[Y_1^2]^2}{\varepsilon^4 n^4} \leq
\frac{4\mathbb{E}[Y_1^4]}{\varepsilon^4n^2},\]</span> which yields <span
class="math display">\[\sum_{n=1}^\infty \mathbb{P}(\lvert
\overline{X}_n - \mu \rvert &gt; \varepsilon) \leq \frac{4
\mathbb{E}[Y_1^4]}{\varepsilon^4} \sum_{n=1}^\infty \frac{1}{n^2} &lt;
\infty.\]</span> This proves <a href="#eq:as"
data-reference-type="eqref" data-reference="eq:as">[eq:as]</a> and
therefore establishes <span class="math display">\[\overline{X}_n
\overset{\text{a.s.}}{\longrightarrow} \mathbb{E}[X_1].\]</span> ◻</p>
</div>
<p>Let us also note that the strong LLN is not the strongest version:
for instance, it is sufficient to require pairwise independence of the
identically distributed samples (Etemadi’s LLN).</p>
<h2 id="convergence-in-distribution">Convergence in distribution</h2>
<p>The previous convergence concepts for random variables express in
different ways the idea that <span class="math inline">\(X_n \to
X\)</span> if <span class="math inline">\(X_n\)</span> and <span
class="math inline">\(X\)</span> are close to another with increasing
probability as <span class="math inline">\(n \to \infty\)</span>. In
many situations, this concept is however too strong. Consider for
e.g. the case that we choose <span class="math inline">\(X \sim
\mathcal{U}([0,1])\)</span> and <span class="math inline">\(X_n = 1 -
X\)</span> for all <span class="math inline">\(n\)</span>. Then <span
class="math inline">\(X_n \sim \mathcal{U}([0,1])\)</span> for all <span
class="math inline">\(n\)</span>, but for any <span
class="math inline">\(\varepsilon &gt; 0\)</span>, <span
class="math display">\[\mathbb{P}(\lvert X_n - X \rvert &lt;
\varepsilon) = \mathbb{P}(\lvert 2X -1 \rvert &lt; \varepsilon) \not\to
1.\]</span> So although <span class="math inline">\(\mathbb{P}_X =
\mathbb{P}_{X_n}\)</span>, i.e., the distributions are identical, the
previous convergence concepts cannot catch this intimate relationship.
We therefore aim at a convergence concept that expresses the idea that
<span class="math inline">\(X_n \to X\)</span> if <span
class="math inline">\(\mathbb{P}_{X_n} \to \mathbb{P}_{X}\)</span> in
some appropriate sense.</p>
<div class="definition">
<p><strong>Definition 4.7</strong>. Let <span
class="math inline">\(X\)</span> be a random variable and <span
class="math inline">\((X_n)_{n\in \mathbb{N}}\)</span> be a sequence of
random variables. We say that <span class="math inline">\((X_n)_{n \in
\mathbb{N}}\)</span> converges in distribution to <span
class="math inline">\(X\)</span> if for any point of continuity<a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> <span class="math inline">\(x \in
\mathbb{R}\)</span> of <span class="math inline">\(F_X\)</span>, it
holds that <span class="math display">\[\lim_{n \to \infty} F_{X_n}(x)
=  F_X(x).\]</span> We then write <span class="math inline">\(X_n
\overset{d}{\longrightarrow} X\)</span>.</p>
</div>
<p>Let’s have a look at the continuity requirement in the above
definition. Consider the sequence <span class="math inline">\(X_n =
\frac{1}{n}\)</span> (that is, <span class="math inline">\(X_n(\omega) =
1/n\)</span> for all <span class="math inline">\(\omega \in
\Omega\)</span>). Then <span class="math inline">\(X_n(\omega) \to 0
\eqcolon X\)</span> for any <span class="math inline">\(\omega \in
\Omega\)</span>, so we would certainly want <span
class="math inline">\(X_n \overset{d}{\longrightarrow} 0\)</span> for
convergence in distribution to be a meaningful concept. Since <span
class="math inline">\(F_{X_n}(x) = \bm{1}_{[1/n,\infty)}(x)\)</span> and
<span class="math inline">\(F_X = \bm{1}_{[0,\infty)}(x)\)</span>, we
have at the discontinuity point <span class="math inline">\(0\)</span>
of <span class="math inline">\(F_X\)</span> that <span
class="math display">\[F_{X_n}(0) = 0 \neq 1 = F_X(0),\]</span> and
therefore <span class="math inline">\(F_{X_n}(0) \not\to
F_X(0)\)</span>. This illustrates why we do not want to factor in
discontinuity points of the limiting cdf.</p>
<p>We now state an equivalent and very useful alternative
characterisation of convergence in distribution. We let <span
class="math display">\[\mathcal{C}(\mathbb{R}) \coloneq\{g \colon
\mathbb{R}\to \mathbb{R}: g \text{ continuous}\}, \quad
\mathcal{C}_b(\mathbb{R}) \coloneq\{g \colon \mathbb{R}\to \mathbb{R}: g
\text{ continuous and bounded}\}.\]</span></p>
<div id="theo:weak" class="theorem">
<p><strong>Theorem 4.8</strong>. <em>We have <span
class="math inline">\(X_n \overset{d}{\longrightarrow} X\)</span> if,
and only if, <span class="math display">\[\forall g \in
\mathcal{C}_b(\mathbb{R}):\quad  \mathbb{E}[g(X_n)] \underset{n \to
\infty}{\longrightarrow} \mathbb{E}[g(X)].\]</span></em></p>
</div>
<div class="corollary">
<p><strong>Corollary 4.9</strong> (Continuous mapping). <em>Let <span
class="math inline">\(\varphi \in \mathcal{C}(\mathbb{R})\)</span>.
Then, <span class="math display">\[X_n \overset{d}{\longrightarrow} X
\implies \varphi(X_n) \overset{d}{\longrightarrow}
\varphi(X).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Choose an arbitrary <span class="math inline">\(g \in
\mathcal{C}_b(\mathbb{R})\)</span>. Since <span
class="math inline">\(g\)</span> and <span
class="math inline">\(\varphi\)</span> are continuous, so is <span
class="math inline">\(g \circ \varphi\)</span>; and since <span
class="math inline">\(g\)</span> is bounded, the same is also true for
<span class="math inline">\(g \circ\varphi\)</span>. Thus, <span
class="math inline">\(g \circ \varphi \in
\mathcal{C}_b(\mathbb{R})\)</span> and <span class="math inline">\(X_n
\overset{d}{\longrightarrow} X\)</span> implies that <span
class="math display">\[\mathbb{E}[g(\varphi(X_n)] \underset{n \to
\infty}{\longrightarrow} \mathbb{E}[g(\varphi(X)].\]</span> Since <span
class="math inline">\(g\)</span> was arbitrary, this gives <span
class="math inline">\(\varphi(X_n) \overset{d}{\longrightarrow}
X\)</span>. ◻</p>
</div>
<div class="exercise">
<p><em>Exercise 4.10</em>. Suppose that <span class="math inline">\(X_n
\overset{d}{\longrightarrow} X\)</span>. Show that for <span
class="math inline">\(a \in \mathbb{R}\)</span> then <span
class="math inline">\(aX_n \overset{d}{\longrightarrow} aX\)</span> and
<span class="math inline">\(X_n +a \overset{d}{\longrightarrow} X
+a\)</span>.</p>
</div>
<div id="theo:p_to_d" class="theorem">
<p><strong>Theorem 4.11</strong>. <em>The following hold:</em></p>
<ol>
<li><p><em><span class="math inline">\(X_n
\overset{\mathbb{P}}{\longrightarrow} X \implies X_n
\overset{d}{\longrightarrow} X\)</span>.</em></p></li>
<li><p><em>If <span class="math inline">\(X_n
\overset{d}{\longrightarrow} c\)</span> for some constant <span
class="math inline">\(c \in \mathbb{R}\)</span>, then <span
class="math inline">\(X_n \overset{\mathbb{P}}{\longrightarrow}
c\)</span>.</em></p></li>
</ol>
</div>
<div class="proof">
<p><em>Proof.</em></p>
<ol>
<li><p>Let <span class="math inline">\(x\)</span> be a continuity point
of <span class="math inline">\(F_X\)</span>. We need to show <span
class="math inline">\(F_{X_n}(x) \underset{n \to
\infty}{\longrightarrow} F_X(x)\)</span>. To this end, let <span
class="math inline">\(\varepsilon &gt; 0\)</span> be arbitrarily chosen
and observe that <span class="math display">\[\label{eq:p_to_d1}
\{X \leq x- \varepsilon \} \cap \{X_n &gt; x\} \subset \{\lvert X_n - X
\rvert &gt; \varepsilon\},\]</span> which implies <span
class="math display">\[\begin{aligned}
F_X(x- \varepsilon) = \mathbb{P}(X \leq x -\varepsilon) &amp;=
\mathbb{P}(X \leq x - \varepsilon, X_n &gt; x) + \mathbb{P}(X \leq x -
\varepsilon, X_n \leq x) \notag\\
&amp;\leq \mathbb{P}(X \leq x - \varepsilon, X_n &gt; x) +
\mathbb{P}(X_n \leq x) \notag\\
&amp;\leq \mathbb{P}(\lvert X_n -X \rvert &gt; \varepsilon) + F_{X_n}(x)
\tag{\text{by } \eqref{eq:p_to_d1}}
\end{aligned}\]</span> Thus, taking <span class="math inline">\(n \to
\infty\)</span> and using that by assumption <span
class="math inline">\(\mathbb{P}(\lvert X_n -X \rvert &gt; \varepsilon)
\underset{n \to \infty}{\longrightarrow} 0\)</span>, it follows that
<span class="math display">\[F_X(x- \varepsilon) \leq \liminf_{n \to
\infty} F_{X_n}(x),\]</span> and thus, using that <span
class="math inline">\(x\)</span> was chosen such that <span
class="math inline">\(F_X(x-) = F_X(x)\)</span>, <span
class="math display">\[F_X(x) = F_X(x-) = \lim_{\varepsilon \downarrow
0} F_X(x- \varepsilon) \leq \liminf_{n \to \infty} F_{X_n}(x).\]</span>
In the same way, we can show that <span class="math display">\[F_X(x +
\varepsilon) \geq \limsup_{n \to \infty} F_{X_n}(x),\]</span> and thus
by right-continuity of <span class="math inline">\(F_X\)</span>, <span
class="math display">\[F_X(x) = \lim_{\varepsilon \downarrow 0} F_X(x +
\varepsilon) \geq \limsup_{n \to \infty} F_{X_n}(x).\]</span> Combining
both estimates, <span class="math display">\[F_X(x) \leq \liminf_{n \to
\infty} F_{X_n}(x) \leq \limsup_{n \to \infty} F_{X_n}(x) \leq
F_X(x),\]</span> which implies <span class="math inline">\(\lim_{n \to
\infty} F_{X_n}(x) = F_X(x)\)</span>.</p></li>
<li><p>Fix <span class="math inline">\(\varepsilon &gt; 0\)</span>. We
have <span class="math inline">\(\{\lvert X_n -c \rvert &gt;
\varepsilon\} = \{X_n &gt; c + \varepsilon \} \uplus \{X_n &lt; c
-\varepsilon\}\)</span> and <span class="math inline">\(c-\varepsilon, c
+ \varepsilon\)</span> are continuity points of <span
class="math inline">\(F_X\)</span> for <span class="math inline">\(X
\equiv c\)</span>. Since <span class="math inline">\(X_n
\overset{d}{\longrightarrow} c\)</span> it follows that <span
class="math display">\[\begin{aligned}
\mathbb{P}(\lvert X_n - c \rvert &gt; \varepsilon) &amp;= \mathbb{P}(X_n
&gt; c + \varepsilon) + \mathbb{P}(X_n &lt; c -\varepsilon)\\
&amp;\leq 1 - F_{X_n}(c+ \varepsilon) + F_{X_n}(c-\varepsilon)\\
&amp;\longrightarrow 1 - F_X(c+ \varepsilon) + F_X(c- \varepsilon)\\
&amp;= 1 - 1 + 0 = 0,
\end{aligned}\]</span> where we used for the last line that <span
class="math inline">\(F_X(x) = \bm{1}_{[c,\infty)}(x).\)</span> Since
<span class="math inline">\(\varepsilon &gt;0\)</span> was arbitrary,
this shows <span class="math inline">\(X_n
\overset{\mathbb{P}}{\longrightarrow} c\)</span>.</p></li>
</ol>
<p> ◻</p>
</div>
<div id="theo:slutsky" class="theorem">
<p><strong>Theorem 4.12</strong> (Slutsky’s theorem). <em>Let <span
class="math inline">\(X,X_1,X_2,\ldots\)</span> and <span
class="math inline">\(Y_1,Y_2,\ldots\)</span> be random variables on a
common probability space such that <span class="math inline">\(X_n
\overset{d}{\longrightarrow} X\)</span> and <span
class="math inline">\(Y_n \overset{\mathbb{P}}{\longrightarrow}
c\)</span> for some <span class="math inline">\(c \in
\mathbb{R}\)</span>. Then,</em></p>
<ol>
<li><p><em><span class="math inline">\(X_n + Y_n
\overset{d}{\longrightarrow} X+ c.\)</span></em></p></li>
<li><p><em><span class="math inline">\(Y_n X_n
\overset{d}{\longrightarrow} cX.\)</span></em></p></li>
<li><p><em><span class="math inline">\(X_n/Y_n \bm{1}_{\{Y_n \neq 0\}}
\overset{d}{\longrightarrow} X/c\)</span> if <span
class="math inline">\(c \neq 0\)</span>.</em></p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 4.13</em>. Note that by Theorem <a href="#theo:p_to_d"
data-reference-type="ref" data-reference="theo:p_to_d">4.11</a>, the
assumption <span class="math inline">\(Y_n
\overset{\mathbb{P}}{\longrightarrow} c\)</span> for a constant <span
class="math inline">\(c \in \mathbb{R}\)</span> is equivalent to only
requiring <span class="math inline">\(Y_n \overset{d}{\longrightarrow}
c\)</span>. If instead <span class="math inline">\(Y_n
\overset{d}{\longrightarrow} Y\)</span> for some random variable that is
not a.s. constant, it is generally <em>not</em> true that <span
class="math inline">\(X_n + Y_n \overset{d}{\longrightarrow}
X+Y\)</span>.</p>
</div>
<div class="proof">
<p><em>Proof.</em> We only prove part (i). Let <span
class="math inline">\(t \in \mathbb{R}\)</span> be a fixed continuity
point of <span class="math inline">\(F_{X+c}\)</span> and <span
class="math inline">\(\varepsilon &gt; 0\)</span>. Then, <span
class="math display">\[\begin{aligned}
F_{X_n+Y_n}(t) &amp;= \mathbb{P}(X_n + Y_n \leq t)\\
&amp;= \mathbb{P}(X_n + Y_n \leq t, \lvert Y_n - c \rvert &lt;
\varepsilon) + \mathbb{P}(X_n + Y_n \leq t, \lvert Y_n - c \rvert \geq
\varepsilon)\\
&amp;\leq \mathbb{P}(X_n + Y_n \leq t, \lvert Y_n - c \rvert &lt;
\varepsilon) + \mathbb{P}(\lvert Y_n - c \rvert \geq \varepsilon)\\
&amp;\leq \mathbb{P}(X_n \leq t-c+\varepsilon) + \mathbb{P}(\lvert Y_n -
c \rvert \geq \varepsilon),
\end{aligned}\]</span> and similarly, <span
class="math display">\[\label{eq:slutsky1}
F_{X_n +Y_n}(t) \geq \mathbb{P}(X_n \leq t-c-\varepsilon) -
\mathbb{P}(\lvert Y_n - c \rvert \geq \varepsilon).\]</span> Since any
cdf can have at most countable discontinuities (why?), we may choose a
sequence <span class="math inline">\((\varepsilon_m)_{m \in
\mathbb{N}}\)</span>, such that each of the points <span
class="math inline">\(t-c+\varepsilon_m\)</span> and <span
class="math inline">\(t-c-\varepsilon_m\)</span> are points of
continuity of <span class="math inline">\(F_{X}\)</span>. Since <span
class="math inline">\(X_n \overset{d}{\longrightarrow} X\)</span> and
<span class="math inline">\(Y_n \overset{\mathbb{P}}{\longrightarrow}
c\)</span>, it therefore follows that for any <span
class="math inline">\(m \in \mathbb{N}\)</span>, <span
class="math display">\[\begin{aligned}
\limsup_{n \to \infty} F_{X_n+Y_n}(t) &amp;\leq \limsup_{n \to \infty}
\Big(\mathbb{P}(X_n \leq t-c-\varepsilon_m) - \mathbb{P}(\lvert Y_n - c
\rvert \geq \varepsilon_m)\Big)\\
&amp;= F_X(t-c+\varepsilon_m)\\
&amp;= F_{X+c}(t - \varepsilon_m).
\end{aligned}\]</span> Taking <span class="math inline">\(m \to
\infty\)</span> and using that <span class="math inline">\(t\)</span> is
a point of continuity of <span class="math inline">\(X+c\)</span>, we
obtain <span class="math display">\[\limsup_{n \to \infty}
F_{X_n+Y_n}(t) \leq F_{X+c}(t).\]</span> Similarly, using <a
href="#eq:slutsky1" data-reference-type="eqref"
data-reference="eq:slutsky1">[eq:slutsky1]</a>, it follows that <span
class="math display">\[\liminf_{n \to \infty} F_{X_n+Y_n}(t) \geq
F_{X+c}(t).\]</span> Combining both statements yields <span
class="math inline">\(\lim_{n \to \infty} F_{X_n+Y_n}(t) =
F_{X+c}(t)\)</span> for the arbitrarily chosen point of continuity <span
class="math inline">\(t\)</span> and therefore <span
class="math inline">\(X_n+Y_n \overset{d}{\longrightarrow}
X+c\)</span>. ◻</p>
</div>
<div id="lem:int_weak" class="lemma">
<p><strong>Lemma 4.14</strong>. <em>Suppose that <span
class="math inline">\(X_n \overset{d}{\longrightarrow} X\)</span> for a
continuous random variable <span class="math inline">\(X\)</span>. Then,
for any <span class="math inline">\(-\infty &lt; a \leq b &lt;
\infty\)</span> it holds that <span
class="math display">\[\mathbb{P}(X_n \in [a,b]) \underset{n \to
\infty}{\longrightarrow} \mathbb{P}(X \in [a,b]).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Note that <span class="math display">\[\mathbb{P}(X_n
\in [a,b]) = \underbrace{F_{X_n}(b) - F_{X_n}(a)}_{= \mathbb{P}(X_n \in
(a,b])} + \mathbb{P}(X_n = a).\]</span> Since <span
class="math inline">\(X\)</span> is continuous, <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> are continuity points of <span
class="math inline">\(F_X\)</span> and therefore by assumption <span
class="math display">\[F_{X_n}(b) - F_{X_n}(a) \underset{n \to
\infty}{\longrightarrow} F_X(b) - F_X(a) = \mathbb{P}(X \in (a,b])
\overset{F_X \text{ cont.}}{=} \mathbb{P}(X \in [a,b]).\]</span> It
therefore remains to prove that <span
class="math inline">\(\mathbb{P}(X_n = a) \underset{n \to
\infty}{\longrightarrow} 0\)</span>. To this end let us define the tent
function <span class="math display">\[\varphi_{k}(x)
\coloneq\begin{cases} 1 + k(a-x), &amp; x \in [a,a+1/k],\\ 1 + k(x-a),
&amp; x \in [a-1/k,a),\\ 0, &amp;\text{otherwise,}\end{cases}\qquad x
\in \mathbb{R}, k \in \mathbb{N}.\]</span> Then, for any <span
class="math inline">\(k\)</span>, <span class="math inline">\(\varphi_k
\in \mathcal{C}_b(\mathbb{R})\)</span> and <span
class="math inline">\(\bm{1}_{\{a\}} \leq \varphi_k\)</span>. Since
<span class="math inline">\(X_n \overset{d}{\longrightarrow} X\)</span>,
this implies that <span class="math display">\[\mathbb{P}(X_n = a) =
\mathbb{E}[\bm{1}_{\{a\}}(X_n)] \leq \mathbb{E}[\varphi_k(X_n)]
\underset{n \to
\infty}{\longrightarrow}  \mathbb{E}[\varphi_k(X)],\]</span> and
therefore for any <span class="math inline">\(k\)</span>, <span
class="math display">\[\limsup_{n \to \infty} \mathbb{P}(X_n = a) \leq
\mathbb{E}[\varphi_k(X)].\]</span> Since <span
class="math inline">\(\varphi_k \underset{k \to \infty}{\longrightarrow}
\bm{1}_{\{a\}}\)</span> pointwise and <span class="math inline">\(\lvert
\varphi_k \rvert \leq 1\)</span>, we conclude with dominated convergence
and continuity of <span class="math inline">\(X\)</span> that <span
class="math display">\[\limsup_{n \to \infty} \mathbb{P}(X_n = a) \leq
\lim_{k \to \infty}\mathbb{E}[\varphi_k(X)] = \mathbb{E}\big[\lim_{k \to
\infty} \varphi_k(X)\big] = \mathbb{P}(X = a) = 0,\]</span> which yields
<span class="math display">\[\lim_{n \to \infty} \mathbb{P}(X_n = a) =
\limsup_{n \to \infty} \mathbb{P}(X_n = a) = 0.\]</span> ◻</p>
</div>
<p>We now head towards <em>the</em> big result in asymptotic probability
that together with the LLN forms the basis of all of asymptotic
statistics. Consider an i.i.d. sample <span
class="math inline">\(X_1,\ldots,X_n\)</span> with finite variance <span
class="math inline">\(\sigma^2\)</span> and mean <span
class="math inline">\(\mu\)</span>. Recall that the sample mean is given
by <span class="math inline">\(\overline{X}_n \coloneq\tfrac{1}{n}
\sum_{i=1}^n X_i\)</span>. By <a href="#eq:var_sum"
data-reference-type="eqref" data-reference="eq:var_sum">[eq:var_sum]</a>
it holds that <span
class="math display">\[\mathop{\mathrm{Var}}(\overline{X}_n) =
\frac{\sigma^2}{n} \implies \sigma_{\overline{X}_n} =
\frac{\sigma}{\sqrt{n}}\]</span> and by linearity <span
class="math inline">\(\mathbb{E}[\overline{X}_n] = \mu\)</span>. The
normalisation of <span class="math inline">\(\overline{X}_n\)</span> is
therefore given by <span class="math display">\[Z_n
\coloneq\frac{\overline{X}_n -
\mathbb{E}[\overline{X}_n]}{\sigma_{\overline{X}_n}} =
\frac{\overline{X}_n - \mu}{\sigma/\sqrt{n}} = \sqrt{n}
\frac{\overline{X}_n - \mu}{\sigma}.\]</span></p>
<div class="exercise">
<p><em>Exercise 4.15</em>. Show that if <span
class="math inline">\(X_1,\ldots,X_n\)</span> are i.i.d. with <span
class="math inline">\(X_1 \sim \mathcal{N}(\mu,\sigma^2)\)</span>, the
normalisation <span class="math inline">\(Z_n\)</span> satisfies <span
class="math inline">\(Z_n \sim \mathcal{N}(0,1)\)</span>.</p>
</div>
<p>The Central Limit Theorem now states that for arbitrary
i.i.d. samples with finite second moment, the exact relationship for the
standardisation of normal random variables becomes an asymptotic
relationship in distribution.</p>
<div class="theorem">
<p><strong>Theorem 4.16</strong> (Central Limit Theorem (CLT)). <em>Let
<span class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> be an
i.i.d. sequence such that <span class="math inline">\(\mathbb{E}[\lvert
X_1\rvert^2] &lt; \infty\)</span> and <span
class="math inline">\(\mathop{\mathrm{Var}}(X_1) &gt; 0\)</span>. Let
<span class="math display">\[Z_n \coloneq\frac{\overline{X}_n -
\mathbb{E}[\overline{X}_n]}{\sqrt{\mathop{\mathrm{Var}}(\overline{X}_n)}}
= \sqrt{n} \frac{\overline{X}_n - \mu}{\sigma},\]</span> for <span
class="math inline">\(\mu \coloneq\mathbb{E}[X_1]\)</span>, <span
class="math inline">\(\sigma^2
\coloneq\mathop{\mathrm{Var}}(X_1)\)</span>. Then, for <span
class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span>, it holds that
<span class="math display">\[Z_n  \overset{d}{\longrightarrow} Z \sim
\mathcal{N}(0,1).\]</span></em></p>
</div>
<div class="remark">
<p><em>Remark 4.17</em>. This is often denoted as <span
class="math inline">\(Z_n \overset{d}{\longrightarrow}
\mathcal{N}(0,1)\)</span>, with the right hand side representing a
generic standard normal random variable. If we let <span
class="math inline">\(Y_i \coloneq(X_i -\mu)/\sigma\)</span>, then the
CLT reads <span class="math display">\[\sqrt{n} \cdot \overline{Y}_n
\overset{d}{\longrightarrow} \mathcal{N}(0,1).\]</span> Thus, while the
empirical mean <span class="math inline">\(\overline{Y}_n\)</span>
converges almost surely to the trivial limit <span
class="math inline">\(0\)</span> according to the LLN, the CLT states
that scaling it by <span class="math inline">\(\sqrt{n}\)</span> gives
convergence in distribution to a standard normal.</p>
</div>
<p>As for the LLN, we cannot give a full proof of the CLT in these
notes, but we illustrate the argument with an object that we have
already encountered: the moment generating function. A deep result on
the mgf is the following.</p>
<div class="theorem">
<p><strong>Theorem 4.18</strong> (Lévy’s continuity theorem). <em>Let
<span class="math inline">\((Y_n)_{n \in \mathbb{N}}\)</span> be a
sequence of random variables, whose mgfs exist in some common
neighborhood <span class="math inline">\((-h,h)\)</span> of <span
class="math inline">\(0\)</span>: <span
class="math display">\[\psi_{Y_n}(t) = \mathbb{E}[\exp(tY_n)] &lt;
\infty, \quad \forall t\in \mathbb{R},n \in \mathbb{N}.\]</span> Let
<span class="math inline">\(Y\)</span> be another random variable whose
mgf <span class="math inline">\(\psi_Y\)</span> also exists on <span
class="math inline">\((-h,h)\)</span>. If <span
class="math display">\[\forall t\in (-h,h) : \quad \psi_{Y_n}(t)
\underset{n \to \infty}{\longrightarrow} \psi_Y(t),\]</span> then <span
class="math inline">\(Y_n \overset{d}{\longrightarrow}
Y.\)</span></em></p>
</div>
<div class="proof">
<p><em>Proof of a restricted version of the CLT.</em> We assume for
simplicity that <span class="math inline">\(\psi_{X_1}\)</span> exists
and is twice continuously differentiable in some interval <span
class="math inline">\((-h,h)\)</span>. Let us first consider the special
case <span class="math inline">\(\mu = 0,\sigma^2 = 1\)</span>. Let
<span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span>. From
Chapter <a href="#chap:rv" data-reference-type="ref"
data-reference="chap:rv">2</a> we know that <span
class="math inline">\(\psi_Y(t) = \mathrm{e}^{t^2/2}\)</span>, so that
by Lévy’s continuity theorem it is enough to show <span
class="math display">\[\forall t \in (-h,h): \quad \psi_{Z_n}(t)
\underset{n \to \infty}{\longrightarrow} \psi_Z(t), \quad \text{for }
Z_n \coloneq\sqrt{n} \overline{X}_n = \frac{\sum_{i=1}^n
X_i}{\sqrt{n}}.\]</span> By Corollary <a href="#coro:mgf"
data-reference-type="ref" data-reference="coro:mgf">3.27</a> it holds
that <span class="math display">\[\label{eq:clt1}
\psi_{Z_n}(t) = \mathbb{E}\Big[\exp\Big(\frac{t}{\sqrt{n}} \sum_{i=1}^n
X_i\Big)\Big] = \psi_{\sum_{i=1}^n X_i}(t/\sqrt{n}) = \prod_{i=1}^n
\psi_{X_i}(t/\sqrt{n}) =
\Big(\psi_{X_1}\Big(\frac{t}{\sqrt{n}}\Big)\Big)^n.\]</span> Let <span
class="math inline">\(L(t) \coloneq\log \psi_{X_1}(t)\)</span>. Then,
using the differentiability assumption on <span
class="math inline">\(\psi_{X_1}\)</span>, <span
class="math display">\[\begin{aligned}
L(0) &amp;= 0\\
L^\prime(0) &amp;=
\frac{\overbrace{\psi^\prime_{X_1}(0)}^{=\mathbb{E}[X_1]}}{\underbrace{\psi_{X_1}(0)}_{=1}}
= \mathbb{E}[X_1] = 0\\
L^{\prime\prime}(0) &amp;=
\frac{\overbrace{\psi^{\prime\prime}_{X_1}(0)\psi_{X_1}(0)}^{=
\mathbb{E}[X_1^2]} - \overbrace{\psi^\prime_{X_1}(0)^2}^{\mathclap{=
\mathbb{E}[X_1]^2}}}{\psi_{X_1}(0)^2} = \mathbb{E}[X_1^2] -
\mathbb{E}[X_1]^2 = \mathop{\mathrm{Var}}(X_1) = 1.
\end{aligned}\]</span> By <a href="#eq:clt1" data-reference-type="eqref"
data-reference="eq:clt1">[eq:clt1]</a>, we need to show <span
class="math display">\[\Big(\psi_{X_1}\Big(\frac{t}{\sqrt{n}}\Big)\Big)^n
\underset{n \to \infty}{\longrightarrow} \psi_Z(t) = \mathrm{e}^{t^2/2},
\quad t \in (-h,h),\]</span> which by taking logs is equivalent to <span
class="math display">\[nL\Big(\frac{t}{\sqrt{n}}\Big) \underset{n \to
\infty}{\longrightarrow} \frac{t^2}{2}, \quad t \in (-h,h).\]</span>
Using L’Hôpital’s rule twice and the above, we indeed get <span
class="math display">\[\begin{aligned}
\lim_{n \to \infty} nL\Big(\frac{t}{\sqrt{n}}\Big) = \lim_{n \to \infty}
\frac{L(t/\sqrt{n})}{n^{-1}} &amp;= \lim_{n \to \infty}
\frac{-n^{3/2}tL^\prime(t/\sqrt{n})}{-2n^{-2}}\\
&amp;= \lim_{n \to \infty} \frac{tL^\prime(t/\sqrt{n})}{2n^{-1/2}}\\
&amp;= \lim_{n \to \infty}
\frac{-n^{-3/2}t^2L^{\prime\prime}(t/\sqrt{n})}{-2n^{-3/2}}\\
&amp;= \frac{t^2}{2} \lim_{n \to \infty} L^{\prime\prime}(t/\sqrt{n})\\
&amp;= \frac{t^2}{2}L^{\prime\prime}(0) = \frac{t^2}{2}.
\end{aligned}\]</span> Thus, for the special case <span
class="math inline">\(\mu = 0,\sigma^2 = 1\)</span> we have proved that
<span class="math inline">\(Z_n \overset{{d}}{\longrightarrow} Z \sim
\mathcal{N}(0,1)\)</span>. For general <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(\sigma^2\)</span> consider <span
class="math inline">\(\hat{X}_n \coloneq(X_n - \mu)/\sigma\)</span>.
Then, <span class="math inline">\((\hat{X}_n)_{n \in
\mathbb{N}}\)</span> is an i.i.d. sequence with <span
class="math inline">\(\mathop{\mathrm{Var}}(\hat{X}_1) = 1,
\mathbb{E}[\hat{X_1}] = 0\)</span>, such that from above it follows
<span class="math display">\[Z_n = \sqrt{n}
\frac{\frac{1}{n}\sum_{i=1}^n X_i - \mu}{\sigma} = \frac{\sum_{i=1}^n
\hat{X_i}}{\sqrt{n}} \overset{d}{\longrightarrow} Z \sim
\mathcal{N}(0,1).\]</span> ◻</p>
</div>
<div id="thm:delta" class="theorem">
<p><strong>Theorem 4.19</strong> (delta method). <em>Let <span
class="math inline">\(\mu \in \mathbb{R}\)</span>, <span
class="math inline">\(\sigma &gt; 0\)</span> and <span
class="math inline">\(g\colon \mathbb{R}\to \mathbb{R}\)</span> be a
measurable function that is differentiable at <span
class="math inline">\(\mu\)</span> and is such that <span
class="math inline">\(g^\prime(\mu) \neq 0\)</span>. Suppose that <span
class="math inline">\((Y_n)_{n \in \mathbb{N}}\)</span> is a sequence of
random variables such that <span
class="math display">\[\sqrt{n}\frac{Y_n - \mu}{\sigma}
\overset{d}{\longrightarrow} \mathcal{N}(0,1).\]</span> Then, <span
class="math display">\[\sqrt{n}\frac{g(Y_n) - g(\mu)}{\sigma
g^\prime(\mu)} \overset{d}{\longrightarrow}
\mathcal{N}(0,1).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Let <span class="math display">\[r(h)
\coloneq\begin{cases} \frac{g(\mu+h) - g(\mu)}{h} - g^\prime(\mu),
&amp;h \neq 0\\ 0, &amp;h = 0.\end{cases}\]</span> Then, <span
class="math display">\[g(Y_n) - g(\mu) = g^\prime(\mu) (Y_n - \mu) +
(Y_n - \mu) r(Y_n - \mu),\]</span> and therefore <span
class="math display">\[\label{eq:delta0}
\sqrt{n}\frac{g(Y_n) - g(\mu)}{\sigma g^\prime(\mu)} = \sqrt{n}\frac{Y_n
- \mu}{\sigma} + \sqrt{n}\frac{Y_n - \mu}{\sigma g^\prime(\mu)}r(Y_n -
\mu).\]</span> Let us show that the second term converges to zero in
probability. By assumption we have <span
class="math display">\[\label{eq:delta1}
Z_n \coloneq \sqrt{n}\frac{Y_n - \mu}{\sigma}
\overset{d}{\longrightarrow} \mathcal{N}(0,1),\]</span> and therefore
<span class="math inline">\(Y_n - \mu = \sigma n^{-1/2} Z_n
\overset{\mathbb{P}}{\longrightarrow} 0\)</span> (this follows, e.g.,
from Slutsky’s theorem and Theorem <a href="#theo:p_to_d"
data-reference-type="ref" data-reference="theo:p_to_d">4.11</a>). Since
<span class="math inline">\(g\)</span> is differentiable at <span
class="math inline">\(\mu\)</span>, <span
class="math inline">\(r\)</span> is a continuous function. Consequently,
the continuous mapping theorem implies that <span
class="math display">\[\label{eq:delta2}
r(Y_n - \mu) \overset{\mathbb{P}}{\longrightarrow} 0.\]</span> Combining
<a href="#eq:delta1" data-reference-type="eqref"
data-reference="eq:delta1">[eq:delta1]</a> and <a href="#eq:delta2"
data-reference-type="eqref" data-reference="eq:delta2">[eq:delta2]</a>
with Slutsky’s theorem therefore yields <span
class="math display">\[\sqrt{n}\frac{Y_n - \mu}{\sigma
g^\prime(\mu)}r(Y_n - \mu) \overset{d}{\longrightarrow} 0,\]</span>
which by Theorem <a href="#theo:p_to_d" data-reference-type="ref"
data-reference="theo:p_to_d">4.11</a> also gives <span
class="math display">\[\sqrt{n}\frac{Y_n - \mu}{\sigma
g^\prime(\mu)}r(Y_n - \mu) \overset{\mathbb{P}}{\longrightarrow}
0.\]</span> This together with <a href="#eq:delta0"
data-reference-type="eqref" data-reference="eq:delta0">[eq:delta0]</a>
and <a href="#eq:delta1" data-reference-type="eqref"
data-reference="eq:delta1">[eq:delta1]</a> finally yields <span
class="math display">\[\sqrt{n}\frac{g(Y_n) - g(\mu)}{\sigma
g^\prime(\mu)} \overset{d}{\longrightarrow} \mathcal{N}(0,1),\]</span>
by yet another application of Slutsky’s theorem. ◻</p>
</div>
<p>Finally, let us also discuss the multivariate CLT, which concerns
convergence in distribution of normalisations of sample means of random
vectors. To this end, we need to talk about independence of random
vectors and convergence in distribution of random vectors. These
concepts extend straightforwardly from the univariate case.</p>
<div class="definition">
<p><strong>Definition 4.20</strong>. </p>
<ol>
<li><p>A collection of <span
class="math inline">\(d\)</span>-dimensional random vectors <span
class="math inline">\(X_1,\ldots,X_n\)</span> (that is, <span
class="math inline">\(X_k = (X_{k,1}, \ldots, X_{k,d})^\top\)</span> for
some random variables <span class="math inline">\(X_{k,i}\)</span>) is
defined to be independent, if <span class="math display">\[\forall A \in
\mathcal{B}(\mathbb{R}^d): \quad \mathbb{P}(X_1 \in A_1,\ldots,X_n \in
A_n) = \prod_{i=1}^n \mathbb{P}(X_i \in A_i).\]</span></p></li>
<li><p>A sequence of random vectors <span class="math inline">\((X_n)_{n
\in \mathbb{N}}\)</span> is defined to be independent, if for any <span
class="math inline">\(n \in \mathbb{N}\)</span>, <span
class="math inline">\(X_1,\ldots,X_n\)</span> are independent.</p></li>
<li><p>A sequence of <span class="math inline">\(d\)</span>-dimensional
random vectors <span class="math inline">\((X_n)_{n \in
\mathbb{N}}\)</span> is said to converge in distribution to a <span
class="math inline">\(d\)</span>-dimensional random vector <span
class="math inline">\(X\)</span> (denoted by <span
class="math inline">\(X_n \overset{d}{\longrightarrow} X\)</span>) if
<span class="math display">\[\forall \varphi \in
\mathcal{C}_b(\mathbb{R}^d): \quad \lim_{n \to \infty}
\mathbb{E}[\varphi(X_n)] = \mathbb{E}[\varphi(X)],\]</span> where <span
class="math display">\[\mathcal{C}_b(\mathbb{R}^d) \coloneq
\big\{\varphi \colon \mathbb{R}^d \to \mathbb{R}: \varphi \text{
continuous and bounded} \big\}.\]</span></p></li>
</ol>
</div>
<div class="theorem">
<p><strong>Theorem 4.21</strong> (Multivariate CLT). <em>Let <span
class="math inline">\((X_n)_{n \in \mathbb{N}}\)</span> be an
i.i.d. sequence of <span class="math inline">\(d\)</span>-dimensional
random vectors such that <span class="math inline">\(\Sigma \coloneq
\Sigma_{X_1}\)</span> exists and is invertible. Let <span
class="math inline">\(\overline{X}_n \coloneq \tfrac{1}{n}\sum_{i=1}^n
X_i\)</span> and <span class="math inline">\(\mu
\coloneq\mathbb{E}[X_1]\)</span>. Let <span class="math display">\[Z_n
\coloneq\Sigma_{\overline{X}_n}^{-1/2}\big(\overline{X}_n -
\mathbb{E}[\overline{X}_n]\big) = \sqrt{n} \Sigma^{-1/2}
\big(\overline{X}_n - \mu\big).\]</span> Then, it holds that <span
class="math display">\[Z_n  \overset{d}{\longrightarrow}  \mathcal{N}(0,\mathbb{I}_d).\]</span></em></p>
</div>
<div class="remark">
<p><em>Remark 4.22</em>. Equivalently, we have <span
class="math display">\[\sqrt{n}\big(\overline{X}_n - \mu\big)
\overset{d}{\longrightarrow} \mathcal{N}(0,\Sigma).\]</span></p>
</div>
<p>The proof is a straightforward consequence of the univariate CLT and
the <em>Cramér–Wold device</em>, which allows us to break down
multivariate distributional convergence to univariate distributional
convergences of linear combinations of the random vector entries.</p>
<div class="theorem">
<p><strong>Theorem 4.23</strong> (Cramér–Wold device). <em>Let <span
class="math inline">\(Z,Z_1,Z_2,\ldots\)</span> be <span
class="math inline">\(d\)</span>-dimensional random vectors. Then, <span
class="math display">\[Z_n \overset{d}{\longrightarrow} Z \iff \forall a
\in \mathbb{R}^d: a^\top Z_n \overset{d}{\longrightarrow} a^\top
Z.\]</span></em></p>
</div>
<h1 id="fundamental-concepts-in-inference">Fundamental concepts in
inference</h1>
<h2 id="introduction">Introduction</h2>
<p>Suppose that a set of <span class="math inline">\(n\)</span> data
points <span class="math inline">\(\bm{x} = \{x_1,\dotsc,x_n\}\)</span>
are collected in an experiment to estimate some unknown quantity.
Statisticians view <span class="math inline">\(\bm{x}\)</span> as
realisations from random variables <span class="math inline">\(\bm{X} =
\{X_1,\dotsc, X_n\}\)</span>. Throughout the rest of this course, we
will focus on the case where <span class="math inline">\(X_1,\dotsc,
X_n\)</span> are i.i.d with some distribution <span
class="math inline">\(P\)</span>. The goal of statistical inference is
to learn about the data generating mechanism <span
class="math inline">\(P\)</span>, using the available sample <span
class="math inline">\(\bm{x}\)</span>.</p>
<div class="example">
<p><em>Example 5.1</em>.  </p>
<ul>
<li><p>Coin flipping;</p></li>
<li><p>Quality control in manufacturing;</p></li>
<li><p>Clinical trials for new drug efficacy;</p></li>
<li><p>Language ability tests in a school;</p></li>
<li><p>Tracking someone’s weight over time; (the i.i.d assumption is
unlikely to be true in this case; <em>Time series analysis</em> is
predominately concerned with statistical inference under temporal
dependence, which relax the independence assumption)</p></li>
<li><p>...</p></li>
</ul>
</div>
<div class="remark">
<p><em>Remark 5.2</em>. To distinguish quantities that are deterministic
and random, we mostly use lowercase letters to denote deterministic
quantities, e.g. <span class="math inline">\({x}\)</span>, and uppercase
letters to denote random variables, e.g. <span
class="math inline">\(X\)</span>. In particular, for deterministic
quantities, we have <span class="math inline">\(\mathbb{E}[x] =
x\)</span> and Var<span class="math inline">\((x) = 0\)</span>.</p>
</div>
<p>We will work under the assumption that <span
class="math inline">\(P\)</span> belongs to some statistical model that
can be parameterised by some parameter <span
class="math inline">\(\theta\)</span>, as defined below. Again, there
are many situations where such an assumption may not be appropriate -
see the course on <em>Nonparametric Statistics</em> for further
discussions.</p>
<div class="definition">
<p><strong>Definition 5.3</strong> (Statistical model). Let <span
class="math inline">\(\Theta\)</span> denote the parameter space and
<span class="math inline">\(\mathcal{S}\)</span> denote the sample
space. A statistical model is a family of probability distributions on
<span class="math inline">\(\mathcal{S}\)</span>. A parametric
statistical model is a set of distributions parametrised by <span
class="math inline">\(\theta \in \Theta \subseteq \mathbb{R}^d\)</span>,
written as <span class="math inline">\(\{P_\theta: \theta \in
\Theta\}\)</span>.</p>
</div>
<div class="example">
<p><em>Example 5.4</em>. Some examples of statistical models</p>
<ul>
<li><p><span class="math inline">\(\{N(\theta,1) : \theta \in \Theta =
\mathbb{R}\}\)</span>;</p></li>
<li><p><span class="math inline">\(\{N(\theta,1) : \theta \in \Theta =
[-2,5]\}\)</span>;</p></li>
<li><p><span class="math inline">\(\{N(\mu, \sigma^2I_d) : \theta =
(\mu,\sigma) \in \Theta = \mathbb{R}^{d+1}\}\)</span>;</p></li>
<li><p>{Ber<span class="math inline">\((\theta): \theta \in
[0,1]\)</span>}.</p></li>
</ul>
</div>
<p>We shall write <span class="math display">\[\label{eq:i.i.d}
    X_1,\dotsc,X_n \overset{i.i.d}{\sim} P_{\theta}, \; \theta \in
\Theta,\]</span> to denote that random variables <span
class="math inline">\(X_1,\ldots,X_n \colon \Omega
\to\mathcal{S}\)</span> are independent and identically distributed
(i.i.d.) with distribution <span
class="math inline">\(P_{\theta}\)</span>. Recall that this means for
some probability measure <span
class="math inline">\(\mathbb{P}_\theta\)</span> on <span
class="math inline">\((\Omega,\mathcal{F})\)</span>, <span
class="math inline">\(X_1,\ldots,X_n\)</span> are i.i.d. with
distribution <span
class="math inline">\(\mathbb{P}_\theta(X^{-1}(\cdot)) =
P_\theta(\cdot)\)</span>. We shall always assume that <span
class="math inline">\(P_\theta\)</span> is dominated by some (<span
class="math inline">\(\sigma\)</span>-finite) measure <span
class="math inline">\(\mu\)</span> on <span
class="math inline">\(\mathcal{S}\)</span>, and therefore it is
equivalent to write <a href="#eq:i.i.d" data-reference-type="eqref"
data-reference="eq:i.i.d">[eq:i.i.d]</a> as <span
class="math display">\[X_1,\dotsc,X_n \overset{i.i.d}{\sim} f(x;
{\theta}),\; \theta \in \Theta,\]</span> where <span
class="math inline">\(f(x; {\theta}) =
\frac{dP_\theta}{d\mu}(x)\)</span>. In statistics, the measure <span
class="math inline">\(\mu\)</span> is often the Lebesgue measure (for
continuous random variables) or the counting measure (for discrete
random variables).</p>
<div class="definition">
<p><strong>Definition 5.5</strong> (Statistic). Given <span
class="math inline">\({X} = \{X_1,\ldots,X_n\}\)</span>, any
(measurable) function of <span class="math inline">\({X}\)</span> that
does not depend on unknown quantities is called a
<em>statistic</em>.</p>
</div>
<div class="remark">
<p><em>Remark 5.6</em>. We often use <span
class="math inline">\(\hat{\theta}_n({X})\)</span> to denote a
statistic. Statistics are computed mostly to estimate the unknown
quantity <span class="math inline">\(\theta\)</span> in the data
generating mechanism <span class="math inline">\(P_\theta\)</span>, and
therefore we often also call it an <em>estimator</em>. Note that the
subscript <span class="math inline">\(n\)</span> in <span
class="math inline">\(\hat{\theta}_n(X)\)</span> indicate that it is a
function of the sample size <span class="math inline">\(n\)</span>. Note
also that it is a random variable since it depends on <span
class="math inline">\(X\)</span> which is random, whereas <span
class="math inline">\(\theta\)</span> is a deterministic quantity in
this course. We will explore the possibility of viewing <span
class="math inline">\(\theta\)</span> as a random variable in the
<em>Bayesian Inference and Computation</em> course.</p>
</div>
<div class="example">
<p><em>Example 5.7</em>. Some examples of statistics</p>
<ul>
<li><p><span class="math inline">\(\hat{\theta}_n({X}) =
{X}\)</span>;</p></li>
<li><p><span class="math inline">\(\hat{\theta}_n(X) =
\frac{1}{n}\sum_{i=1}^nX_i\)</span></p></li>
<li><p><span class="math inline">\(\hat{\theta}_n(X) =\)</span>
median<span class="math inline">\(({X})\)</span></p></li>
</ul>
</div>
<p>Most statistical problems can be identified as one of following three
types:</p>
<ul>
<li><p>(Point) Estimation: Constructing <span
class="math inline">\(\hat{\theta}_n(X)\)</span> such that for all <span
class="math inline">\(\theta \in \Theta\)</span>, when <span
class="math inline">\(X_i \sim P_\theta\)</span>, our estimator <span
class="math inline">\(\hat{\theta}_n\)</span> is close to <span
class="math inline">\(\theta\)</span>.</p></li>
<li><p>(Hypothesis) Testing: Making decisions about whether we are under
the null hypothesis <span class="math inline">\(H_0\)</span> or the
alternative hypothesis <span class="math inline">\(H_1\)</span> using
some test statistic <span class="math inline">\(T_n(X)\)</span> that
takes value <span class="math inline">\(0\)</span> or <span
class="math inline">\(1\)</span>. The goal is constructing <span
class="math inline">\(T_n(X)\)</span> such that <span
class="math inline">\(T_n(X) = 0\)</span> when <span
class="math inline">\(H_0\)</span> is true and <span
class="math inline">\(T_n(X) = 1\)</span> when <span
class="math inline">\(H_1\)</span> is true, with high
probability.</p></li>
<li><p>Confidence sets: Finding sets or intervals (depending on the
dimensionality of the parameter) <span
class="math inline">\(C_n(X)\)</span> such that for <span
class="math inline">\(\alpha \in (0,1)\)</span> we have <span
class="math inline">\(\mathbb{P}_{\theta}(\theta \in C_n(X)) \geq
1-\alpha\)</span>, for all <span class="math inline">\(\theta \in
\Theta\)</span>.</p></li>
</ul>
<h2 id="point-estimation">Point estimation</h2>
<p>We consider the task of estimating the parameter <span
class="math inline">\(\theta \in \Theta \subseteq \mathbb{R}\)</span>.
Given an an i.i.d. sample <span
class="math inline">\(X_1,\ldots,X_n\)</span> for a statistical model
<span class="math inline">\((P_\theta)_{\theta \in \Theta}\)</span>, an
<em>estimator</em> <span
class="math inline">\(\hat{\theta}_n(X_1,\ldots,X_n)\)</span> is a
statistic that is designed to estimate the unknown parameter of interest
<span class="math inline">\(\theta\)</span>. To assess the quality of
the estimator <span class="math inline">\(\hat{\theta}_n\)</span>, we
may consider the following quantities.</p>
<div class="definition">
<p><strong>Definition 5.8</strong> (Bias and mean squared error).  </p>
<ol>
<li><p>We call <span
class="math display">\[\operatorname{Bias}(\hat{\theta}_n)
\coloneq\mathbb{E}[\hat{\theta}_n] - \theta\]</span> the <em>bias</em>
of <span class="math inline">\(\hat{\theta}_n\)</span> (w.r.t. the
unknown parameter <span class="math inline">\(\theta\)</span>). We say
that <span class="math inline">\(\hat{\theta}_n\)</span> is
<em>unbiased</em>, if <span class="math display">\[\forall \theta \in
\Theta: \operatorname{Bias}(\hat{\theta}_n) = 0.\]</span></p>
<p>Note that to compute the bias, we need to compute <span
class="math inline">\(\mathbb{E}[\hat{\theta}_n] = \int_{\mathbb{R}^n}
\hat{\theta}_n(x_1,\ldots,x_n) d P^n_\theta(x_1,\ldots,x_n)\)</span>
which usually leads to a function of the unknown parameter <span
class="math inline">\(\theta\)</span>. Sometimes people use <span
class="math inline">\(\mathbb{E}_{\theta}\)</span> to emphasize the fact
that the random variables have distribution <span
class="math inline">\(P_\theta\)</span>, but we simply write <span
class="math inline">\(\mathbb{E}\)</span> as long as the source of
randomness is clear. Moreover, using properties of expectation
(especially linearity) can often simplify the calculation.</p></li>
<li><p>We call <span
class="math display">\[\operatorname{MSE}(\hat{\theta}_n)
\coloneq\mathbb{E}( \hat{\theta}_n - \theta)^2\]</span> the <em>mean
squared error</em> of <span
class="math inline">\(\hat{\theta}_n\)</span> (w.r.t. the unknown
parameter <span class="math inline">\(\theta\)</span>). As we will show
shortly, computing MSE is equivalent to computing the bias and variance
of <span class="math inline">\(\hat{\theta}_n\)</span>.</p></li>
</ol>
</div>
<div class="example">
<p><em>Example 5.9</em>. Let <span class="math inline">\(P_\theta =
\mathcal{N}(\theta,\sigma^2)\)</span> for <span
class="math inline">\(\theta \in \mathbb{R}\)</span> and variance <span
class="math inline">\(\sigma^2\)</span>. Let <span
class="math inline">\(X_1,X_2,\ldots,X_n\)</span> be an i.i.d. sample
from <span class="math inline">\(P_\theta\)</span> and define <span
class="math inline">\(\hat{\theta}_n \coloneq\overline{X}_n =
\sum_{i=1}^nX_i/n\)</span>. For any <span class="math inline">\(\theta
\in \mathbb{R}\)</span>, <span
class="math inline">\(\mathbb{E}[\hat{\theta}_n] =
\mathbb{E}[\overline{X}_n] = \theta\)</span>, so the sample mean <span
class="math inline">\(\overline{X}_n\)</span> is an unbiased estimator
for <span class="math inline">\(\theta\)</span>. For the mean squared
error, note that <span class="math display">\[\mathbb{E}( \hat{\theta}_n
- \theta)^2  = \mathbb{E}(\overline{X}_n-\theta)^2 =
\mathbb{E}(\overline{X}_n-\mathbb{E}(\overline{X}_n))^2 =
\text{Var}(\overline{X}_n) = \sigma^2/n.\]</span></p>
</div>
<div id="lemma:bias-variance" class="lemma">
<p><strong>Lemma 5.10</strong> (Bias-variance decomposition). <em>Let
<span class="math inline">\(\hat{\theta}_n\)</span> be an estimator for
the unknown parameter <span class="math inline">\(\theta\)</span> of a
statistical model <span class="math inline">\((P_\theta)_{\theta \in
\Theta}\)</span>. It holds that <span class="math display">\[\forall
\theta \in \Theta: \quad \operatorname{MSE}(\hat{\theta}_n) =
(\operatorname{Bias}(\hat{\theta}_n))^2 +
\operatorname{Var}(\hat{\theta}_n).\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> <span class="math display">\[\begin{aligned}
\operatorname{MSE}(\hat{\theta}_n) &amp;= \mathbb{E}\big[\lvert
(\hat{\theta}_n - \mathbb{E}[\hat{\theta}_n]) +
(\mathbb{E}[\hat{\theta}_n] - \theta)\rvert^2\big] \\
&amp;=\mathbb{E}\big[\lvert \hat{\theta}_n - \mathbb{E}[\hat{\theta}_n]
\rvert^2 \big]
+ 2\underbrace{\mathbb{E}\big[(\hat{\theta}_n -
\mathbb{E}[\hat{\theta}_n])(\mathbb{E}[\hat{\theta}_n] - \theta)
\big]}_{\mathclap{=\underbrace{\mathbb{E}[(\hat{\theta}_n -
\mathbb{E}[\hat{\theta}_n])]}_{\mathclap{= \mathbb{E}[\hat{\theta}_n] -
\mathbb{E}[\hat{\theta}_n] = 0}}\textstyle{(\mathbb{E}[\hat{\theta}_n] -
\theta)}}} +\underbrace{\mathbb{E}\big[\lvert \mathbb{E}[\hat{\theta}_n]
- \theta \rvert^2 \big]}_{\textstyle= \lvert \mathbb{E}[\hat{\theta}_n]
- \theta \rvert^2} \\
&amp;=\mathbb{E}\big[\lvert \hat{\theta}_n - \mathbb{E}[\hat{\theta}_n]
\rvert^2 \big]  +  \lvert \mathbb{E}[\hat{\theta}_n] - \theta \rvert^2\\
&amp;= \mathop{\mathrm{Var}}(\hat{\theta}_n) +
\big(\operatorname{Bias}(\hat{\theta}_n)\big)^2
\end{aligned}\]</span> ◻</p>
</div>
<div id="example:expo1" class="example">
<p><em>Example 5.11</em>. Let <span class="math inline">\(P_\theta =
\operatorname{Exp}(\theta)\)</span> for <span
class="math inline">\(\theta \in (0,\infty)\)</span>, i.e. <span
class="math display">\[f(x;\theta) = \theta e^{-\theta x}, x \geq 0,
\theta &gt;0.\]</span> Suppose <span class="math inline">\(n &gt;
2\)</span>. Consider <span class="math inline">\(\hat{\theta}_n =
\tfrac{1}{\overline{X}_n}\)</span> and we would like to compute its bias
and mean squared error. Since <span
class="math inline">\(X_1,\dotsc,X_n\)</span> are i.i.d Exp(<span
class="math inline">\(\theta\)</span>), we have <span
class="math inline">\(\sum_{i=1}^n X_i\)</span> has distribution <span
class="math inline">\(\Gamma(n,\theta)\)</span> (See Proposition 3.2.18)
with density function <span class="math inline">\(f_{n,\theta}\)</span>.
Therefore, <span class="math display">\[\begin{aligned}
         \mathbb{E}\mathopen{}\mathclose\bgroup\left[\frac{1}{\overline{X}_n}\aftergroup\egroup\right]
&amp;= \mathbb{E}\mathopen{}\mathclose\bgroup\left[\frac{n}{\sum_{i=1}^n
X_i}\aftergroup\egroup\right] = \int_0^{\infty} \frac{n}{y}
f_{n,\theta}(y) dy = \int_0^{\infty}
\frac{n}{y}\frac{\theta^n}{\Gamma(n)}y^{n-1}e^{-\theta y} dy \\
         &amp;= \frac{n\theta\Gamma(n-1)}{\Gamma(n)}
\int_0^{\infty}\frac{\theta^{n-1}}{\Gamma(n-1)}y^{n-2}e^{-\theta y} dy =
\frac{n}{n-1} \theta \int_0^{\infty} f_{n-1,\theta}(y) dy =
\frac{n}{n-1} \theta.
    
\end{aligned}\]</span> Then we have <span
class="math display">\[\text{Bias}(\hat{\theta}_n) = \frac{n}{n-1}\theta
- \theta = \frac{1}{n-1}\theta.\]</span> We leave it as an exercise to
show that <span class="math display">\[\text{Var}(\hat{\theta}_n) =
\frac{n^2\theta^2}{(n-1)^2(n-2)}.\]</span> Combining the results for
bias and variance of <span
class="math inline">\(\hat{\theta}_n\)</span>, we can conclude using
Lemma <a href="#lemma:bias-variance" data-reference-type="ref"
data-reference="lemma:bias-variance">5.10</a> that <span
class="math display">\[\text{MSE}(\hat{\theta}_n) =
\text{Bias}(\hat{\theta}_n)^2+\text{Var}(\hat{\theta}_n) =
\mathopen{}\mathclose\bgroup\left(\frac{1}{n-1}\theta\aftergroup\egroup\right)^2
+ \frac{n^2\theta^2}{(n-1)^2(n-2)} =
\frac{n+2}{(n-1)(n-2)}\theta^2.\]</span></p>
</div>
<p>Bias, variance, and mean squared error are all important quantities
regarding an estimator that we might be interested in. In particular,
they describe different aspects of the finite-sample (non-asymptotic)
behavior of an estimator. We are also interested in asymptotic
properties of an estimator, which describes the behavior of an estimator
as the sample size <span class="math inline">\(n\)</span> becomes
infinite. The power of asymptotic evaluation is that when we let the
sample size becomes infinite, calculations simplify.</p>
<div class="definition">
<p><strong>Definition 5.12</strong> (Consistency and Asymptotics).  </p>
<ol>
<li><p>We say that <span class="math inline">\(\hat{\theta}_n\)</span>
is <em>consistent</em>, if <span class="math display">\[\forall \theta
\in \Theta: \hat{\theta}_n \overset{\mathbb{P}_\theta}{\longrightarrow}
\theta \quad \Big(\iff \forall \theta \in \Theta,\varepsilon &gt; 0:
\mathbb{P}_\theta(\lvert \hat{\theta}_n - \theta \rvert \geq
\varepsilon) \underset{n \to \infty}{\longrightarrow} 0
\Big)\]</span></p></li>
<li><p>We say <span class="math inline">\(\hat{\theta}_n\)</span> is
<em>mean square consistent</em>, if <span
class="math display">\[\text{MSE}(\hat{\theta}_n) \underset{n \to
\infty}{\longrightarrow} 0,\]</span> and <span
class="math inline">\(\hat{\theta}_n\)</span> is <em>asymptotically
unbiased</em> if <span
class="math display">\[\text{Bias}(\hat{\theta}_n) \underset{n \to
\infty}{\longrightarrow} 0.\]</span></p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 5.13</em>. Note that mean square consistent is equivalent
to say <span
class="math inline">\(\hat{\theta}_n\overset{\mathcal{L}^2}{\longrightarrow}
\theta\)</span> by definition. However, <span
class="math inline">\(\mathbb{E}(\hat{\theta}_n- \theta) \rightarrow
0\)</span> does not imply <span
class="math inline">\(\mathbb{E}|\hat{\theta}_n- \theta| \rightarrow
0\)</span>, and therefore asymptotically unbiasedness does not imply
convergence in <span class="math inline">\(\mathcal{L}^1\)</span>.</p>
</div>
<div id="prop:mse-consistent" class="proposition">
<p><strong>Proposition 5.14</strong>. <em>Let <span
class="math inline">\((\hat{\theta}_n)_{n \in \mathbb{N}}\)</span> be a
sequence of estimators for the unknown parameter <span
class="math inline">\(\theta\)</span> of a statistical model <span
class="math inline">\((P_\theta)_{\theta \in \Theta}\)</span>. If <span
class="math inline">\(\operatorname{MSE}(\hat{\theta}_n) \underset{n \to
\infty}{\longrightarrow} 0\)</span> for all <span
class="math inline">\(\theta \in \Theta\)</span>, then <span
class="math inline">\((\hat{\theta}_n)_{n \in \mathbb{N}}\)</span> is
consistent.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> It is a direct consequence of convergence in <span
class="math inline">\(\mathcal{L}^2\)</span> implies convergence in
probability (Theorem 4.1.2). We repeat this proof here again. For all
<span class="math inline">\(\theta \in \Theta\)</span> and <span
class="math inline">\(\varepsilon &gt; 0\)</span>, Markov’s inequality
gives <span class="math display">\[\mathbb{P}_\theta(\lvert
\hat{\theta}_n - \theta \rvert \geq \varepsilon) \leq
\frac{\mathbb{E}[\lvert \hat{\theta}_n - \theta
\rvert^2]}{\varepsilon^2} =
\frac{\operatorname{MSE}(\hat{\theta}_n)}{\varepsilon^2} \underset{n \to
\infty}{\longrightarrow} 0.\]</span> This establishes <span
class="math inline">\(\hat{\theta}_n
\overset{\mathbb{P}}{\longrightarrow} \theta\)</span> for all <span
class="math inline">\(\theta \in \Theta\)</span>, i.e.,
consistency. ◻</p>
</div>
<div id="ex:var_mse" class="example">
<p><em>Example 5.15</em>. Let <span class="math inline">\(P_{\theta} =
\mathcal{N}(0,\theta^2)\)</span> for <span class="math inline">\(\theta
\in (0,\infty)\)</span> and let <span
class="math inline">\(X_1,X_2,\ldots, X_n \overset{i.i.d}{\sim}
P_\theta\)</span>. Consider <span class="math inline">\(\hat{\theta}^2_n
\coloneq\frac{1}{n}\sum_{i=1}^n X_i^2\)</span>, we have immediately
<span class="math display">\[\mathbb{E}[\hat{\theta}^2_n] =
\mathbb{E}[X_1^2] = \theta^2,\]</span> and therefore it is an unbiased
estimator for <span class="math inline">\(\theta^2\)</span>. Moreover,
since <span class="math inline">\(\theta^2 &lt; \infty\)</span>, by the
strong LLN, for any <span class="math inline">\(\theta^2 \in
(0,\infty)\)</span> it holds that <span
class="math inline">\(\hat{\theta}^2_n
\overset{\text{a.s.}}{\longrightarrow} \theta^2\)</span> and therefore
also <span class="math inline">\(\hat{\theta}^2_n
\overset{\mathbb{P}}{\longrightarrow} \theta^2\)</span>, so <span
class="math inline">\(\hat{\theta}^2_n\)</span> is a consistent
estimator for <span class="math inline">\(\theta^2\)</span>.</p>
<p>Now, consider <span class="math inline">\(\hat{\theta}_n
\coloneq\sqrt{\tfrac{1}{n}\sum_{i=1}^n X_i^2}\)</span>. By the
continuous mapping theorem, it holds that <span
class="math display">\[\forall \theta \in \Theta: \quad \hat{\theta}_n
\overset{\mathbb{P}}{\longrightarrow} \theta.\]</span> If we tried to
show the consistency of <span
class="math inline">\(\hat{\theta}_n\)</span> for <span
class="math inline">\(\theta\)</span> by computing its MSE, it would be
much more difficult.</p>
</div>
<p>We can draw the following conclusion between various concepts
introduced so far. Suppose <span class="math inline">\(X_1,\dotsc, X_n
\overset{i.i.d}{\sim} P_\theta\)</span>. All the statements below are
regarding the parameter <span class="math inline">\(\theta\)</span>.</p>
<ul>
<li><p>If <span class="math inline">\(\hat{\theta}_n\)</span> is
unbiased, then it is asymptotically unbiased. The converse is not true
(See Example <a href="#example:expo1" data-reference-type="ref"
data-reference="example:expo1">5.11</a>).</p></li>
<li><p>If <span class="math inline">\(\hat{\theta}_n\)</span> is mean
square consistent, then it is consistent (Proposition <a
href="#prop:mse-consistent" data-reference-type="ref"
data-reference="prop:mse-consistent">5.14</a>). The converse is not
true.</p></li>
<li><p>If <span class="math inline">\(\hat{\theta}_n\)</span> is mean
square consistent, then it is asymptotically unbiased.</p></li>
<li><p>Asymptotically unbiased and consistency generally do not imply
each other. (See exercises below).</p></li>
</ul>
<div class="exercise">
<p><em>Exercise 5.16</em>. Show that if <span
class="math inline">\(X_1,\dotsc, X_n \overset{i.i.d}{\sim}
\text{Exp}(\theta)\)</span>, then <span class="math inline">\(X_{\min} =
\min\{X_1,\dotsc,X_n\}\)</span> has distribution Exp(<span
class="math inline">\(n\theta\)</span>). Use this to show that <span
class="math inline">\(T_n(X) = nX_{\min}\)</span> is unbiased for <span
class="math inline">\(1/\theta\)</span>, i.e. <span
class="math inline">\(\mathbb{E}( nX_{\min}) = 1/\theta\)</span>. Also
compute <span class="math inline">\(\text{Var}(T_n(X))\)</span> and
conclude that it is not mean square consistent for <span
class="math inline">\(1/\theta\)</span>.</p>
</div>
<p>Given the result from the above exercise, we have for any <span
class="math inline">\(\varepsilon&gt; 0\)</span> <span
class="math display">\[\mathbb{P}_\theta(|nX_{\min} - 1/\theta| &gt;
\varepsilon) \geq \mathbb{P}_\theta(nX_{\min} - 1/\theta &gt;
\varepsilon) = \mathbb{P}_\theta(X_{\min} &gt; (\varepsilon+
(1/\theta))/n) = \exp(-(\theta \varepsilon+ 1),\]</span> and therefore
we can conclude that <span class="math inline">\(nX_{\min}\)</span> is
an unbiased estimator for <span class="math inline">\(1/\theta\)</span>,
but it is not consistent.</p>
<div id="exer:consistencyimplies" class="exercise">
<p><em>Exercise 5.17</em> (*). Suppose <span
class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim} P_\theta,
\theta \in \Theta \subseteq \mathbb{R}\)</span>, and suppose we have an
estimator <span class="math inline">\(\hat{\theta}_n\)</span> that is
consistent and <span class="math inline">\(\mathbb{E}(\hat{\theta}^2_n)
\leq C\)</span>, for some constant <span
class="math inline">\(C&gt;0\)</span> and any <span
class="math inline">\(n \in \mathbb{N}\)</span>. Show that <span
class="math inline">\(\hat{\theta}_n\)</span> is also asymptotically
unbiased.</p>
</div>
<p>Having discussed various desirable properties of an estimator, we
will introduce a principled way of deriving estimators that enjoy some
of these properties (especially from an asymptotic point of view) in the
next chapter. It is known as the <em>Maximum Likelihood Estimator</em>
(MLE).</p>
<h2 id="confidence-intervals">Confidence intervals</h2>
<p>A confidence interval is a random interval <span
class="math inline">\(C\)</span> expressed in terms of the data <span
class="math inline">\(X_1,\ldots,X_n\)</span> such that with a certain
degree of confidence – that needs to be made precise – contains the
unknown parameter <span class="math inline">\(\theta\)</span>.</p>
<div class="definition">
<p><strong>Definition 5.18</strong>. Let <span
class="math inline">\(X_1,\ldots,X_n
\overset{i.i.d}{\sim}\mathbb{P}_\theta, \theta \in \Theta \subseteq
\mathbb{R}\)</span>.</p>
<ol>
<li><p>A random interval <span class="math inline">\(C_n(X) =
[L_n(X_1,\ldots,X_n), U_n(X_1,\ldots,X_n)] \subseteq
\mathbb{R}\)</span>, where <span class="math inline">\(L_n,U_n\)</span>
are measurable functions, is called a (non-asymptotic) confidence
interval (CI) at level <span class="math inline">\(1 - \alpha \in
(0,1)\)</span> for <span class="math inline">\(\theta\)</span>, if <span
class="math inline">\(\forall \theta \in \Theta\)</span> <span
class="math display">\[\underbrace{\mathbb{P}_\theta(\theta \in
C_n(X))}_{\mathclap{= \mathbb{P}_\theta\big(L_n(X_1,\ldots,X_n) \leq
\theta \leq U_n(X_1,\ldots,X_n)\big)}} \geq 1 -
\alpha.\]</span></p></li>
<li><p>We call <span class="math inline">\(C_n(X)\)</span> an asymptotic
(or approximate) confidence interval for <span
class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>, if for <span
class="math inline">\(\forall \theta \in \Theta\)</span> <span
class="math display">\[\lim_{n \to \infty} \mathbb{P}_\theta(\theta \in
C_n(X)) \geq 1 - \alpha.\]</span></p></li>
</ol>
</div>
<div class="remark">
<p><em>Remark 5.19</em>. </p>
<ul>
<li><p>It is important to stress that the confidence interval <span
class="math inline">\(C_n(X)\)</span> is a random quantity and the
parameter <span class="math inline">\(\theta\)</span> is fixed
(non-random)! The correct interpretation of CIs is that if we construct
many confidence intervals from repeated random samples, at least <span
class="math inline">\(100(1-\alpha)\%\)</span> of these intervals would
contain the true parameter <span
class="math inline">\(\theta\)</span>.</p></li>
<li><p>Confidence intervals often requires distributional properties of
some estimator for <span class="math inline">\(\theta\)</span> to be
understood. It is typically difficult to characterize the distribution
of some estimator for every finite <span
class="math inline">\(n\)</span>, but their limiting distributions are
often easier to obtain thanks to results like CLT and Delta method
(Theorem <a href="#thm:delta" data-reference-type="ref"
data-reference="thm:delta">4.19</a>). Under the same statistical model,
CIs are often wider than asymptotic CIs, but they are valid for every
finite <span class="math inline">\(n\)</span> (hence the same
non-asymptotic) whereas asymptotic CIs are only valid when <span
class="math inline">\(n\)</span> is sufficiently large.</p></li>
</ul>
</div>
<h4
id="confidence-interval-for-the-unknown-mean-of-a-population">Confidence
interval for the unknown mean of a population</h4>
<div class="example">
<p><em>Example 5.20</em>. Suppose <span
class="math inline">\(X_1,\dotsc, X_n \overset{i.i.d}{\sim} N(\theta,
1)\)</span>, <span class="math inline">\(\theta \in \Theta \subseteq
\mathbb{R}\)</span>. The interval <span class="math inline">\(C =
(-\infty,\infty)\)</span> is a CI at level <span
class="math inline">\(1-\alpha\)</span> for any <span
class="math inline">\(\alpha \in (0,1)\)</span>, but it is useless in
the sense that it does not help us infer anything about <span
class="math inline">\(\theta\)</span>. In general, for a given <span
class="math inline">\(\alpha\)</span>, we are interested in finding
<span class="math inline">\(C_n\)</span> such that its length <span
class="math inline">\(|C_n|\)</span> is as small as possible. However,
we shall not dive into this issue here in this course; see Section 9,3
in <span class="citation" data-cites="casella2024statistical"></span>
for a complete treatment.</p>
<p>A more reasonable way of think about CIs is viewing it as quantifying
the uncertainty of a point estimator. Consider <span
class="math inline">\(\overline{X}_n\)</span> as an estimator for <span
class="math inline">\(\theta\)</span>. Then if we can show <span
class="math display">\[\label{eq:example-1}
      \mathbb{P}_\theta(|\overline{X}_n - \theta| \leq u_\alpha) \geq
1-\alpha,\]</span> then we have <span
class="math inline">\([\overline{X}_n - u_\alpha, \overline{X}_n +
u_\alpha]\)</span> is a CI for <span
class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>. Indeed, if <a
href="#eq:example-1" data-reference-type="eqref"
data-reference="eq:example-1">[eq:example-1]</a> is true, then we have
<span class="math display">\[\mathbb{P}_\theta(\overline{X}_n - u_\alpha
\leq \theta \leq \overline{X}_n + u_\alpha) \geq 1-\alpha.\]</span> In
practice, we can replace <span
class="math inline">\(\overline{X}_n\)</span> with the observed data
<span class="math inline">\(\overline{x}_n = \sum_{i=1}^n
x_i/n\)</span>, and the remaining question is to find <span
class="math inline">\(u_\alpha\)</span> such that <a
href="#eq:example-1" data-reference-type="eqref"
data-reference="eq:example-1">[eq:example-1]</a> holds. This can be done
using the fact that <span class="math inline">\(\overline{X}_n \sim
N(\theta,1/n)\)</span> and therefore <span
class="math inline">\(\sqrt{n}(\overline{X}_n - \theta) \sim
N(0,1)\)</span> <span
class="math display">\[\mathbb{P}_\theta(|\overline{X}_n - \theta| \leq
u_\alpha) = \mathbb{P}_\theta(|\sqrt{n}|\overline{X}_n - \theta| \leq
\sqrt{n} u_\alpha) = \mathbb{P}(|Z| \leq \sqrt{n}u_{\alpha}) =
\mathbb{P}(- \sqrt{n}u_{\alpha}&lt; Z &lt; \sqrt{n}u_{\alpha})
=2(\Phi(\sqrt{n}u_\alpha)-1/2),\]</span> where <span
class="math inline">\(Z \sim N(0,1)\)</span> and <span
class="math inline">\(\Phi(z) = \mathbb{P}(Z \leq z)\)</span> is the CDF
of the standard normal distribution. For the above to be greater equal
than <span class="math inline">\(1-\alpha\)</span>, we need <span
class="math display">\[2(\Phi(\sqrt{n}u_\alpha)-1/2) \geq 1-\alpha
\implies  u_\alpha \geq \frac{1}{\sqrt{n}}
\Phi^{-1}(1-\alpha/2).\]</span> Therefore, we conclude that <span
class="math display">\[\Big[\overline{X}_n - \frac{1}{\sqrt{n}}
\Phi^{-1}(1-\alpha/2),\; \overline{X}_n + \frac{1}{\sqrt{n}}
\Phi^{-1}(1-\alpha/2)\Big],\]</span> is a CI for <span
class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>.</p>
<p>For a given value of <span class="math inline">\(\alpha \in
(0,1)\)</span>, <span
class="math inline">\(\Phi^{-1}(1-\alpha/2)\)</span> is sometimes called
critical values and it can be explicitly found from the normal table
(also known as the z-score table) in Table <a href="#fig:normaltable"
data-reference-type="ref" data-reference="fig:normaltable">7.1</a>. More
easily, if you use R as the programming language, <span
class="math inline">\(\Phi^{-1}(1-\alpha/2)\)</span> can be found
using</p>
<pre><code>    qnorm(1-alpha/2)</code></pre>
<p>where <span class="math inline">\(\text{alpha}\)</span> is your input
value for <span class="math inline">\(\alpha\)</span>. Sometimes, we
write <span class="math inline">\(z_{1-\alpha/2}:=
\Phi^{-1}(1-\alpha/2)\)</span> so that <span
class="math display">\[\mathbb{P}(X \leq z_{1-\alpha/2}) =
1-\alpha/2.\]</span></p>
<p>To give a specific example, suppose that <span
class="math inline">\(x = \{2.86,3.45,1.76,4,3.7,2.88,5.6\}\)</span>,
then we have <span class="math inline">\(n = 7\)</span> and <span
class="math inline">\(\overline{x}_n = 3.464\)</span>. For <span
class="math inline">\(\alpha = 0.05\)</span>, <span
class="math inline">\(\Phi^{-1}(1-\alpha/2) = 1.96\)</span>, and
therefore, we conclude that <span class="math display">\[[\overline{X}_n
- \frac{1.96}{\sqrt{n}}, \overline{X}_n + \frac{1.96}{\sqrt{n}}] \approx
[3.464-\frac{1.96}{\sqrt{7}}, 3.464+\frac{1.96}{\sqrt{7}}] \approx
[2.724, 4.204]\]</span> is a 95% CI for <span
class="math inline">\(\theta\)</span>.</p>
</div>
<p>The same arguments used in the above example leads immediately to the
following result.</p>
<div id="prop:normalCI" class="proposition">
<p><strong>Proposition 5.21</strong>. <em>If <span
class="math inline">\(X_1,\dotsc, X_n \overset{i.i.d}{\sim} N(\theta,
\sigma^2)\)</span>, <span class="math inline">\(\theta \in \Theta
\subseteq \mathbb{R}\)</span>, and assume <span
class="math inline">\(\sigma &gt; 0\)</span> is known. Then <span
class="math display">\[C_n =  \Big[\overline{X}_n -
\frac{\sigma}{\sqrt{n}} z_{1-\alpha/2} ,\; \overline{X}_n +
\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2} \Big],\]</span> is a CI for <span
class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>.</em></p>
</div>
<div id="example:asym-CI" class="example">
<p><em>Example 5.22</em>. In the example above, the key step in deriving
the CI for <span class="math inline">\(\theta\)</span> is that we use
the distributional property of <span
class="math inline">\(\overline{X}_n\)</span> to control <a
href="#eq:example-1" data-reference-type="eqref"
data-reference="eq:example-1">[eq:example-1]</a>. Now, consider <span
class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim}
P_{\theta}\)</span>, <span class="math inline">\(\theta \in \Theta
\subseteq \mathbb{R}\)</span>, with <span
class="math inline">\(\mathbb{E}(X_1) = \theta\)</span> and <span
class="math inline">\(\text{Var}(X_1) = \sigma^2\)</span>. We assume
<span class="math inline">\(\sigma &gt;0\)</span> is known. Even if we
do not know the distribution of <span
class="math inline">\(\overline{X}_n\)</span>, we can still show <span
class="math display">\[[\overline{X}_n - \frac{1.96\sigma}{\sqrt{n}},
\overline{X}_n + \frac{1.96\sigma}{\sqrt{n}}]\]</span> is an asymptotic
95% CI for <span class="math inline">\(\theta\)</span> by using CLT and
Lemma <a href="#lem:int_weak" data-reference-type="ref"
data-reference="lem:int_weak">4.14</a>. Indeed, we have <span
class="math inline">\(\sqrt{n}\frac{\overline{X}_n - \theta}{\sigma}
\overset{d}{\longrightarrow} N(0,1)\)</span> by CLT, and therefore <span
class="math display">\[\mathbb{P}_\theta\Big(\sqrt{n}\frac{\overline{X}_n
- \theta}{\sigma} \in [-z,z]\Big)  \underset{n \to
\infty}{\longrightarrow}  2\Phi(z) -1,\]</span> and choosing <span
class="math inline">\(z = z_{1-\alpha/2} =
\Phi^{-1}(1-\alpha/2)\)</span> gives an asymptotic CI for <span
class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span> as <span
class="math display">\[C_n =  \Big[\overline{X}_n -
\frac{\sigma}{\sqrt{n}} z_{1-\alpha/2} ,\; \overline{X}_n +
\frac{\sigma}{\sqrt{n}} z_{1-\alpha/2} \Big].\]</span> Further choosing
<span class="math inline">\(\alpha = 0.05\)</span> leads to an
asymptotic 95% CI for <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="prop:conf_cheby" class="exercise">
<p><em>Exercise 5.23</em>. Let <span
class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim}
P_{\theta}\)</span>, <span class="math inline">\(\theta \in \Theta
\subseteq \mathbb{R}\)</span>, with <span
class="math inline">\(\mathbb{E}(X_1) = \theta\)</span> and <span
class="math inline">\(\text{Var}(X_1) = 1\)</span>.Then, for any <span
class="math inline">\(\alpha \in (0,1)\)</span>, <span
class="math display">\[C_n(X) \coloneq\big[\overline{X}_n -
\tfrac{1}{\sqrt{\alpha n}}, \overline{X}_n + \tfrac{1}{\sqrt{\alpha n}}
\big],\]</span> is an <span class="math inline">\(1-\alpha\)</span>
confidence interval for the unknown mean <span
class="math inline">\(\theta\)</span>.</p>
</div>
<p>Note that the size difference between the asymptotic confidence
intervals <span class="math inline">\(C_n\)</span> from Example <a
href="#example:asym-CI" data-reference-type="ref"
data-reference="example:asym-CI">5.22</a> and the non-asymptotic
confidence intervals from Exercise <a href="#prop:conf_cheby"
data-reference-type="ref" data-reference="prop:conf_cheby">5.23</a> –
denoted for the moment by <span
class="math inline">\(\tilde{C}_n\)</span> – can be large. E.g., for the
typical choice <span class="math inline">\(\alpha = 0.05\)</span>, we
<span class="math inline">\(\lvert \tilde{C}_n \rvert \approx 8.94
n^{-1/2}\)</span>. On the other hand, for the same choice of <span
class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\lvert {C}_n \rvert = 3.92 \sigma
n^{-1/2}\)</span>. Keep in mind however that <span
class="math inline">\(C_n\)</span> only guarantees an asymptotic <span
class="math inline">\(1-\alpha\)</span> coverage and is therefore only
useful for sufficiently large sample sizes, whereas <span
class="math inline">\(\tilde{C}_n\)</span> gives a <span
class="math inline">\(1-\alpha\)</span> coverage in probability for any
<em>finite</em> sample size <span class="math inline">\(n\)</span>.</p>
<h4
id="asymptotic-normality-and-ci-in-the-case-of-unknown-variance">Asymptotic
normality and CI in the case of unknown variance</h4>
<p>As we saw above, a common way to establish asymptotic CIs for <span
class="math inline">\(\theta\)</span> is by showing some estimator <span
class="math inline">\(\hat{\theta}_n\)</span> has an asymptotic normal
distribution, as defined below.</p>
<div class="definition">
<p><strong>Definition 5.24</strong>. Let <span
class="math inline">\((P_\theta)_{\theta \in \Theta}\)</span> be a
statistical model with parameter space <span
class="math inline">\(\Theta \subseteq \mathbb{R}\)</span>. We say an
estimator <span class="math inline">\(\hat{\theta}_n\)</span> is
asymptotically normal if, for some <span class="math inline">\(\sigma_n
\rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow
\infty\)</span>, <span class="math display">\[\frac{\hat{\theta}_n-
\theta}{\sigma_n} \overset{d}{\longrightarrow} N(0,1).\]</span> If <span
class="math inline">\(\sigma_n = \sigma/\sqrt{n}\)</span>, for some
<span class="math inline">\(\sigma &gt; 0\)</span>, then we say <span
class="math inline">\(\hat{\theta}_n\)</span> is asymptotically normal
with asymptotic variance <span class="math inline">\(\sigma^2\)</span>,
since in this case <span class="math display">\[\sqrt{n}(\hat{\theta}_n-
\theta) \overset{d}{\longrightarrow} N(0,\sigma^2)\]</span></p>
</div>
<div id="exer:asympnormalCI" class="exercise">
<p><em>Exercise 5.25</em>. Given a statistical model <span
class="math inline">\((P_\theta)_{\theta \in \Theta}\)</span> and an
asymptotically normal estimator <span
class="math inline">\(\hat{\theta}_n\)</span> with known <span
class="math inline">\(\sigma_n \rightarrow 0\)</span>, show that the
interval <span class="math display">\[C_n =
\mathopen{}\mathclose\bgroup\left[ \hat{\theta}_n - \sigma_n
z_{1-\alpha/2}, \hat{\theta}_n + \sigma_n z_{1-\alpha/2}
\aftergroup\egroup\right]\]</span> is an asymptotic confidence interval
(CI) for <span class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>.</p>
</div>
<div class="proposition">
<p><strong>Proposition 5.26</strong>. <em>If <span
class="math inline">\(\hat{\theta}_n\)</span> is asymptotically normal,
as defined above, then it is also consistent for <span
class="math inline">\(\theta\)</span>, i.e. <span
class="math inline">\(\hat{\theta}_n\overset{\mathbb{P}}{\longrightarrow}
\theta\)</span>. If, in addition, <span
class="math inline">\(\mathbb{E}(\hat{\theta}_n^2) &lt; \infty\)</span>
for all <span class="math inline">\(n \in \mathbb{N}\)</span>, then
<span class="math inline">\(\hat{\theta}_n\)</span> is also
asymptotically unbiased.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Since <span class="math inline">\(\sigma_n
\rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow
\infty\)</span>, by Slutsky’s theorem, we have <span
class="math display">\[\sigma_n \cdot \frac{\hat{\theta}_n-
\theta}{\sigma_n}  \overset{d}{\longrightarrow} 0 \implies
\hat{\theta}_n- \theta  \overset{\mathbb{P}}{\longrightarrow} 0
\iff  \hat{\theta}_n\overset{\mathbb{P}}{\longrightarrow}
\theta.\]</span> The second part of proof follows from exercise <a
href="#exer:consistencyimplies" data-reference-type="ref"
data-reference="exer:consistencyimplies">5.17</a>. ◻</p>
</div>
<div id="ex:normalmean" class="example">
<p><em>Example 5.27</em>. Let <span class="math inline">\(X_1,\dotsc,X_n
\overset{i.i.d}{\sim} P_{\theta}\)</span>, <span
class="math inline">\(\theta \in \Theta \subseteq \mathbb{R}\)</span>,
with <span class="math inline">\(\mathbb{E}(X_1) = \theta\)</span> and
<span class="math inline">\(\text{Var}(X_1) = \sigma^2\)</span>, but
with unknown <span class="math inline">\(\sigma &gt;0\)</span>. CLT
shows <span class="math inline">\(\hat{\theta}_n=
\overline{X}_n\)</span> is asymptotically normal with <span
class="math inline">\(\sigma_n = \sigma/\sqrt{n}\)</span>, i.e. <span
class="math display">\[\sqrt{n}\frac{\overline{X}_n -\theta}{\sigma}
\overset{d}{\longrightarrow} N(0,1).\]</span> From Exercise <a
href="#exer:asympnormalCI" data-reference-type="ref"
data-reference="exer:asympnormalCI">5.25</a>, we have <span
class="math display">\[[\overline{X}_n -
\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2}, \overline{X}_n +
\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2}]\]</span> is an asymptotic CI for
<span class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>. In practice, we often do not
know the value of <span class="math inline">\(\sigma\)</span> and it has
to be estimated using the data. However, as long as we have a consistent
estimator for <span class="math inline">\(\sigma\)</span>, i.e. <span
class="math inline">\(\hat{\sigma}_n \overset{P}{\longrightarrow}
    \sigma\)</span> then <span class="math display">\[[\overline{X}_n -
\frac{\hat{\sigma}_n}{\sqrt{n}}z_{1-\alpha/2}, \overline{X}_n +
\frac{\hat{\sigma}_n}{\sqrt{n}}z_{1-\alpha/2}]\]</span> is again an
asymptotic CI for <span class="math inline">\(\theta\)</span> at level
<span class="math inline">\(1-\alpha\)</span>. This is because we
actually have <span class="math display">\[\sqrt{n}\frac{\overline{X}_n
-\theta}{\hat{\sigma}_n} = \sqrt{n}\frac{\overline{X}_n
-\theta}{{\sigma}} \frac{{\sigma}}{\hat{\sigma}_n}
\overset{d}{\longrightarrow} N(0,1),\]</span> due to Slutsky’s theorem,
where <span class="math inline">\(\frac{{\sigma}}{\hat{\sigma}_n}
\overset{\mathbb{P}}{\longrightarrow} 1\)</span> can seen by applying
continuous mapping theorem to <span class="math inline">\(\hat{\sigma}_n
\overset{P}{\longrightarrow}
    \sigma\)</span>.</p>
</div>
<h1 id="maximum-likelihood-estimation">Maximum Likelihood
Estimation</h1>
<p>The construction of estimators for individual problems is made much
simpler by the existence of some general techniques for doing so. One of
the most widely used approaches in statistics centers around the
likelihood function.</p>
<h2
id="likelihood-function-and-maximum-likelihood-estimator-mle">Likelihood
function and maximum likelihood estimator (MLE)</h2>
<div class="definition">
<p><strong>Definition 6.1</strong>. Let <span
class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim}f(x;\theta),
\theta \in \Theta\)</span>. The likelihood function is defined as <span
class="math display">\[L(\theta;X) := \prod_{i=1}^{n}
f(X_i;\theta),\]</span> and the log-likelihood function is defined as
<span class="math display">\[l(\theta; X) := \log L(\theta;X) =
\sum_{i=1}^n \log f(X_i;\theta).\]</span> The <em>maximum likelihood
estimator (MLE)</em> is defined as <span
class="math display">\[\hat{\theta}_{MLE}(X) :=
\mathop{\mathrm{arg\,max}}_{\theta \in \Theta}  L(\theta;X) =
\mathop{\mathrm{arg\,max}}_{\theta \in \Theta}  l(\theta;X)\footnote{The
reason taht $ L(\theta;X)$ and $l(\theta;X)$ have the same maximiser is
because $x \rightarrow \log(x)$ is an increasing
function.}.\]</span></p>
</div>
<div class="remark">
<p><em>Remark 6.2</em>.  </p>
<ul>
<li><p>Suppose we observed <span class="math inline">\(x =
(x_1,\dotsc,x_n)\)</span> as the realisations of <span
class="math inline">\(X = (X_1,\dotsc,X_n)\)</span>. Then, we call <span
class="math inline">\(L(\theta;x) := \prod_{i=1}^{n}
f(x_i;\theta)\)</span> the observed likelihood function, <span
class="math inline">\(l(\theta; x) := \log L(\theta;x)\)</span> the
observed log-likelihood function, and <span
class="math inline">\(\hat{\theta}_{MLE}(x) :=
\mathop{\mathrm{arg\,max}}_{\theta \in \Theta}  L(\theta;x)\)</span> the
maximum likelihood estimate. These quantities are fixed and can computed
once the actual data <span class="math inline">\(x =
(x_1,\dotsc,x_n)\)</span> is given.</p></li>
<li><p>Both the <span class="math inline">\(L(\theta;X)\)</span> and
<span class="math inline">\(l(\theta;X)\)</span> should be viewed as a
function of <span class="math inline">\(\theta\)</span>, and MLE is the
maximiser of both functions in <span
class="math inline">\(\theta\)</span>.</p></li>
<li><p><span class="math inline">\(L(\theta;X)\)</span> is not a pdf/pmf
for <span class="math inline">\(\theta\)</span> and in particular <span
class="math inline">\(\int_{\Theta} L(\theta;X) d\theta \neq
1\)</span>.</p></li>
<li><p>Finding MLE is essentially an optimisation problem. MLE may not
exist and it may not be unique, depending on the complexity of the
statistical model <span class="math inline">\(\{f(x,\theta), \theta \in
\Theta\}\)</span>. However, we shall later implicitly assume a set of
<em>regularity conditions</em> that avoids such issues so that MLE
exists and is unique.</p></li>
<li><p>Note that, by definition, <span
class="math inline">\(\hat{\theta}_{MLE}(X) \in \Theta\)</span>,
i.e. the estimator always belongs to the parameter space.</p></li>
<li><p>We note that <span
class="math inline">\(\hat{\theta}_{MLE}(X)\)</span> is a random
variable with distribution depending on <span
class="math inline">\(f(x,\theta)\)</span>, so we will be interested in
studying the statistical properties of <span
class="math inline">\(\hat{\theta}_{MLE}(x)\)</span>, e.g. bias,
consistency, and asymptotic normality.</p></li>
<li><p>MLE usually turns out to be quite intuitive if there is a clear
interpretation of the parameter that you try to estimate. It gives a
principled way to obtain point estimation and confidence intervals when
the statistical model becomes more complex, and it also enjoys several
desirable statistical properties.</p></li>
</ul>
</div>
<p>One could view the definition of likelihood function as the joint
pdf/pmf of <span class="math inline">\(X_1,\dotsc,X_n\)</span> and it
takes the product form due to our assumption that they are independent.
This view also leads to the following motivation for MLE:</p>
<p>If <span class="math inline">\(L(\theta_1;X) &gt;
L(\theta_2;X)\)</span> (equivalently, if <span
class="math inline">\(l(\theta_1;X) &gt; l(\theta_2;X)\)</span>), then
<span class="math inline">\(\theta_1\)</span> is more likely to have
been responsible for producing the observed <span
class="math inline">\(X_1, \dotsc, X_n\)</span>. In other words, <span
class="math inline">\(f(x;\theta_1)\)</span> is a better model than
<span class="math inline">\(f(x;\theta_2)\)</span> in terms of how well
it fits the observed data.</p>
<p>One can extend the definition of Likelihood function to allow
dependence as well as change in distribution. The simplest extension is
perhaps to the case where the data are independent but not identically
distributed. A prominent example of this case is the linear regression
problem.</p>
<div class="example">
<p><em>Example 6.3</em>. Suppose that <span class="math inline">\(Y_i =
x_i^{\top}\beta + \varepsilon_i, i = 1,\dotsc,n\)</span>, where <span
class="math inline">\(\varepsilon_i \overset{i.i.d}{\sim}N(0,
\sigma^2)\)</span> with known <span class="math inline">\(\sigma &gt;
0\)</span>, and <span class="math inline">\(x_i \in
\mathbb{R}^d\)</span> is assumed to be known and
fixed/deterministic/non-random. The parameter <span
class="math inline">\(\beta \in R^d\)</span> is the regression
coefficient. Using properties of Gaussian random variables, we have
<span class="math display">\[Y_i \sim N(x_i^{\top}\beta,
\sigma^2),\]</span> and they are independent. Therefore, the likelihood
function, or joint pdf of <span class="math inline">\(Y =
(Y_1,\dotsc,Y_n)\)</span>, in this case is <span
class="math display">\[L(\beta; Y, x) = \prod_{i=1}^n
\frac{1}{\sqrt{2\pi} \sigma} \exp\Big(-\frac{1}{2\sigma^2} (Y_i -
x_i^{\top}\beta)^2\Big),\]</span> and the MLE for <span
class="math inline">\(\beta\)</span> can be found as <span
class="math display">\[\hat{\beta}_{MLE}(Y, x) =
\mathop{\mathrm{arg\,max}}_{\beta \in \mathbb{R}^d}L(\beta; Y,
x)\]</span></p>
</div>
<p>The following exercise shows that the MLE for <span
class="math inline">\(\beta\)</span> in a regression problem can be
obtained by a method known commonly as the least square method.</p>
<div id="exer:regression" class="exercise">
<p><em>Exercise 6.4</em>. Suppose that <span class="math inline">\(Y_i =
x_i^{\top}\beta + \varepsilon_i, i = 1,\dotsc,n\)</span>, where <span
class="math inline">\(\varepsilon_i \overset{i.i.d}{\sim}N(0,
\sigma^2)\)</span> with known <span class="math inline">\(\sigma &gt;
0\)</span>, and <span class="math inline">\(x_i \in
\mathbb{R}^d\)</span> is assumed to be known and
fixed/deterministic/non-random. Show that the MLE for <span
class="math inline">\(\beta\)</span> coincides with <span
class="math display">\[\hat{\beta}(Y, x) :=
\mathop{\mathrm{arg\,min}}_{\beta \in \mathbb{R}^d} \sum_{i=1}^n {(Y_i -
x_i^{\top}\beta)^2},\]</span> i.e. <span
class="math inline">\(\hat{\beta}_{MLE}(Y, x) =  \hat{\beta}(Y,
x)\)</span>. Find <span class="math inline">\(\hat{\beta}(Y, x)\)</span>
explicitly by solving the above optimization problem, assuming <span
class="math inline">\(\sum_{i=1}^n x_ix_i^{\top}\)</span> is
invertible.</p>
</div>
<h2 id="examples">Examples</h2>
<div class="example">
<p><em>Example 6.5</em>. Suppose <span class="math inline">\(X_1, \dots,
X_n \overset{i.i.d}{\sim}f(x;\theta)\)</span>, where <span
class="math display">\[f(x;\theta) =
\frac{1}{\sqrt{2\pi}}\exp(-(x-\theta)^2/2), \; x \in \mathbb{R}, \theta
\in \mathbb{R}.\]</span> Now, the likelihood function is <span
class="math display">\[L(\theta; X) = \Big(\frac{1}{\sqrt{2\pi}}\Big)^n
\exp\Big(-\frac{1}{2} \sum_{i=1}^n (X_i - \theta)^2\Big),\]</span> and
the log-likelihood function is <span class="math display">\[l(\theta; X)
= -n\log(\sqrt{2\pi})-\frac{1}{2}\sum_{i=1}^n(X_i - \theta)^2.\]</span>
To find the maximiser of <span class="math inline">\(l(\theta;
X)\)</span>, we first compute <span class="math inline">\(\frac{\partial
l}{\partial \theta}\)</span> and set it to zero to find stationary
points: <span class="math display">\[\frac{\partial l(\theta;
X)}{\partial \theta} = \sum_{i=1}^n(X_i - \theta) = 0 \implies
\hat{\theta}_n= \overline{X}_n.\]</span> To conclude <span
class="math inline">\(\hat{\theta}_n\)</span> is indeed the global
maximiser, we can take the second derivative <span
class="math display">\[\frac{\partial^2 l(\theta; X)}{\partial \theta^2}
= -n &lt; 0.\]</span> Note that <span
class="math inline">\(f(x;\theta)\)</span> is actually the density
function of <span class="math inline">\(N(\theta, 1)\)</span>. Now that
we have established <span class="math inline">\(\overline{X}_n\)</span>
is MLE for <span class="math inline">\(\theta\)</span>, we consider some
statistical properties of it</p>
<ul>
<li><p>Bias(<span class="math inline">\(\overline{X}_n\)</span>) = <span
class="math inline">\(\mathbb{E}(\overline{X}_n - \theta) = 0\)</span>,
Var(<span class="math inline">\(\overline{X}_n) = 1/n\)</span>,
MSE(<span class="math inline">\(\overline{X}_n) = 1/n\)</span>.</p></li>
<li><p><span class="math inline">\(\overline{X}_n\)</span> is consistent
and asymptotically unbiased for <span
class="math inline">\(\theta\)</span> since it is mean square consistent
for <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Since <span class="math inline">\(\overline{X}_n \sim N(\theta,
1/n)\)</span>, we have <span
class="math inline">\(\overline{X}_n\)</span> is asymptotically normal
with <span class="math inline">\(\sigma_n = 1/\sqrt{n}\)</span>. As a
result, by Exercise <a href="#exer:asympnormalCI"
data-reference-type="ref" data-reference="exer:asympnormalCI">5.25</a>,
we have <span class="math inline">\([\overline{X}_n -
\frac{z_{1-\alpha/2}}{\sqrt{n}},  \overline{X}_n +
\frac{z_{1-\alpha/2}}{\sqrt{n}}]\)</span> is an asymptotic CI for <span
class="math inline">\(\theta\)</span> at level <span
class="math inline">\(1-\alpha\)</span>. (Alternatively, one can
directly use the arguments in Example 5.3.3 to see this is in fact a
non-asymptotic CI)</p></li>
</ul>
</div>
<div id="example-gaussian-meanvariance" class="example">
<p><em>Example 6.8</em>. Suppose that <span
class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim}f(x;
\theta)\)</span>, where <span class="math inline">\(\theta  = (\mu,
\sigma)\)</span> and <span class="math display">\[f(x;\mu, \sigma) =
\frac{1}{\sqrt{2\pi}\sigma}\exp(-(x-\mu)^2/(2\sigma^2)), \; x \in
\mathbb{R}, \mu \in \mathbb{R}, \sigma &gt; 0.\]</span> We consider the
case where both <span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\sigma\)</span> are unknown and therefore, both of
them need to be estimated. The likelihood function is <span
class="math display">\[L(\mu, \sigma;X) =
\Big(\frac{1}{\sqrt{2\pi}\sigma}\Big)^n\exp\Big(-\frac{1}{2\sigma^2}\sum_{i=1}^n(X_i
- \mu)^2\Big)\]</span> and the log-likelihood is <span
class="math display">\[l(\mu,\sigma;X) = -n\log(\sqrt{2\pi} \sigma) -
\frac{1}{2\sigma^2}\sum_{i=1}^n(X_i - \mu)^2.\]</span> To find MLE for
<span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\sigma\)</span>, we first take partial derivative
to find the stationary point <span
class="math inline">\((\hat{\mu}_n,\hat{\sigma}_n)\)</span> of <span
class="math inline">\(l(\mu,\sigma;X)\)</span>: <span
class="math display">\[\frac{\partial l}{\partial \mu} =
\frac{1}{\sigma^2}\sum_{i=1}^n(X_i - \mu) = 0, \qquad \frac{\partial
l}{\partial \sigma} = -\frac{n}{\sigma} + \frac{1}{\sigma^3}
\sum_{i=1}^n(X_i - {\mu})^2= 0\]</span> Solving these equations leads to
<span class="math display">\[\hat{\mu}_n = \overline{X}_n, \quad
\hat{\sigma}^2_n = \frac{1}{n} \sum_{i=1}^n(X_i -
\overline{X}_n)^2.\]</span> Now, we must check this stationary point
<span class="math inline">\((\hat{\mu}_n,\hat{\sigma}_n)\)</span> is
indeed the global maximum. There are many arguments one can use to
justify it. One simple argument would be noticing that for any <span
class="math inline">\(\mu \neq \overline{X}_n\)</span> <span
class="math display">\[\sum_{i=1}^n (X_i - \mu)^2 &gt; \sum_{i=1}^n (X_i
- \overline{X}_n)^2.\]</span> Therefore, for any <span
class="math inline">\(\sigma &gt;0\)</span>, <span
class="math display">\[l(\hat{\mu}_n, \sigma;X) \geq l(\mu,
\sigma;X),\]</span> and it just remains to verify <span
class="math inline">\(l(\hat{\mu}_n,\sigma;X)\)</span> achieves its
global maximum at <span class="math inline">\(\hat{\sigma}_n\)</span>.
Taking the second derivative <span class="math display">\[\frac{\partial
^2}{\partial (\sigma)^2} l(\hat{\mu}_n,\hat{\sigma}_n)=
\frac{\partial}{\partial\sigma}\frac{\partial }{\partial \sigma}
l(\mu,\sigma)\bigg|_{\mu = \hat{\mu}_n, \sigma = \hat{\sigma}_n} =
\frac{-2n}{\hat{\sigma}_n^2} &lt; 0,\]</span> we can conclude that <span
class="math inline">\((\hat{\mu}_n,\hat{\sigma}_n)\)</span> is indeed
the global maximum and hence the MLE for <span
class="math inline">\(\theta = (\mu, \sigma)\)</span>.</p>
<p>A more direct approach to verify <span
class="math inline">\((\hat{\mu}_n,\hat{\sigma}_n)\)</span> is the MLE
involves computing the Hessian matrix. We leave that as an exercise(*).
Now, let’s consider some statistical properties of the MLE <span
class="math inline">\((\hat{\mu}_n,\hat{\sigma}_n)\)</span> .</p>
<p><u><strong>Asymptotic confidence interval for <span
class="math inline">\(\mu\)</span>:</strong></u></p>
<p>Recall from Proposition <a href="#prop:normalCI"
data-reference-type="ref" data-reference="prop:normalCI">5.21</a>, a CI
for <span class="math inline">\(\mu\)</span> at level <span
class="math inline">\(1-\alpha\)</span> is <span
class="math display">\[\Big[\overline{X}_n -
\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2}, \; \overline{X}_n +
\frac{\sigma}{\sqrt{n}}z_{1-\alpha/2}\Big],\]</span> when <span
class="math inline">\(\sigma\)</span> is known. We also have shown in
Example <a href="#ex:normalmean" data-reference-type="ref"
data-reference="ex:normalmean">5.27</a> that if we have a consistent
estimator for <span class="math inline">\(\sigma\)</span>, then we can
just replace <span class="math inline">\(\sigma\)</span> in the above CI
by its estimator. To that end, we need to study the properties of <span
class="math inline">\(\hat{\sigma}^2_n\)</span>. The following identity
is useful: <span class="math display">\[\hat{\sigma}^2_n = \frac{1}{n}
\sum_{i=1}^n(X_i - \overline{X}_n)^2 = \frac{1}{n}\sum_{i=1}^n X_i^2 -
\overline{X}_n^2.\]</span> Now, by SLLN and continuous mapping theorem,
we have <span class="math display">\[\frac{1}{n}\sum_{i=1}^n X_i^2
\overset{\text{a.s.}}{\longrightarrow} \mathbb{E}[X_1]^2, \quad
\overline{X}_n^2 \overset{\text{a.s.}}{\longrightarrow}
\mathbb{E}[X_1]^2,\]</span> Hence, <span
class="math display">\[\hat{\sigma}^2_n
\overset{\text{a.s.}}{\longrightarrow} \mathbb{E}[X_1^2] -
\mathbb{E}[X_1]^2 = \sigma^2 \implies \hat{\sigma}_n
\overset{\mathbb{P}}{\longrightarrow} \sigma.\]</span> Now that we have
found a consistent estimator for <span
class="math inline">\(\sigma\)</span>, we can conclude <span
class="math display">\[\Big[\overline{X}_n -
\frac{\hat{\sigma}_n}{\sqrt{n}}z_{1-\alpha/2}, \; \overline{X}_n +
\frac{\hat{\sigma}_n}{\sqrt{n}}z_{1-\alpha/2}\Big],\]</span> is an
asymptotic CI for <span class="math inline">\(\mu\)</span> at level
<span class="math inline">\(1-\alpha\)</span>, when <span
class="math inline">\(\sigma\)</span> is unknown, where <span
class="math inline">\(\hat{\sigma}_n = \sqrt{\frac{1}{n}
\sum_{i=1}^n(X_i - \overline{X}_n)^2}\)</span>.</p>
<p>We note that a non-asymptotic CI for <span
class="math inline">\(\mu\)</span> can be constructed by introducing the
student’s <span class="math inline">\(t\)</span> distribution. We will
discuss this later in the course in the context of hypothesis
testing.</p>
<p><u><strong>Confidence interval for <span
class="math inline">\(\sigma^2\)</span>:</strong></u></p>
<p>To construct a (non-asymptotic) confidence interval for <span
class="math inline">\(\sigma\)</span>, we need to understand the
distribution of <span class="math inline">\(\hat{\sigma}^2.\)</span> We
state the result directly. For a proof of this result, search Cochran’s
theorem.</p>
<div id="thm:cochran" class="theorem">
<p><strong>Theorem 6.6</strong>. <em>Suppose <span
class="math inline">\(X_1,\dotsc,X_n
\overset{i.i.d}{\sim}N(\mu,\sigma^2)\)</span>, then <span
class="math display">\[\frac{\sum_{i=1}^n(X_i -
\overline{X}_n)^2}{\sigma^2} \sim \chi^2_{n-1}.\]</span></em></p>
</div>
<p>To see this result intuitively, we note the following identity <span
class="math display">\[\frac{\sum_{i=1}^n(X_i -
\overline{X}_n)^2}{\sigma^2} = \frac{\sum_{i=1}^n(X_i -
\mu)^2}{\sigma^2} - \frac{n(\overline{X}_n - \mu)^2}{\sigma^2} \sim
\chi^2_{n} - \chi^2_1,\]</span> the key calculation is to argue <span
class="math inline">\(\overline{X}_n\)</span> and <span
class="math inline">\({\sum_{i=1}^n(X_i - \overline{X}_n)^2}\)</span>
are independent.</p>
<p>Note that Theorem <a href="#thm:cochran" data-reference-type="ref"
data-reference="thm:cochran">6.6</a> implies <span
class="math display">\[\frac{n \hat{\sigma}_n^2}{\sigma^2} \sim
\chi^2_{n-1},\]</span> which leads to the following CI for <span
class="math inline">\(\sigma^2\)</span>.</p>
<div class="corollary">
<p><strong>Corollary 6.7</strong>. <em>Suppose <span
class="math inline">\(X_1,\dotsc,X_n
\overset{i.i.d}{\sim}N(\mu,\sigma^2)\)</span>, <span
class="math inline">\(\hat{\sigma}_n^2 = \frac{1}{n} \sum_{i=1}^n(X_i -
\overline{X}_n)^2\)</span>. Given the critical values <span
class="math inline">\(\chi^2_{n-1,\alpha/2}\)</span> and <span
class="math inline">\(\chi^2_{n-1,1-\alpha/2}\)</span>, a confidence
interval for <span class="math inline">\(\sigma^2\)</span> at level
<span class="math inline">\(1-\alpha\)</span> is <span
class="math display">\[\Big[\frac{n
\hat{\sigma}_n^2}{\chi^2_{n-1,1-\alpha/2}}, \; \frac{n
\hat{\sigma}_n^2}{\chi^2_{n-1,\alpha/2}}\Big]\]</span></em></p>
</div>
<p>The specific values of <span
class="math inline">\(\chi^2_{n-1,1-\alpha/2}\)</span> and <span
class="math inline">\(\chi^2_{n-1,\alpha/2}\)</span> can be obtain from
R using the command</p>
<pre><code>    qchisq(1-alpha/2, n-1), qchisq(alpha/2, n-1),</code></pre>
<p>respectively.</p>
<div class="proof">
<p><em>Proof.</em> Since <span class="math inline">\(\frac{n
\hat{\sigma}_n^2}{\sigma^2} \sim \chi^2_{n-1},\)</span> we know <span
class="math display">\[\mathbb{P}\Big(\chi^2_{n-1,\alpha/2} \leq \frac{n
\hat{\sigma}_n^2}{\sigma^2}\leq \chi^2_{n-1,1-\alpha/2}\Big) \geq
1-\alpha,\]</span> by the definition of <span
class="math inline">\(\chi^2_{n-1,\alpha/2}\)</span> and <span
class="math inline">\(\chi^2_{n-1,1-\alpha/2}\)</span>. Simply rewriting
the inequalities inside the probability gives <span
class="math display">\[\mathbb{P}\Big(\frac{n
\hat{\sigma}_n^2}{\chi^2_{n-1,1-\alpha/2}} \leq \sigma^2 \leq
    \frac{n \hat{\sigma}_n^2}{\chi^2_{n-1,\alpha/2}}\Big) \geq
1-\alpha.\]</span> ◻</p>
</div>
<p>In fact, we can immediately see from the proof above, <span
class="math display">\[\Big[\sqrt{\frac{n
\hat{\sigma}_n^2}{\chi^2_{n-1,1-\alpha/2}}}, \; \sqrt{\frac{n
\hat{\sigma}_n^2}{\chi^2_{n-1,\alpha/2}}}\Big]\]</span> is a CI for
<span class="math inline">\(\sigma\)</span> at level <span
class="math inline">\(1-\alpha\)</span>, since <span
class="math inline">\(\sqrt{\cdot}\)</span> is an increasing function.
This is simple because our CI for <span
class="math inline">\(\sigma^2\)</span> is non-asymptotic. We shall see
later that using asymptotic arguments, one need to resort to Delta
method (Theorem <a href="#thm:delta" data-reference-type="ref"
data-reference="thm:delta">4.19</a>) to derive asymptotic CI for <span
class="math inline">\(\sigma\)</span>.</p>
<p><u><strong>The notion of sample variance:</strong></u></p>
<p>Finally, we discuss another important terminology used widely in
statistics - sample variance. To motivate it, we observe that since
<span class="math inline">\(\frac{n \hat{\sigma}_n^2}{\sigma^2} \sim
\chi^2_{n-1},\)</span> we have <span
class="math display">\[\mathbb{E}(\hat{\sigma}^2_n) =
\frac{n-1}{n}\sigma^2,\]</span> using the property that <span
class="math inline">\(\mathbb{E}(W) = k,\)</span> if <span
class="math inline">\(W \sim \chi^2_k\)</span>. This shows MLE are not
necessarily unbiased. We easily construct an unbiased estimator for
<span class="math inline">\(\sigma^2\)</span> based on <span
class="math inline">\(\hat{\sigma}^2_n\)</span>. Indeed, we have <span
class="math display">\[\mathbb{E}(\frac{n}{n-1}\hat{\sigma}^2_n) =
\mathbb{E}\Big(\frac{1}{n-1}\sum_{i=1}^n(X_i - \overline{X}_n)^2\Big) =
\sigma^2,\]</span> and this means <span class="math inline">\(S^2: =
\frac{1}{n-1}\sum_{i=1}^n(X_i - \overline{X}_n)^2\)</span> is unbiased
for <span class="math inline">\(\sigma^2\)</span>. We call <span
class="math inline">\(S^2\)</span> the <em>sample variance</em>
essentially due to its unbiasedness.</p>
</div>
<div class="example">
<p><em>Example 6.9</em>. Suppose <span class="math inline">\(X_1, \dots,
X_n \overset{i.i.d}{\sim}f(x;\theta)\)</span>, where <span
class="math display">\[f(x;\theta) = \theta e^{-\theta x}, x &gt; 0,
\theta &gt;0.\]</span> Thus, we have: <span
class="math display">\[L(\theta; X) = \theta^n e^{-\theta \sum_{i=1}^n
X_i}, \quad l(\theta; X) = n \log(\theta) - \theta \sum_{i=1}^n
X_i\]</span> To find the maximiser of <span
class="math inline">\(l(\theta;X)\)</span>, we can first compute <span
class="math inline">\(\frac{\partial l}{\partial \theta}\)</span> and
set it to zero to find stationary points: <span
class="math display">\[\frac{\partial l(\theta)}{\partial \theta} =
\frac{n}{\theta} - \sum_{i=1}^n X_i = 0 \implies \hat{\theta}_n=
\frac{1}{\overline{X}_n}.\]</span> where <span
class="math inline">\(\overline{X}_n\)</span> denotes the sample mean.
To verify the above <span class="math inline">\(\hat{\theta}_n\)</span>
indeed achieves maximum, we check <span
class="math display">\[\frac{\partial^2 l}{\partial \theta^2} =
-\frac{n}{\theta^2} &lt; 0,\]</span> which concludes that <span
class="math inline">\(\hat{\theta}_n=  \frac{1}{\overline{X}}\)</span>
is the MLE. We studied its properties in Example <a
href="#example:expo1" data-reference-type="ref"
data-reference="example:expo1">5.11</a> and we showed that</p>
<ul>
<li><p>Bias(<span class="math inline">\(\hat{\theta}_n) =
\frac{1}{n-1}\theta\)</span>, MSE<span
class="math inline">\((\hat{\theta}_n) = \frac{n+2}{(n-1)(n-2)}\theta^2
\rightarrow 0\)</span>, as <span class="math inline">\(n \rightarrow
\infty\)</span>. Therefore <span
class="math inline">\(\hat{\theta}_n\)</span> is asymptotically unbiased
but not unbiased for any finite <span class="math inline">\(n\)</span>.
It is consistent since it is mean square consistent.</p></li>
<li><p>We can actually show that <span class="math inline">\(\sqrt{
    n} (\hat{\theta}_n- \theta) \overset{d}{\longrightarrow} N(0,
\theta^2)\)</span> using Delta method (Theorem <a href="#thm:delta"
data-reference-type="ref" data-reference="thm:delta">4.19</a>) - check
this yourself! We will present some more general arguments later
on.</p></li>
</ul>
</div>
<div id="exer-bermle" class="exercise">
<p><em>Exercise 6.10</em>. Suppose we observe actual data <span
class="math inline">\(x = \{x_1,\dotsc,x_n\}\)</span> and decide to
model them by <span class="math inline">\(X_1, \dots, X_n
\overset{i.i.d}{\sim}\text{Ber}(p)\)</span>, where <span
class="math inline">\(p \in (0,1)\)</span>.</p>
<p>(1) Write down the likelihood function and find the MLE for <span
class="math inline">\(p\)</span>.</p>
<p>(2) Construct an asymptotic confidence interval for <span
class="math inline">\(p\)</span> at level <span
class="math inline">\(1-\alpha\)</span> using the value <span
class="math inline">\(\Phi^{-1}(1-\alpha/2)\)</span>, where <span
class="math inline">\(\Phi\)</span> is the CDF for <span
class="math inline">\(N(0,1)\)</span>, and justify your
construction.</p>
<p>(3) Suppose the actual data we observe is <span
class="math inline">\(x = \{1,0,1,1,1,0,0,1,0\}\)</span>. Write down an
asymptotic confidence interval for <span
class="math inline">\(p\)</span> at level <span
class="math inline">\(0.95\)</span> based on your answer to (2).</p>
</div>
<div id="exer:mleunif" class="exercise">
<p><em>Exercise 6.11</em>. Suppose <span class="math inline">\(X_1,
\dots, X_n \overset{i.i.d}{\sim}f(x;\theta)\)</span>, where <span
class="math display">\[f(x;\theta) = \frac{1}{\theta}, \; x \in [0,
\theta], \theta &gt;0.\]</span></p>
<p>(1) Write down the likelihood function. Show that the MLE for <span
class="math inline">\(\theta\)</span> is <span
class="math inline">\(\hat{\theta}_n= X_{(n)} = \max\{ X_1,\dotsc,
X_n\}\)</span>.</p>
<p>(2) Show that <span class="math display">\[n (\theta -
\hat{\theta}_n) \overset{d}{\longrightarrow}
\text{Exp}(1/\theta).\]</span> (This is in fact a purely probability
exercise, but it demonstrates the fact that not all MLEs are
asymptotically normal, i.e. some regularity conditions are required for
asymptotically normality of MLE to hold!).</p>
</div>
<h2 id="properties-of-mle">Properties of MLE</h2>
<h3
id="invariance---we-did-not-cover-this-in-the-lecture-so-this-subsection-on-invariance-is-not-examinable">Invariance
- we did not cover this in the lecture so this subsection on invariance
is <em>not examinable</em></h3>
<p>Now, suppose that we are interested in estimating a function of <span
class="math inline">\(\theta\)</span>, denoted by <span
class="math inline">\(\tau = g(\theta)\)</span>. If <span
class="math inline">\(g\)</span> is one-to-one (known as bijective),
then we can define the likelihood function for <span
class="math inline">\(\tau\)</span> by replacing <span
class="math inline">\(\theta\)</span> in <span
class="math inline">\(L(\theta;X)\)</span> by <span
class="math inline">\(g^{-1}(\theta)\)</span>: <span
class="math display">\[\tilde{L}(\tau; X) := L(g^{-1}(\tau);
X).\]</span></p>
<div id="thm:mle-invariance" class="theorem">
<p><strong>Theorem 6.12</strong> (Invariance of the MLE). <em>Let <span
class="math inline">\(X_1, X_2, \ldots, X_n
\overset{i.i.d}{\sim}f(x;\theta), \theta \in \Theta\)</span>. Let <span
class="math inline">\(\tau = g(\theta)\)</span> be a function of <span
class="math inline">\(\theta\)</span> such that <span
class="math inline">\(g^{-1}\)</span> exists, i.e. <span
class="math inline">\(g\)</span> is bijective. Then, if <span
class="math inline">\(\hat{\theta}_n\)</span> is the MLE for <span
class="math inline">\(\theta\)</span> then <span
class="math inline">\(g(\hat{\theta}_n)\)</span> is the MLE for <span
class="math inline">\(g(\theta)\)</span>.</em></p>
</div>
<div class="proof">
<p><em>Proof.</em> We need to show that if <span
class="math inline">\(\hat{\theta}_n\)</span> maximizes <span
class="math inline">\(L(\theta;X)\)</span>, then <span
class="math inline">\(g(\hat{\theta}_n)\)</span> maximizes <span
class="math inline">\(\tilde{L}(\tau; X)\)</span>. By the definition of
<span class="math inline">\(\tilde{L}(\tau; X)\)</span> and the
existence of <span class="math inline">\(g^{-1}\)</span>, we have <span
class="math display">\[\tilde{L}(g(\hat{\theta}_n); X) =
L(\hat{\theta}_n;X).\]</span> Hence for any other <span
class="math inline">\(\tau = g(\theta)\)</span>, <span
class="math display">\[\tilde{L}(\tau; X)  = L(\theta;X)
\leq  L(\hat{\theta}_n;X) =  \tilde{L}(g(\hat{\theta}_n); X),\]</span>
and therefore <span class="math inline">\(g(\hat{\theta}_n)\)</span> is
the MLE for <span class="math inline">\(g(\theta)\)</span>. ◻</p>
</div>
<p>In the case where <span class="math inline">\(g^{-1}\)</span> does
not exist (e.g. <span class="math inline">\(g(x) = x^2\)</span>), one
can modify the likelihood function for <span
class="math inline">\(\tau\)</span> but the conclusion of Theorem <a
href="#thm:mle-invariance" data-reference-type="ref"
data-reference="thm:mle-invariance">6.12</a> still holds. (See Theorem
7.2.10 in <span class="citation"
data-cites="casella2024statistical"></span>)</p>
<h3 id="asymptotic-properties">Asymptotic properties</h3>
<div id="thm:mleproperty" class="theorem">
<p><strong>Theorem 6.13</strong>. <em>Suppose <span
class="math inline">\(X_1, \dots, X_n \overset{\text{iid}}{\sim} f(x;
\theta)\)</span>, <span class="math inline">\(\theta \in \Theta
\subseteq \mathbb{R}\)</span>, and let <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> be the MLE
based on <span class="math inline">\(X = (X_1,\dotsc,X_n)\)</span>.
Assume certain regularity conditions hold, including<a href="#fn6"
class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a>:</em></p>
<ul>
<li><p><em><span class="math inline">\(\{x: f(x, \theta) &gt;
0\}\)</span> is the same for all <span class="math inline">\(\theta \in
\Theta\)</span>.</em></p></li>
<li><p><em>The log-likelihood function <span
class="math inline">\(l(\theta; X)\)</span> is differentiable in <span
class="math inline">\(\theta\)</span> and sufficiently
smooth.</em></p></li>
<li><p><em><span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> is the unique
stationary point of <span class="math inline">\(l(\theta;
X)\)</span>.</em></p></li>
</ul>
<p><em>Then the MLE <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> is consistent
and asymptotically unbiased. Moreover, <span
class="math display">\[\sqrt{n} (\hat{\theta}_{\text{MLE}} - \theta)
\overset{d}{\longrightarrow} N(0, I(\theta)^{-1}),\]</span> where <span
class="math display">\[I(\theta) = \mathrm{Var}
\mathopen{}\mathclose\bgroup\left[ \frac{\partial}{\partial \theta} \log
f(X_1; \theta) \aftergroup\egroup\right] = -\mathbb{E}
\mathopen{}\mathclose\bgroup\left[ \frac{\partial^2}{\partial \theta^2}
\log f(X_1, \theta) \aftergroup\egroup\right].\]</span></em></p>
</div>
<div class="remark">
<p><em>Remark 6.14</em>. </p>
<ul>
<li><p>The regularity conditions guarantee that the MLE exists and is
unique. They also exclude examples like <span
class="math inline">\(X_1\dotsc,X_n \overset{i.i.d}{\sim}\text{Unif}(0,
\theta), \theta &gt;0\)</span>, which violates asymptotic normality (See
Exercise <a href="#exer:mleunif" data-reference-type="ref"
data-reference="exer:mleunif">6.11</a>).</p></li>
<li><p>Since <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> is both
asymptotically normal and consistent, we can immediately write down an
asymptotic confidence interval for <span
class="math inline">\(\theta\)</span> as: <span
class="math display">\[\hat{\theta}_{{MLE}} \pm z_{1-\alpha / 2}
\sqrt{\frac{1}{n I(\hat{\theta}_{{MLE}})}},\]</span> assuming <span
class="math inline">\(I(\theta)\)</span> is continuous.</p></li>
<li><p>We call <span class="math display">\[S(\theta;X_1) :=
\frac{\partial}{\partial \theta} \log f(X_1;\theta), \qquad X_1 \sim
f(x; \theta)\]</span> the <strong>score function</strong>, and <span
class="math inline">\(I(\theta)\)</span>, the variance of the score, is
called the <strong>Fisher information</strong> (with sample size <span
class="math inline">\(1\)</span>) and sometimes written as <span
class="math inline">\(I_1(\theta)\)</span>. Under the i.i.d assumption,
we have <span class="math display">\[I_n(\theta) :=
\mathrm{Var}(\frac{\partial}{\partial \theta} l(\theta;X)) =
\sum_{i=1}^n\mathrm{Var}(S(\theta;X_i)) = nI(\theta).\]</span></p></li>
</ul>
</div>
<div id="lemma:score" class="lemma">
<p><strong>Lemma 6.15</strong>. <em>For any <span
class="math inline">\(\theta \in \Theta\)</span>, suppose <span
class="math inline">\(X \sim  f(x;\theta)\)</span>, assume sufficient
strong conditions on <span class="math inline">\(f(x,\theta)\)</span>
such that we can interchange integration and differentiation, then <span
class="math display">\[\mathbb{E}[ S(\theta,X)] = 0, \qquad
\mathrm{Var}(S(\theta,X)) = - \mathbb{E}\Big[\frac{\partial}{\partial
\theta} S(\theta,X)\Big]\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> We only prove the expectation statement, the variance
part is left as an exercise. Note that <span
class="math display">\[\mathbb{E}[ S(\theta,X)] =
\mathbb{E}\Big[\frac{\partial}{\partial \theta} \log f(X;\theta)\Big] =
= \mathbb{E}\Big[\frac{\frac{\partial}{\partial
\theta}f(X;\theta)}{f(X;\theta)} \Big] = \int
\frac{\frac{\partial}{\partial \theta}f(x;\theta)}{f(x;\theta)}
f(x;\theta) dx = \frac{\partial}{\partial \theta} \int f(x;\theta) dx =
0.\]</span> ◻</p>
</div>
<div id="ex:berI(p)" class="example">
<p><em>Example 6.16</em>. Suppose that <span class="math inline">\(X_1,
\dots, X_n \overset{\text{iid}}{\sim} \text{Ber}(p), p \in
(0,1).\)</span> We know from Exercise <a href="#exer-bermle"
data-reference-type="ref" data-reference="exer-bermle">6.10</a>, the MLE
for <span class="math inline">\(p\)</span> is <span
class="math display">\[\hat{p}_{\text{MLE}} = \overline{X}_n.\]</span>
By central limit theorem, we have <span class="math display">\[\sqrt{n}
(\overline{X}_n - p) \overset{d}{\longrightarrow} N(0, p(1-p)).\]</span>
Alternatively, we can obtain the same result using asymptotic normality
of MLE by computing <span class="math inline">\(I(p)\)</span>. Note that
for Bernoulli random variable we have <span
class="math display">\[f(X_1; p) = p^{X_1}(1-p)^{1-X_1}.\]</span> To
find <span class="math inline">\(I(p)\)</span>, we first compute <span
class="math display">\[\frac{\partial}{\partial p} \log f(X_1; p) =
\frac{X_1}{p} - \frac{1-X_1}{1-p},\]</span> then we have <span
class="math display">\[I(p) = \text{Var}\Big(\frac{\partial}{\partial
\theta} \log f(X_1; \theta)\Big) = \text{Var}\Big(\frac{X_1}{p} -
\frac{1-X_1}{1-p}\Big) = \text{Var}(\frac{X_1-p}{p(1-p)}) =
\frac{1}{p(1-p)}\]</span> Hence, by Theorem <a href="#thm:mleproperty"
data-reference-type="ref" data-reference="thm:mleproperty">6.13</a>
<span class="math display">\[\sqrt{n} (\overline{X}_n - p)
\overset{d}{\longrightarrow} N(0, p(1-p)).\]</span></p>
</div>
<div class="proof">
<p><em>Proof sketch for Theorem <a href="#thm:mleproperty"
data-reference-type="ref"
data-reference="thm:mleproperty">6.13</a>.</em> We only sketch the proof
for asymptotic normality. Denote <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> by <span
class="math inline">\(\hat{\theta}\)</span> for notation simplicity and
we write <span class="math inline">\(\theta_0\)</span> for the true
parameter, i.e. <span class="math inline">\(X_1\dotsc,X_n
\overset{i.i.d}{\sim}f(x,\theta_0), \theta_0 \in \Theta\)</span>. Note
that the log-likelihood function is still <span
class="math inline">\(l(\theta) = \sum_{i=1}^n\log
f(X_i;\theta)\)</span>. We also write <span
class="math inline">\(l&#39;(\theta)\)</span> for <span
class="math inline">\(\frac{\partial l(\theta)}{\partial
\theta}\)</span>, <span
class="math inline">\(l&#39;&#39;(\theta)\)</span> for <span
class="math inline">\(\frac{\partial^2 l(\theta)}{\partial
\theta^2}\)</span> and so on. Note that <span
class="math inline">\(l&#39;(\hat{\theta}) = 0\)</span>.</p>
<p>Using a Taylor expansion of <span
class="math inline">\(l&#39;(\theta)\)</span> around <span
class="math inline">\(\theta_0\)</span>, specifically Lagrange form of
the remainder, we have: <span class="math display">\[l&#39;(\theta) =
l&#39;(\theta_0) + (\theta - \theta_0) l&#39;&#39;(\theta_0) +
\frac{(\theta - \theta_0)^2}{2}
l&#39;&#39;&#39;(\tilde{\theta}),\]</span> where <span
class="math inline">\(\tilde{\theta} \in [\theta, \theta_0]\)</span>.
Evaluate <span class="math inline">\(l&#39;(\theta)\)</span> at <span
class="math inline">\(\theta = \hat{\theta}\)</span>: <span
class="math display">\[0 = l&#39;(\theta_0) + (\hat{\theta} - \theta_0)
l&#39;&#39;(\theta_0) + \frac{(\hat{\theta} - \theta_0)^2}{2}
l&#39;&#39;&#39;(\tilde{\theta}),\]</span> which is equivalent to <span
class="math display">\[\sqrt{n}(\hat{\theta} - \theta_0)
=  -\frac{\sqrt{n} l&#39;(\theta_0)}{l&#39;&#39;(\theta_0) +
\frac{1}{2}(\hat{\theta} - \theta_0)l&#39;&#39;&#39;(\tilde{\theta})} =
-\frac{\sqrt{n}\cdot\frac{1}{n}
l&#39;(\theta_0)}{\frac{1}{n}l&#39;&#39;(\theta_0) +
\frac{1}{2}(\hat{\theta} -
\theta_0)l&#39;&#39;&#39;(\tilde{\theta})/n}\]</span> Recall that <span
class="math display">\[l&#39;(\theta) = \sum_{i=1}^n
\frac{\partial}{\partial \theta} \log f(\theta; X_i) = \sum_{i=1}^n
S(\theta;X_i),\]</span> and <span
class="math inline">\(l&#39;(\theta_0)\)</span> means that we evaluate
the function of <span class="math inline">\(l&#39;(\theta)\)</span> at
<span class="math inline">\(\theta = \theta_0\)</span> so that we have
<span class="math inline">\(l&#39;(\theta_0) = \sum_{i=1}^n
S(\theta_0;X_i)\)</span>. since <span class="math inline">\(X_i
\overset{i.i.d}{\sim}f(x,\theta_0)\)</span>, by Lemma <a
href="#lemma:score" data-reference-type="ref"
data-reference="lemma:score">6.15</a>, we have <span
class="math inline">\(\mathbb{E}(S(\theta_0;X_i)) = 0\)</span> and <span
class="math inline">\(\text{Var}(S(\theta_0;X_i)) =
I(\theta_0)\)</span>. Therefore, by CLT, we have <span
class="math display">\[\sqrt{n}\cdot\frac{1}{n} l&#39;(\theta_0)
\overset{d}{\longrightarrow} N(0, I(\theta_0)).\]</span> Similarly,
<span class="math display">\[\frac{1}{n}l&#39;&#39;(\theta) =\frac{1}{n}
\sum_{i=1}^n \frac{\partial^2}{\partial \theta^2} \log f(\theta; X_i) =
\frac{1}{n}\sum_{i=1}^n \frac{\partial}{\partial \theta} S(\theta,X_1)
\overset{a.s.}{\longrightarrow} \mathbb{E}\Big[\frac{\partial}{\partial
\theta} S(\theta,X_1)\Big],\]</span> since <span
class="math inline">\(X_1 \sim f(x,\theta_0)\)</span>, <span
class="math inline">\(\frac{1}{n}l&#39;&#39;(\theta_0)
\overset{a.s.}{\longrightarrow}\mathbb{E}\Big[\frac{\partial}{\partial
\theta} S(\theta_0,X_1)\Big] = -I(\theta_0)\)</span>.</p>
<p>Finally, we will assume it holds that the term <span
class="math display">\[\frac{1}{2}(\hat{\theta} -
\theta_0)l&#39;&#39;&#39;(\tilde{\theta})/n
\overset{\mathbb{P}}{\longrightarrow} 0,\]</span> which can be shown
using more involved arguments<a href="#fn7" class="footnote-ref"
id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>Together, we can apply Slutsky’s Theorem to conclude <span
class="math display">\[\sqrt{n}(\hat{\theta} - \theta_0)
\overset{d}{\longrightarrow} N\Big(0,
\frac{1}{I(\theta_0)}\Big).\]</span> ◻</p>
</div>
<div class="theorem">
<p><strong>Theorem 6.17</strong> (Multivariate version). <em>Suppose
<span class="math inline">\(X_1, \dots, X_n \overset{\text{iid}}{\sim}
f(x; \theta)\)</span>, <span class="math inline">\(\theta \in \Theta
\subseteq \mathbb{R}^d\)</span>, and let <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> be the MLE
based on <span class="math inline">\(X_1,\dotsc,X_n\)</span>. Define the
Fisher Information matrix <span class="math inline">\(I(\theta) \in
\mathbb{R}^{d \times d}\)</span> to be the covariance matrix of <span
class="math inline">\(\nabla_{\theta} \log f(X_1,\theta)\)</span>, i.e.
<span class="math display">\[I(\theta)_{i,j} =
\mathrm{Cov}\Big[\frac{\partial}{\partial \theta_i}\log f(X_1; \theta),
\frac{\partial}{\partial \theta_j}\log f(X_1; \theta)\Big] =
-\mathbb{E}\Big[\frac{\partial^2}{\partial \theta_i\theta_j}\log
f(X_1;\theta)\Big].\]</span> Assume the same regularity conditions hold
as in Theorem <a href="#thm:mleproperty" data-reference-type="ref"
data-reference="thm:mleproperty">6.13</a>, then the MLE <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> is consistent
and asymptotically unbiased. Moreover, <span
class="math display">\[\sqrt{n} (\hat{\theta}_{\text{MLE}} - \theta)
\overset{d}{\longrightarrow} N(0, I(\theta)^{-1}).\]</span></em></p>
</div>
<p>Note that we again have <span class="math display">\[I_n(\theta) :=
\mathrm{Var}(\nabla_{\theta} l(\theta;X)) =
\sum_{i=1}^n\mathrm{Var}(\nabla_{\theta} \log f(X_i,\theta)) =
nI(\theta).\]</span> due to the i.i.d assumption.</p>
<div class="example">
<p><em>Example 6.18</em>. Recall the setup of Example <a
href="#example-gaussian-meanvariance" data-reference-type="ref"
data-reference="example-gaussian-meanvariance">6.8</a>, where we have
<span class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim}f(x;
\theta)\)</span>, with <span class="math inline">\(\theta  = (\mu,
\sigma)\)</span> and <span class="math display">\[f(x;\mu, \sigma) =
\frac{1}{\sqrt{2\pi}\sigma}\exp(-(x-\mu)^2/(2\sigma^2)), \; x \in
\mathbb{R}, \mu \in \mathbb{R}, \sigma &gt; 0.\]</span> We consider the
case where both <span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\sigma\)</span> are unknown. See the solution for
Week 9 exercises where we obtain <span
class="math display">\[\frac{\partial^2 l}{\partial \mu^2} =
-\frac{n}{\sigma^2}, \quad
\frac{\partial^2 l}{\partial (\sigma)^2} = \frac{n}{\sigma^2} -
\frac{3}{\sigma^4} \sum_{i=1}^n (X_i - \mu)^2, \quad \frac{\partial^2
l}{\partial \mu \partial \sigma} = \frac{\partial^2 l}{\partial \sigma
\partial \mu} = -\frac{2}{\sigma^3} \sum_{i=1}^n (X_i - \mu).\]</span>
Taking expectation for each term, we have <span
class="math display">\[\mathbb{E}(\frac{\partial^2 l}{\partial \mu^2}) =
-\frac{n}{\sigma^2}, \quad \mathbb{E}(\frac{\partial^2 l}{\partial
(\sigma)^2}) = -\frac{2n}{\sigma^2}, \quad \mathbb{E}(\frac{\partial^2
l}{\partial \mu \partial \sigma}) = 0\]</span> Therefore, the Fisher
information matrix with sample size <span
class="math inline">\(n\)</span> is <span
class="math display">\[I_n(\theta) = \begin{pmatrix}
    \frac{n}{\sigma^2} &amp; 0 \\ 0 &amp; \frac{2n}{\sigma^2},
\end{pmatrix}\]</span> and <span class="math display">\[I(\theta) =
\frac{1}{n}I_n(\theta) = \begin{pmatrix}
    \frac{1}{\sigma^2} &amp; 0 \\ 0 &amp; \frac{2}{\sigma^2}
\end{pmatrix}.\]</span></p>
</div>
<div class="exercise">
<p><em>Exercise 6.19</em>. Suppose that <span class="math inline">\(Y_i
= x_i^{\top}\beta + \varepsilon_i, i = 1,\dotsc,n\)</span>, where <span
class="math inline">\(\varepsilon_i \overset{i.i.d}{\sim}N(0,
\sigma^2)\)</span> with known <span class="math inline">\(\sigma &gt;
0\)</span>, and <span class="math inline">\(x_i \in
\mathbb{R}^d\)</span> is assumed to be known and
fixed/deterministic/non-random. Recall that the log-likelihood function
is <span class="math display">\[l(\beta; Y, x) = -n\log(\sqrt{2\pi}
\sigma) - \frac{1}{2\sigma^2}\sum_{i=1}^n(Y_i -
x_i^{\top}\beta)^2.\]</span> Find the Fisher information matrix <span
class="math inline">\(I(\beta) \in \mathbb{R}^{d\times d}\)</span>.</p>
</div>
<p>Now that we have discussed asymptotic properties of MLE. It is
natural to wonder how does it compare to other potential estimators? The
following result known as the Cramér-Rao lower bound shows that MLE
achieves the smallest variance among all unbiased estimators,
asymptotically.</p>
<div class="theorem">
<p><strong>Theorem 6.20</strong> (Cramér-Rao lower bound). <em>Let <span
class="math inline">\(X_1,\dotsc,X_n \overset{i.i.d}{\sim}f(x;\theta),
\theta \in \Theta \subseteq \mathbb{R}\)</span>, under certain
regularity conditions, for any unbiased estimator <span
class="math inline">\(T(X)\)</span> for <span
class="math inline">\(\theta\)</span>, based on <span
class="math inline">\(X = (X_1,\dotsc,X_n)\)</span>, it holds that <span
class="math display">\[\mathrm{Var}(T(X)) \geq
\frac{1}{nI(\theta)}.\]</span></em></p>
</div>
<div class="remark">
<p><em>Remark 6.21</em>. </p>
<ul>
<li><p>We say an unbiased estimator based on <span
class="math inline">\(X_1,\dotsc,X_n\)</span> is <em>efficient</em> if
its variance equals the lower bound <span
class="math inline">\(\frac{1}{nI(\theta)}\)</span>, for any <span
class="math inline">\(\theta \in \Theta\)</span>. However, as this is a
non-asymptotic notion, finding efficient estimators can be difficult in
general.</p></li>
<li><p>We can equivalently write the statement as, for any unbiased
estimator <span class="math inline">\(T(X)\)</span> <span
class="math display">\[\mathrm{Var}[\sqrt{n}(T(X) - \theta)] \geq
\frac{1}{I(\theta)}.\]</span> Now, compare to the asymptotic normality
of MLE in Theorem <a href="#thm:mleproperty" data-reference-type="ref"
data-reference="thm:mleproperty">6.13</a> <span
class="math display">\[\sqrt{n} (\hat{\theta}_{\text{MLE}} - \theta)
\overset{d}{\longrightarrow} N\Big(0, \frac{1}{I(\theta)}\Big),\]</span>
we observe that in the limit, MLE achieves the Cramér-Rao lowerbound,
which is the smallest possible variance among all unbiased estimators.
Therefore, MLE is said to be <em>asymptotically efficient</em>.</p></li>
<li><p>Recall that given the asymptotically normality of MLE, we always
have an asymptotic CI for <span class="math inline">\(\theta\)</span> as
<span class="math display">\[\hat{\theta}_{\text{MLE}} \pm
z_{1-\alpha/2} \frac{1}{\sqrt{nI(\hat{\theta}_{\text{MLE}})}},\]</span>
which has length <span
class="math display">\[\frac{2z_{1-\alpha/2}}{\sqrt{nI(\hat{\theta}_{\text{MLE}})}}
\overset{\mathbb{P}}{\longrightarrow}
\frac{2z_{1-\alpha/2}}{\sqrt{nI(\theta)}},\]</span> by consistency of
MLE and continuous mapping theorem. Therefore, we should expect CI based
on MLE to have the shortest length asymptotically, among all CIs based
on asymptotically unbiased estimators.</p></li>
</ul>
</div>
<h3 id="plug-in-estimators-and-delta-method">Plug-in estimators and
delta method</h3>
<div class="theorem">
<p><strong>Theorem 6.22</strong> (Delta method. This is a restatement of
Theorem <a href="#thm:delta" data-reference-type="ref"
data-reference="thm:delta">4.19</a> for the purpose of inference).
<em>Let <span class="math inline">\(X_1, \ldots, X_n
\overset{\text{i.i.d.}}{\sim} f(x, \theta)\)</span>, <span
class="math inline">\(\theta \in \Theta \subseteq \mathbb{R}\)</span>.
Suppose <span class="math display">\[\sqrt{n}
\mathopen{}\mathclose\bgroup\left( \hat{\theta}_n(X) - \theta
\aftergroup\egroup\right) \overset{d}{\longrightarrow} N(0,
\sigma^2)\]</span> for some <span class="math inline">\(\sigma &gt;
0\)</span>. Then, let <span class="math inline">\(g : \mathbb{R} \to
\mathbb{R}\)</span> be a function that is differentiable at <span
class="math inline">\(\theta\)</span>, with <span
class="math inline">\(g&#39;(\theta) \neq 0\)</span>. Then <span
class="math display">\[\sqrt{n} \mathopen{}\mathclose\bgroup\left(
g\mathopen{}\mathclose\bgroup\left(\hat{\theta}_n(X)\aftergroup\egroup\right)
- g(\theta) \aftergroup\egroup\right) \overset{d}{\longrightarrow}
N\mathopen{}\mathclose\bgroup\left(0,
\mathopen{}\mathclose\bgroup\left(g&#39;(\theta)\aftergroup\egroup\right)^2
\sigma^2\aftergroup\egroup\right).\]</span></em></p>
</div>
<div class="example">
<p><em>Example 6.23</em>. Let <span class="math inline">\(X_1, \ldots,
X_n \overset{\text{i.i.d.}}{\sim} \text{Ber}(p)\)</span>, <span
class="math inline">\(p \in (0, 1)\)</span>. Recall from Exercise <a
href="#exer-bermle" data-reference-type="ref"
data-reference="exer-bermle">6.10</a>, the MLE for <span
class="math inline">\(p\)</span> is <span class="math inline">\(\hat{p}
= \bar{X}_n\)</span>, and <span class="math display">\[\sqrt{n}
\mathopen{}\mathclose\bgroup\left(\hat{p} - p\aftergroup\egroup\right)
\overset{d}{\longrightarrow} N(0, p(1-p)),\]</span> by either the CLT or
by computing the Fisher information <span class="math inline">\(I(p) =
\frac{1}{p(1-p)}\)</span> (See Example <a href="#ex:berI(p)"
data-reference-type="ref" data-reference="ex:berI(p)">6.16</a>).</p>
<p>Now, suppose we want to estimate the log-odds <span
class="math display">\[g(p) = \log \frac{p}{1-p}.\]</span> The
derivative of <span class="math inline">\(g(p)\)</span> is <span
class="math display">\[g&#39;(p) = \frac{\partial}{\partial p}
\mathopen{}\mathclose\bgroup\left( \log p - \log(1-p)
\aftergroup\egroup\right) = \frac{1}{p} + \frac{1}{1-p} =
\frac{1}{p(1-p)} \neq 0.\]</span> Therefore, using the plug-in estimator
<span class="math inline">\(g(\hat{p})\)</span> and applying the delta
method, we obtain <span class="math display">\[\sqrt{n}
\mathopen{}\mathclose\bgroup\left( \log \frac{\hat{p}}{1-\hat{p}} - g(p)
\aftergroup\egroup\right) \overset{d}{\longrightarrow}
N\mathopen{}\mathclose\bgroup\left(0,
\frac{1}{p(1-p)}\aftergroup\egroup\right).\]</span></p>
<p>Since <span class="math inline">\(\hat{p}
\overset{\mathbb{P}}{\longrightarrow} p\)</span> by the SLLN (also the
fact that almost sure convergence implies convergce in probability),
then <span class="math display">\[\log \frac{\hat{p}}{1-\hat{p}} \pm
z_{1-\alpha/2} \frac{1}{\sqrt{n \hat{p}(1-\hat{p})}}\]</span> is an
asymptotic confidence interval (CI) for <span
class="math inline">\(g(p)\)</span> at level <span
class="math inline">\(1-\alpha\)</span>.</p>
</div>
<div class="theorem">
<p><strong>Theorem 6.24</strong>. <em>Suppose <span
class="math inline">\(X_1, \ldots, X_n \overset{\text{i.i.d.}}{\sim}
f(x; \theta)\)</span>, <span class="math inline">\(\theta \in \Theta
\subseteq \mathbb{R}\)</span>. Let <span
class="math inline">\(g\)</span> be any function differentiable on <span
class="math inline">\(\Theta\)</span>, and let <span
class="math inline">\(T\)</span> be any unbiased estimator for <span
class="math inline">\(g(\theta)\)</span> based on <span
class="math inline">\(X = (X_1, \ldots, X_n)\)</span>. Then <span
class="math display">\[\mathrm{Var}(T(X)) \geq
\frac{\mathopen{}\mathclose\bgroup\left(g&#39;(\theta)\aftergroup\egroup\right)^2}{n
I(\theta)}.\]</span></em></p>
</div>
<h2 id="beyond-mle">Beyond MLE</h2>
<p>It may appear that maximum likelihood estimation has largely ‘solved’
the essential problem of learning from data that statistics is concerned
with. Notably, MLEs enjoy a form of optimality in the form of asymptotic
efficiency. What are some of its limitations that motivates statistical
methodology beyond MLE?</p>
<p>In fact, there are many limitations. In particular, the assumption
that we can always "correctly" pick a statistical model is quite
unrealistic. As famously said by George E. P. Box, an eminent British
statistician, “all models are wrong, but some are useful”. It would
therefore make sense to consider the issue of model misspecification,
e.g., <span class="math inline">\(X_1, \ldots, X_n
\overset{i.i.d}{\sim}\text{Exp}(\theta)\)</span>. but we treated them as
<span class="math inline">\(X_1, \ldots, X_n \overset{i.i.d}{\sim}N(\mu,
\sigma^2)\)</span>.</p>
<p>Recall that we can view MLE as maximizing some objective function,
and the objective function that we choose is the likelihood function. In
the case that we are not confident about our choice of statistical
model, we may pick a different objective function, perhaps motivated by
some characteristics that we observed in the data. Specifically, we may
consider a slightly general form of obtaining estimators via optimising
some objective function <span
class="math inline">\(M(\theta;X)\)</span>. Given <span
class="math inline">\(X = (X_1, \ldots, X_n)\)</span>, <span
class="math inline">\(X_1, \ldots, X_n \overset{i.i.d}{\sim}f(x;
\theta), \theta \in \Theta\)</span>, consider <span
class="math display">\[\label{eq:M-estimator}
    \hat{\theta}(X) := \arg \max_{\theta \in \Theta} M(\theta;
X)\]</span> where <span class="math display">\[M(\theta; X)
:=  \sum_{i=1}^n m(\theta; X_i).\]</span> Note that if <span
class="math inline">\(m(\theta; X_i) = \log f(X_i; \theta)\)</span> and
, then <span class="math inline">\(\hat{\theta}(X) =
\hat{\theta}_{{MLE}}(X).\)</span> The estimator defined by <a
href="#eq:M-estimator" data-reference-type="eqref"
data-reference="eq:M-estimator">[eq:M-estimator]</a> is known as
M-estimators, and in the case <span class="math inline">\(\Theta
\subseteq \mathbb{R}\)</span>, it can be shown <span class="citation"
data-cites="van2000asymptotic"></span> under some regularity conditions
that <span class="math display">\[\sqrt{n}
\mathopen{}\mathclose\bgroup\left( \hat{\theta}(X) - \theta
\aftergroup\egroup\right) \overset{d}{\longrightarrow} N
\mathopen{}\mathclose\bgroup\left( 0,
\frac{\mathbb{E}\mathopen{}\mathclose\bgroup\left[
\mathopen{}\mathclose\bgroup\left( \frac{\partial}{\partial \theta}
m(\theta; X_1) \aftergroup\egroup\right)^2
\aftergroup\egroup\right]}{\mathopen{}\mathclose\bgroup\left( \mathbb{E}
\mathopen{}\mathclose\bgroup\left[ \frac{\partial^2}{\partial \theta^2}
m(\theta; X_1) \aftergroup\egroup\right] \aftergroup\egroup\right)^2}
\aftergroup\egroup\right).\]</span> Note that when <span
class="math inline">\(m(\theta; X_1) = \log f(X_1; \theta)\)</span>,
<span
class="math display">\[\frac{\mathbb{E}\mathopen{}\mathclose\bgroup\left[
\mathopen{}\mathclose\bgroup\left( \frac{\partial}{\partial \theta}
m(\theta; X_1) \aftergroup\egroup\right)^2
\aftergroup\egroup\right]}{\mathopen{}\mathclose\bgroup\left( \mathbb{E}
\mathopen{}\mathclose\bgroup\left[ \frac{\partial^2}{\partial \theta^2}
m(\theta; X_1) \aftergroup\egroup\right] \aftergroup\egroup\right)^2} =
\frac{I(\theta)}{(I(\theta))^2} = \frac{1}{I(\theta)},\]</span> that is
if we manage to use the true log-likelihood function as the objective
function, then we recover the Cramér-Rao lower bound. Choosing <span
class="math inline">\(m(\theta;X)\)</span> that is different from <span
class="math inline">\(\log f(X; \theta)\)</span> usually leads to a loss
of efficiency but such a loss is usually compensated by some other
benefits.</p>
<div class="example">
<p><em>Example 6.25</em>. Let <span class="math inline">\(X_1, \ldots,
X_n \overset{\text{i.i.d.}}{\sim} N(\theta, 1)\)</span>, <span
class="math inline">\(\theta \in \mathbb{R}\)</span>. The MLE for <span
class="math inline">\(\theta\)</span> is given by (Check this yourself!)
<span class="math display">\[\hat{\theta}_{\text{MLE}} = \arg
\min_{\theta \in \mathbb{R}}  \sum_{i=1}^n (X_i - \theta)^2 =
\bar{X}_n.\]</span> If we use <span class="math inline">\(m(\theta, X_i)
= |X_i - \theta|\)</span> instead, then <span
class="math display">\[\hat{\theta} = \arg \min_{\theta \in \mathbb{R}}
\sum_{i=1}^n |X_i - \theta| = \text{median}\{X_1, \ldots,
X_n\}.\]</span> The median estimator <span
class="math inline">\(\hat{\theta}\)</span> is not as efficient as <span
class="math inline">\(\hat{\theta}_{\text{MLE}}\)</span> if the data are
indeed generated from <span class="math inline">\(N(\theta,1)\)</span>,
but it has the benefit of being robust to outliers within the data.
Therefore, it can be imagined that <span
class="math inline">\(\hat{\theta}\)</span> is much more “efficient"
when the data are not normally distributed but follow a heavy-tailed
distribution.</p>
</div>
<div class="example">
<p><em>Example 6.26</em>. In the regression setting, we discussed in
Exercise <a href="#exer:regression" data-reference-type="ref"
data-reference="exer:regression">6.4</a> that both MLE and ordinary
least square lead to the estimator <span
class="math display">\[\hat{\beta}_{\text{MLE}} = \arg \min_{\beta \in
\mathbb{R}^d}  \sum_{i=1}^n (Y_i - x_i^\top \beta)^2,\]</span> which can
be solved as <span class="math display">\[\hat{\beta}_{\text{MLE}} =
\mathopen{}\mathclose\bgroup\left(  \sum_{i=1}^n x_i x_i^\top
\aftergroup\egroup\right)^{-1}
\mathopen{}\mathclose\bgroup\left(  \sum_{i=1}^n x_i Y_i
\aftergroup\egroup\right),\]</span> or equivalently, <span
class="math display">\[\hat{\beta}_{\text{MLE}} = (X^\top X)^{-1} X^\top
Y,\]</span> if we rewrite <span class="math inline">\(X =
\begin{pmatrix} x_1^\top \\ \vdots \\ x_n^\top \end{pmatrix} \in
\mathbb{R}^{n \times d}\)</span> and <span class="math inline">\(Y =
\begin{pmatrix} Y_1 \\ \vdots \\ Y_n \end{pmatrix} \in
\mathbb{R}^n\)</span>. For robustness, we can again consider <span
class="math display">\[\hat{\beta} = \arg \min_{\beta \in \mathbb{R}^d}
\sum_{i=1}^n \mathopen{}\mathclose\bgroup\left| Y_i - x_i^\top \beta
\aftergroup\egroup\right|.\]</span> Another significant limitation of
MLE in regression problems is that <span
class="math inline">\(\hat{\beta}_{\text{MLE}}\)</span> only exists when
<span class="math inline">\(d &lt; n\)</span>. In modern data sets, such
high dimensional data sets are very common. It turns out that if we
instead use <span class="math display">\[\hat{\beta}_{\text{lasso}} =
\arg \min_{\beta \in \mathbb{R}^d}\Big\{ \sum_{i=1}^n
\mathopen{}\mathclose\bgroup\left(Y_i - x_i^\top \beta
\aftergroup\egroup\right)^2 + \lambda \|\beta\|_1\Big\},\]</span> where
<span class="math inline">\(\|\beta\|_1 = \sum_{j=1}^d
|\beta_j|\)</span>. Then <span
class="math inline">\(\hat{\beta}_{\text{lasso}}\)</span> is still
well-defined, even if <span class="math inline">\(d \gg n\)</span>. This
estimator is called the Least Absolute Shrinkage and Selection Operator
(LASSO), and was proposed in <span class="citation"
data-cites="tibshirani1996regression"></span>, which becomes the central
object in high-dimensional statistics.</p>
</div>
<h1 id="chap:app">Technical Appendix</h1>
<div class="proof">
<p><em>Proof of Lemma <a href="#lem:meas_cont" data-reference-type="ref"
data-reference="lem:meas_cont">1.14</a>.</em></p>
<ol>
<li><p>Let <span class="math inline">\((B_n)_{n\in \mathbb{N}}\)</span>
be defined by <span class="math display">\[\begin{aligned}
B_1 &amp;= A_1\\
B_2 &amp;= A_2\setminus A_1\\
&amp;\vdots\\
B_n &amp;= A_n \setminus (A_1 \cup \cdots \cup A_{n-1}).
\end{aligned}\]</span> Clearly, this sequence is pairwise disjoint.
Moreover, observe that <span class="math display">\[A_{n+1} =
\Big(A_{n+1} \setminus \bigcup_{k=1}^n A_k\Big) \cup \bigcup_{k=1}^n A_k
= B_{n+1} \cup \bigcup_{k=1}^n A_k,\]</span> since <span
class="math inline">\((A_n)_n\)</span> is increasing. It therefore
follows easily by induction that for any <span class="math inline">\(n
\in \mathbb{N}\)</span>, <span class="math inline">\(\bigcup_{k=1}^n A_k
= \bigcup_{k=1}^n B_k\)</span> and therefore also <span
class="math inline">\(\bigcup_{n=1}^\infty A_n = \bigcup_{n=1}^\infty
B_n\)</span>. Consequently, using disjointness and <span
class="math inline">\(\sigma\)</span>-additivity, we have <span
class="math display">\[\begin{aligned}
\mu\Big(\bigcup_{n \in \mathbb{N}} A_n \Big) = \mu\Big(\bigcup_{n \in
\mathbb{N}} B_n \Big) &amp;= \sum_{n \in \mathbb{N}} \mu(B_n) \\
&amp;= \lim_{n \to \infty} \sum_{k=1}^n \mu(B_k)\\
&amp;= \lim_{n \to \infty} \mu\Big(\bigcup_{k=1}^n B_k \Big)\\
&amp;= \lim_{n \to \infty} \mu\Big(\bigcup_{k=1}^n A_k \Big)\\
&amp;= \lim_{n \to \infty} \mu(A_n),
\end{aligned}\]</span> where the last line follows from the assumption
that <span class="math inline">\((A_n)_n\)</span> is
increasing.</p></li>
<li><p>Since <span class="math inline">\(A_{n+1} \supset A_n\)</span> we
have <span class="math inline">\(A_1 \setminus A_n \subset A_1 \setminus
A_{n+1}\)</span>. Thus, the sequence <span class="math inline">\((A_1
\setminus A_n)_n\)</span> is increasing and (i) yields <span
class="math display">\[\mu\Big(A_1 \setminus \bigcap_{n \in \mathbb{N}}
A_n\Big) = \mu\Big(\bigcup_{n \in \mathbb{N}} (A_1 \setminus A_n) \Big)
= \lim_{n \to \infty} \mu(A_1 \setminus A_n) = \lim_{n \to \infty}
(\mu(A_1) - \mu(A_n)) = \mu(A_1) - \lim_{n \to \infty}
\mu(A_n),\]</span> where we used the assumption <span
class="math inline">\(\mu(A_1) &lt; \infty\)</span> for the third
equality. The statement now follows from <span
class="math inline">\(\mu\Big(\Big(\bigcap_{n \in \mathbb{N}}
A_n\Big)^{\mathrm{c}} \Big) = 1- \mu\Big(\bigcap_{n \in \mathbb{N}} A_n
\Big)\)</span>.</p></li>
</ol>
<p> ◻</p>
</div>
<div class="proof">
<p><em>Proof of Proposition <a href="#prop:meas_gen"
data-reference-type="ref" data-reference="prop:meas_gen">2.2</a>.</em>
If <span class="math inline">\(f\)</span> is measurable, then since
<span class="math inline">\(\mathcal{E} \subset \sigma(\mathcal{E}) =
\mathcal{B}(\mathbb{R})\)</span> it holds that <span
class="math inline">\(f^{-1}(\mathcal{E}) \subset
\mathcal{B}(\mathbb{R})\)</span>. Conversely, suppose that <span
class="math inline">\(f^{-1}(\mathcal{E}) \subset
\mathcal{B}(\mathbb{R})\)</span>. Consider the family of sets <span
class="math display">\[\mathcal{C} \coloneq\Big\{B \in
\mathcal{B}(\mathbb{R}): f^{-1}(B) \in \mathcal{A} \Big\}.\]</span> We
claim that <span class="math inline">\(\mathcal{C}\)</span> is a <span
class="math inline">\(\sigma\)</span>-algebra over <span
class="math inline">\(\mathbb{R}\)</span>. Indeed,</p>
<ol>
<li><p><span class="math inline">\(\mathbb{R}\in \mathcal{C}\)</span>
since <span class="math inline">\(f^{-1}(\mathbb{R}) = E \in
\mathcal{A}\)</span>;</p></li>
<li><p>if <span class="math inline">\(B \in \mathcal{C}\)</span> then
<span class="math display">\[f^{-1}(B^{\mathrm{c}}) = f^{-1}(\mathbb{R})
\setminus f^{-1}(B) = \mathbb{R}\setminus \underbrace{f^{-1}(B)}_{\in
\mathcal{A}} \in \mathcal{A},\]</span> since the <span
class="math inline">\(\sigma\)</span>-algebra <span
class="math inline">\(\mathcal{A}\)</span> is closed under taking
complements. It follows that <span class="math inline">\(B^{\mathrm{c}}
\in \mathcal{C}\)</span> as well;</p></li>
<li><p>for a sequence <span class="math inline">\((B_n)_{n \in
\mathbb{N}} \subset \mathcal{C}\)</span> we have <span
class="math display">\[f^{-1}\Big(\bigcup_{n \in \mathbb{N}} B_n \Big) =
\bigcup_{n \in \mathbb{N}} \underbrace{f^{-1}(B_n)}_{\in \mathcal{A}}
\in \mathcal{A},\]</span> where the inclusion follows from <span
class="math inline">\(\sigma\)</span>-stability of a <span
class="math inline">\(\sigma\)</span>-algebra. Therefore, <span
class="math inline">\(\bigcup_n B_n \in \mathcal{C}\)</span>.</p></li>
</ol>
<p>We have shown that <span class="math inline">\(\mathcal{C}\)</span>
is a <span class="math inline">\(\sigma\)</span>-algebra and by
definition of <span class="math inline">\(\mathcal{C}\)</span> we have
<span class="math inline">\(\mathcal{E} \subset \mathcal{C}\)</span>.
Since <span class="math inline">\(\sigma(\mathcal{E})\)</span> is the
smallest <span class="math inline">\(\sigma\)</span>-algebra containing
<span class="math inline">\(\mathcal{E}\)</span>, this entails <span
class="math inline">\(\mathcal{B}(\mathbb{R}) = \sigma(\mathcal{E})
\subset \mathcal{C}\)</span> as desired. ◻</p>
</div>
<div class="proof">
<p><em>Proof of Proposition <a href="#prop:cond_exp"
data-reference-type="ref" data-reference="prop:cond_exp">3.43</a>.</em>
Linearity is not obvious from the definition that we provide for the
conditional expectation and requires a deeper measure theoretic
understanding that is out of scope of this module. The tower property
follows from the calculation <span
class="math display">\[\begin{aligned}
\mathbb{E}\big[ \mathbb{E}[X \mid Y ] \big] =
\mathbb{E}\Big[\int_{\mathbb{R}} x f_{X \mid Y}(x \mid Y)
\mathop{}\!\mathrm{d} {\mu(x)} \Big] &amp;= \int_{\mathbb{R}^m}
\int_{\mathbb{R}} x f_{X \mid Y}(x \mid y) f_X(x) \mathop{}\!\mathrm{d}
{\mu(x)}\mathop{}\!\mathrm{d} {\nu(y)}\\
&amp;= \int_{\{f_Y \neq 0\}} \int_{\mathbb{R}} x \underbrace{f_{X \mid
Y}(x \mid y) f_Y(y)}_{\mathclap{= f_{X,Y}(x,y) \text{ on } \{y: f_Y(y) =
0\}}} \mathop{}\!\mathrm{d} {\mu(x)}\mathop{}\!\mathrm{d} {\nu(y)}\\
&amp;= \int_{\mathbb{R}^{m+1}} f_{X,Y}(x,y) \mathop{}\!\mathrm{d}
{\mu\otimes \nu(x,y)} \\
&amp;= 1,
\end{aligned}\]</span> where we used a version of Fubini’s theorem for
integrable functions, usually referred to as Tonelli’s theorem (or often
also Fubini–Tonelli theorem). Finally, if <span
class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> are independent we have <span
class="math inline">\(\mathbb{P}\)</span>-a.s. <span
class="math display">\[\mathbb{E}[X \mid Y] = \int_{\mathbb{R}} x
\frac{\overbrace{f_{X,Y}(x,Y)}^{\mathclap{= f_{X}(x) f_Y(Y)}}}{f_Y(Y)}
\mathop{}\!\mathrm{d} {\mu(x)} \bm{1}_{\{f_Y(Y) \neq 0\}} =
\int_{\mathbb{R}} x f_X(x) \mathop{}\!\mathrm{d} {\mu(x)} =
\mathbb{E}[X],\]</span> where we used <span
class="math inline">\(\mathbb{P}(f_Y(Y) = 0) = \int_{\{y: f_Y(y) = 0\}}
f_Y(y) \mathop{}\!\mathrm{d} {\nu(y)} = 0\)</span>. ◻</p>
</div>
<h2 id="borelcantelli-lemma">Borel–Cantelli lemma</h2>
<p>Let <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> be a
probability space and <span class="math inline">\((A_n)_{n \in
\mathbb{N}} \subset \mathcal{F}\)</span> be a sequence of events. We
define <span class="math display">\[\begin{aligned}
\limsup_{n \to \infty} A_n &amp;= \bigcap_{n = 1}^\infty \bigcup_{m =
n}^\infty A_m\\
&amp;= \big\{\omega \in \Omega: \forall n \in \mathbb{N}\, \exists m
\geq n \text{ s.t. } \omega \in A_m\big\}\\
&amp;= \big\{\omega \in \Omega: \omega \in A_n \text{ for infinitely
many } n \in \mathbb{N}\big\}.
\end{aligned}\]</span></p>
<div class="lemma">
<p><strong>Lemma 7.1</strong> (Borel–Cantelli). <em>Let <span
class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> be a
probability space and <span class="math inline">\((A_n)_{n \in
\mathbb{N}} \subset \mathcal{F}\)</span> be a sequence of events. Then,
<span class="math display">\[\sum_{n=1}^\infty \mathbb{P}(A_n) &lt;
\infty \implies \mathbb{P}\Big(\limsup_{n \to \infty} A_n \Big) =
0.\]</span></em></p>
</div>
<div class="proof">
<p><em>Proof.</em> Let <span class="math inline">\(B_n = \bigcup_{m \geq
n} A_m\)</span>. then, <span class="math inline">\((B_n)_n\)</span> is
decreasing, whence continuity of probability measures implies that <span
class="math display">\[\label{eq:bc1}
\mathbb{P}\Big(\limsup_{n \to \infty} A_n \Big) =
\mathbb{P}\Big(\bigcap_{n=1}^\infty B_n \Big) = \lim_{n \to \infty}
\mathbb{P}(B_n).\]</span> Since by assumption <span
class="math inline">\(\sum_{n=1}^\infty \mathbb{P}(A_n) &lt;
\infty,\)</span> we have <span class="math inline">\(\lim_{n \to \infty}
\sum_{m \geq n} \mathbb{P}(A_m) = 0\)</span>. Monotonicity of
probability measures gives <span class="math display">\[\lim_{n \to
\infty} \mathbb{P}(B_n) \leq \lim_{n \to \infty} \sum_{m \geq n}
\mathbb{P}(A_m) = 0.\]</span> Plugging this into <a href="#eq:bc1"
data-reference-type="eqref" data-reference="eq:bc1">[eq:bc1]</a> yields
the result. ◻</p>
</div>
<p>This allows to prove Lemma <a href="#coro:as"
data-reference-type="ref" data-reference="coro:as">4.6</a>.</p>
<div class="proof">
<p><em>Proof of Lemma <a href="#coro:as" data-reference-type="ref"
data-reference="coro:as">4.6</a>.</em> Let <span
class="math display">\[\Lambda \coloneq \Big\{\lim_{n \to \infty} Y_n =
Y \big\}.\]</span> We have to show that the given assumption implies
<span class="math inline">\(\mathbb{P}(\Lambda) = 0\)</span>, or
equivalently, <span
class="math inline">\(\mathbb{P}(\Lambda^{\mathrm{c}}) = 1\)</span>.
Noting that <span class="math display">\[\Lambda^{\mathrm{c}} =
\big\{\limsup_n \, \lvert Y_n - Y\rvert &gt; 0\big\} =
\bigcup_{N=1}^\infty \bigcap_{n =1}^\infty \bigcup_{m \geq n} \{\lvert
Y_n -Y \rvert &gt; 1/N\} =  \bigcup_{N=1}^\infty \limsup_{n \to
\infty}\, \{\lvert Y_n -Y \rvert &gt; 1/N\},\]</span> continuity of
probability measures gives <span
class="math display">\[\mathbb{P}(\Lambda^{\mathrm{c}}) = \lim_{N \to
\infty} \mathbb{P}\Big(\limsup_{n \to \infty}\, \{\lvert Y_n -Y \rvert
&gt; 1/N\} \Big).\]</span> By assumption, for any <span
class="math inline">\(N \in \mathbb{N}\)</span> it holds that <span
class="math display">\[\sum_{n=1}^\infty \mathbb{P}(\lvert Y_n - Y
\rvert &gt; 1/N) &lt; \infty,\]</span> so Borel–Cantelli yields that for
any <span class="math inline">\(N \in \mathbb{N}\)</span>, <span
class="math display">\[\mathbb{P}\Big(\limsup_{n \to \infty}\, \{\lvert
Y_n -Y \rvert &gt; 1/N\} \Big) = 0.\]</span> This now implies <span
class="math inline">\(\mathbb{P}(\Lambda^\mathrm{c}) = 0\)</span>, which
finishes the proof. ◻</p>
</div>
<h2 id="standard-normal-table">Standard Normal table</h2>
<figure id="fig:normaltable">
<img src="table.png" />
<figcaption>Numerical values for the CDF of standard normal random
variable</figcaption>
</figure>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Note here that if we start with a distribution <span
class="math inline">\(\mathbb{P}_X\)</span> on <span
class="math inline">\((\mathbb{R},\mathcal{B}(\mathbb{R}))\)</span>, we
can always construct a probability space <span
class="math inline">\((\Omega, \mathcal{F}, \mathbb{P})\)</span> and a
random variable <span class="math inline">\(X \colon \Omega \to
\mathbb{R}\)</span> such that <span
class="math inline">\(\mathbb{P}_X\)</span> is the distribution of <span
class="math inline">\(X\)</span>. Indeed, we may simply set <span
class="math inline">\(\Omega = \mathbb{R}, \mathcal{F}=
\mathcal{B}(\mathbb{R}), \mathbb{P}= \mathbb{P}_X\)</span> and <span
class="math inline">\(X(\omega) = \omega\)</span> for all <span
class="math inline">\(\omega \in \mathbb{R}\)</span>. This is referred
to as the <em>canonical construction</em>.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><em>it is implicit here that the integrals make sense,
that is Fubini’s theorem also states that <span class="math inline">\(x
\mapsto \int_{E_2} g(x,y) \mathop{}\!\mathrm{d} {\mu_2(y)}\)</span> and
<span class="math inline">\(y \mapsto \int_{E_1} g(x,y)
\mathop{}\!\mathrm{d} {\mu_1(x)}\)</span> are measurable</em><a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>this is because for any <span
class="math inline">\(\omega \notin \{\omega \in \Omega: f_Y(Y(\omega))
= 0)\} \eqcolon N\)</span>, <span class="math inline">\(B \mapsto
\mathbb{P}_{X \mid Y}(B)(\omega)\)</span> is a probability distribution
and <span class="math inline">\(\mathbb{P}(N) = \int_{\{f_Y = 0\}}
f_Y(y) \mathop{}\!\mathrm{d} {\nu(y)} = 0\)</span>.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><em>similarly to random variables, if <span
class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>
are <span class="math inline">\(n\)</span> and <span
class="math inline">\(m\)</span>-dimensional random vectors,
respectively, they are said to be independent if <span
class="math inline">\(\mathbb{P}(X \in B_1, Y \in B_2) = \mathbb{P}(X
\in B_1) \mathbb{P}(Y \in B_2)\)</span> for any Borel sets <span
class="math inline">\(B_1,B_2\)</span>, which is equivalent to the
factorisation identity <span class="math inline">\(f_{X,Y}(x,y) = f_X(x)
f_Y(y)\)</span> a.e. w.r.t. their dominating measure.</em><a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>that is, <span class="math inline">\(\lim_{y \to x}
F_X(y) = x\)</span><a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><em>For a full list of assumptions; see <span
class="citation" data-cites="casella2024statistical"></span>, Section
10.6.2</em><a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>These arguments are known as uniform law of large
numbers. Note that here one cannot use continuous mapping theorem since
<span class="math inline">\(l&#39;&#39;&#39;(\theta;X)\)</span> is a
random function<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
